
@article{AbadieEtAl:2006,
  title = {Large Sample Properties of Matching Estimators for Average Treatment Effects},
  author = {Abadie, Alberto and Imbens, Guido W.},
  date = {2006},
  journaltitle = {Econometrica : journal of the Econometric Society},
  shortjournal = {Econometrica},
  volume = {74},
  number = {1},
  pages = {235--267},
  doi = {10.1111/j.1468-0262.2006.00655.x},
  file = {D\:\\Zotero\\storage\\K3SPB3F8\\Abadie_Imbens_2006_Large sample properties of matching estimators for average treatment effects.pdf}
}

@misc{Abrahamsen:1997,
  title = {A Review of {{Gaussian}} Random Fields and Correlation Functions},
  author = {Abrahamsen, Petter},
  date = {1997}
}

@article{alstonBayesianModelComparison2005,
  title = {Bayesian {{Model Comparison}}: {{Review}} and {{Discussion}}},
  author = {Alston, C and Kuhnert, P and Choy, S Low and McVinish, R and Mengersen, K},
  date = {2005},
  pages = {4},
  abstract = {This paper provides a brief review of the more popular methods for comparing models in a Bayesian framework. Personal experience in implementing these methods in problems requiring mixture models is also referenced.},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\DZAYMCPU\\Alston et al_Bayesian Model Comparison.pdf}
}

@article{AngristEtAl:2001,
  title = {Instrumental Variables and the Search for Identification: {{From}} Supply and Demand to Natural Experiments},
  author = {Angrist, Joshua D and Krueger, Alan B},
  date = {2001-11},
  journaltitle = {Journal of Economic Perspectives},
  volume = {15},
  number = {4},
  pages = {69--85},
  doi = {10.1257/jep.15.4.69},
  file = {D\:\\Zotero\\storage\\FED9UL7J\\Angrist_Krueger_2001_Instrumental variables and the search for identification.pdf}
}

@article{azouryOptimalPoliciesApproximations2009,
  title = {Optimal {{Policies}} and {{Approximations}} for a {{Bayesian Linear Regression Inventory Model}}},
  author = {Azoury, Katy S. and Miyaoka, Julia},
  date = {2009-05},
  journaltitle = {Management Science},
  shortjournal = {Management Science},
  volume = {55},
  number = {5},
  pages = {813--826},
  issn = {0025-1909, 1526-5501},
  doi = {10/bd4mc2},
  url = {http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1080.0980},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\FNKZ5NP8\\Azoury_Miyaoka_2009_Optimal Policies and Approximations for a Bayesian Linear Regression Inventory.pdf;D\:\\Zotero\\storage\\J8UGH8H5\\Azoury_Miyaoka_2009_Optimal Policies and Approximations for a Bayesian Linear Regression Inventory.pdf}
}

@article{baldwinIntroductionUsingBayesian2017,
  title = {An Introduction to Using {{Bayesian}} Linear Regression with Clinical Data},
  author = {Baldwin, Scott A. and Larson, Michael J.},
  date = {2017-11},
  journaltitle = {Behaviour Research and Therapy},
  shortjournal = {Behaviour Research and Therapy},
  volume = {98},
  pages = {58--75},
  issn = {00057967},
  doi = {10/gd3vfk},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0005796716302364},
  urldate = {2022-03-25},
  abstract = {Statistical training psychology focuses on frequentist methods. Bayesian methods are an alternative to standard frequentist methods. This article provides researchers with an introduction to fundamental ideas in Bayesian modeling. We use data from an electroencephalogram (EEG) and anxiety study to illustrate Bayesian models. Specifically, the models examine the relationship between error-related negativity (ERN), a particular event-related potential, and trait anxiety. Methodological topics covered include: how to set up a regression model in a Bayesian framework, specifying priors, examining convergence of the model, visualizing and interpreting posterior distributions, interval estimates, expected and predicted values, and model comparison tools. We also discuss situations where Bayesian methods can outperform frequentist methods as well has how to specify more complicated regression models. Finally, we conclude with recommendations about reporting guidelines for those using Bayesian methods in their own research. We provide data and R code for replicating our analyses.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\JSFNI2JD\\Baldwin_Larson_2017_An introduction to using Bayesian linear regression with clinical data.pdf}
}

@article{ballardSupportingInformationInformation,
  title = {Supporting Information: {{Information}} Processing under Reward versus under Punishment},
  author = {Ballard, Timothy and Sewell, David K and Cosgrove, Daniel and Neal, Andrew},
  pages = {8},
  langid = {english},
  keywords = {⛔ No DOI found,I 级文献},
  file = {D\:\\Zotero\\storage\\J73CYMYT\\Ballard et al. - Supporting information Information processing und.pdf}
}

@report{barrettSixReasonsConsider2019,
  type = {preprint},
  title = {Six {{Reasons}} to {{Consider Using R}} in {{Psychological Research}}},
  author = {Barrett, Tyson S.},
  date = {2019-08-15},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/8mb6d},
  url = {https://osf.io/8mb6d},
  urldate = {2022-04-16},
  abstract = {The R Statistical Environment is becoming increasingly accessible to non-statistician researchers. This provides an opportunity for many researchers in psychology to consider adopting R in their work. Herein is presented six reasons for why R should not be overlooked by researchers in psychology: 1) R is free and open-source; 2) R has many packages built for common descriptive and statistical analyses in the psychological sciences; 3) the R community is supportive and have freely provided many useful resources, for beginners and advanced users alike; 4) R is becoming increasingly popular in psychology already, making it easier to collaborate using the software; 5) analyses in R can be highly reproducible with features like R Markdown and knitr, simplifying the process to provide open science; and 6) the R language has improved in diverse ways, making common data wrangling tasks fast, dependable, and highly replicable. These reasons are presented with their corresponding limitations.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\J7XEBCXP\\Barrett - 2019 - Six Reasons to Consider Using R in Psychological R.pdf}
}

@article{bergerOverviewRobustBayesian1994,
  title = {An Overview of Robust {{Bayesian}} Analysis},
  author = {Berger, James O. and Moreno, Elías and Pericchi, Luis Raul and Bayarri, M. Jesús and Bernardo, José M. and Cano, Juan A. and De la Horra, Julián and Martín, Jacinto and Ríos-Insúa, David and Betrò, Bruno and Dasgupta, A. and Gustafson, Paul and Wasserman, Larry and Kadane, Joseph B. and Srinivasan, Cid and Lavine, Michael and O’Hagan, Anthony and Polasek, Wolfgang and Robert, Christian P. and Goutis, Constantinos and Ruggeri, Fabrizio and Salinetti, Gabriella and Sivaganesan, Siva},
  date = {1994-06},
  journaltitle = {Test},
  shortjournal = {Test},
  volume = {3},
  number = {1},
  pages = {5--124},
  issn = {1133-0686, 1863-8260},
  doi = {10/b2b42z},
  url = {http://link.springer.com/10.1007/BF02562676},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\YKRDTBD5\\Berger et al_1994_An overview of robust Bayesian analysis.pdf}
}

@article{berghTutorialBayesianMultimodel2021,
  title = {A Tutorial on {{Bayesian}} Multi-Model Linear Regression with {{BAS}} and {{JASP}}},
  author = {van den Bergh, Don and Clyde, Merlise A. and Gupta, Akash R. Komarlu Narendra and de Jong, Tim and Gronau, Quentin F. and Marsman, Maarten and Ly, Alexander and Wagenmakers, Eric-Jan},
  options = {useprefix=true},
  date = {2021-12},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {53},
  number = {6},
  pages = {2351--2371},
  issn = {1554-3528},
  doi = {10/gk5q7j},
  url = {https://link.springer.com/10.3758/s13428-021-01552-2},
  urldate = {2022-03-25},
  abstract = {Linear regression analyses commonly involve two consecutive stages of statistical inquiry. In the first stage, a single ‘best’ model is defined by a specific selection of relevant predictors; in the second stage, the regression coefficients of the winning model are used for prediction and for inference concerning the importance of the predictors. However, such second-stage inference ignores the model uncertainty from the first stage, resulting in overconfident parameter estimates that generalize poorly. These drawbacks can be overcome by model averaging, a technique that retains all models for inference, weighting each model’s contribution by its posterior probability. Although conceptually straightforward, model averaging is rarely used in applied research, possibly due to the lack of easily accessible software. To bridge the gap between theory and practice, we provide a tutorial on linear regression using Bayesian model averaging in JASP, based on the BAS package in R. Firstly, we provide theoretical background on linear regression, Bayesian inference, and Bayesian model averaging. Secondly, we demonstrate the method on an example data set from the World Happiness Report. Lastly, we discuss limitations of model averaging and directions for dealing with violations of model assumptions.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\77L48YNK\\Bergh et al_2021_A tutorial on Bayesian multi-model linear regression with BAS and JASP.pdf}
}

@book{BernardoEtAl:2009,
  title = {Bayesian Theory},
  author = {Bernardo, Jose-M. and Smith, Adrian F. M.},
  date = {2009},
  series = {Wiley Series in Probability and Mathematical Statistics: {{Probability}} and Mathematical Statistics},
  publisher = {{John Wiley \&amp; Sons, Ltd., Chichester}}
}

@article{Betancourt:2015b,
  title = {A Unified Treatment of Predictive Model Comparison},
  author = {Betancourt, Michael},
  date = {2015-06},
  keywords = {⛔ No DOI found}
}

@article{Betancourt:2016b,
  title = {Diagnosing Suboptimal Cotangent Disintegrations in Hamiltonian Monte Carlo},
  author = {Betancourt, Michael},
  date = {2016-04},
  journaltitle = {ArXiv e-prints},
  volume = {1604.00695},
  keywords = {⛔ No DOI found}
}

@article{Betancourt:2018a,
  title = {The Convergence of Markov Chain Monte Carlo Methods: {{From}} the Metropolis Method to Hamiltonian Monte Carlo},
  author = {Betancourt, Michael},
  date = {2018},
  journaltitle = {Annalen der Physik},
  volume = {0},
  number = {0},
  pages = {1700214},
  keywords = {⛔ No DOI found}
}

@article{Betancourt:2018b,
  title = {A Conceptual Introduction to Hamiltonian Monte Carlo},
  author = {Betancourt, Michael},
  date = {2018-01},
  journaltitle = {ArXiv e-prints},
  volume = {1701.02434},
  keywords = {⛔ No DOI found}
}

@article{Betancourt:2019,
  title = {Incomplete Reparameterizations and Equivalent Metrics},
  author = {Betancourt, Michael},
  date = {2019},
  keywords = {⛔ No DOI found}
}

@article{Betancourt2018a,
  title = {Calibrating Model-Based Inferences and Decisions},
  author = {Betancourt, Michael},
  date = {2018-03},
  keywords = {⛔ No DOI found}
}

@article{BetancourtEtAl:2014b,
  title = {Optimizing the Integrator Step Size for Hamiltonian Monte Carlo},
  author = {Betancourt, Michael and Byrne, Simon and Girolami, Mark},
  date = {2014-11},
  journaltitle = {ArXiv e-prints},
  volume = {1410.5110},
  keywords = {⛔ No DOI found}
}

@incollection{BetancourtEtAl:2015,
  title = {Hamiltonian {{Monte Carlo}} for Hierarchical Models},
  booktitle = {Current Trends in Bayesian Methodology with Applications},
  author = {Betancourt, Michael and Girolami, Mark},
  editor = {Dipak K. Dey, Umesh Singh and Loganathan, A.},
  date = {2015},
  publisher = {{Chapman \& Hall/CRC Press}}
}

@article{beyerSuicideBehaviorsBipolar2016,
  title = {Suicide {{Behaviors}} in {{Bipolar Disorder}}},
  author = {Beyer, John L. and Weisler, Richard H.},
  date = {2016-03},
  journaltitle = {Psychiatric Clinics of North America},
  shortjournal = {Psychiatric Clinics of North America},
  volume = {39},
  number = {1},
  pages = {111--123},
  issn = {0193953X},
  doi = {10/f8f34g},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0193953X15000970},
  urldate = {2022-04-16},
  langid = {english},
  file = {D\:\\Zotero\\storage\\EULKXFK3\\beyer2016.pdf.pdf;D\:\\Zotero\\storage\\PD49WLT6\\Beyer and Weisler - 2016 - Suicide Behaviors in Bipolar Disorder.pdf;D\:\\Zotero\\storage\\XHWKS3Q2\\Beyer_Weisler_2016_Suicide Behaviors in Bipolar Disorder.pdf}
}

@book{Bishop:2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer, New York}}
}

@article{boedekerHierarchicalLinearModeling2017,
  title = {Hierarchical {{Linear Modeling}} with {{Maximum Likelihood}}, {{Restricted Maximum Likelihood}}, and {{Fully Bayesian Estimation}}},
  author = {Boedeker, Peter},
  date = {2017},
  publisher = {{University of Massachusetts Amherst}},
  doi = {10.7275/5VVY-8613},
  url = {https://scholarworks.umass.edu/pare/vol22/iss1/2/},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\23XPP4UT\\Boedeker_2017_Hierarchical Linear Modeling with Maximum Likelihood, Restricted Maximum.pdf}
}

@report{boehmComputingUsingInclusion2021,
  type = {preprint},
  title = {Computing and {{Using Inclusion Bayes Factors}} for {{Mixed Fixed}} and {{Random Effect Diffusion Decision Models}}},
  author = {Boehm, Udo and Evans, Nathan J. and Gronau, Quentin Frederik and Matzke, Dora and Wagenmakers, Eric-Jan and Heathcote, Andrew},
  date = {2021-07-01},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/45t2w},
  url = {https://osf.io/45t2w},
  urldate = {2021-10-07},
  abstract = {Cognitive models provide a substantively meaningful quantitative description of latent cognitive processes. The quantitative formulation of these models supports cumulative theory building and enables strong empirical tests. However, the non-linearity of these models and pervasive correlations among model parameters pose special challenges when applying cognitive models to data. Firstly, estimating cognitive models typically requires large hierarchical data sets that need to be accommodated by an appropriate statistical structure within the model. Secondly, statistical inference needs to appropriately account for model uncertainty to avoid overconfidence and biased parameter estimates. In the present work we show how these challenges can be addressed through a combination of Bayesian hierarchical modelling and Bayesian model averaging. To illustrate these techniques, we apply the popular diffusion decision model to data from a collaborative selective influence study.},
  langid = {english},
  annotation = {ZSCC: 0000000},
  file = {D\:\\Zotero\\storage\\RBVLG3RW\\Boehm et al_2021_Computing and Using Inclusion Bayes Factors for Mixed Fixed and Random Effect.pdf}
}

@article{bornnEfficientComputationalApproach,
  title = {An Efficient Computational Approach for Prior Sensitivity Analysis and Cross-Validation},
  author = {Bornn, Luke and Doucet, Arnaud and Gottardo, Raphael},
  journaltitle = {The Canadian Journal of Statistics},
  pages = {18},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\EI4REBR2\\Bornn et al. - An efficient computational approach for prior sens.pdf}
}

@article{BoseEtAl:2002,
  title = {A Contemporary Review and Bibliography of Infinitely Divisible Distributions and Processes},
  author = {Bose, Arup and Dasgupta, Anirban and Rubin, Herman},
  date = {2002},
  journaltitle = {Sankhyā: The Indian Journal of Statistics, Series A (1961-2002)},
  volume = {64},
  number = {3},
  pages = {763--819},
  keywords = {⛔ No DOI found}
}

@book{BoxEtAl:1973,
  title = {Bayesian Inference in Statistical Analysis},
  author = {Box, George E. P. and Tiao, George C.},
  date = {1973},
  series = {Addison-Wesley Series in Behavioral Science: {{Quantitative}} Methods},
  publisher = {{Addison-Wesley Publishing Co., Reading, Mass.-London-Don Mills, Ont.}}
}

@book{BoxEtAl:1987,
  title = {Empirical Model-Building and Response Surfaces},
  author = {Box, George E. P. and Draper, Norman R.},
  date = {1987},
  series = {Wiley Series in Probability and Mathematical Statistics: {{Applied}} Probability and Statistics},
  publisher = {{John Wiley \&amp; Sons, Inc., New York}}
}

@book{BoxEtAl:2005,
  title = {Statistics for Experimenters},
  author = {Box, George E. P. and Hunter, J. Stuart and Hunter, William G.},
  date = {2005},
  series = {Wiley Series in Probability and Statistics},
  edition = {2},
  publisher = {{Wiley-Interscience [John Wiley \& Sons], Hoboken, NJ}}
}

@article{brochhagenBriefRiskBeing2021,
  title = {Brief at the {{Risk}} of {{Being Misunderstood}}: {{Consolidating Population-}} and {{Individual-Level Tendencies}}},
  shorttitle = {Brief at the {{Risk}} of {{Being Misunderstood}}},
  author = {Brochhagen, Thomas},
  date = {2021-09},
  journaltitle = {Computational Brain \& Behavior},
  shortjournal = {Comput Brain Behav},
  volume = {4},
  number = {3},
  pages = {305--317},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-021-00099-x},
  url = {https://link.springer.com/10.1007/s42113-021-00099-x},
  urldate = {2021-09-15},
  abstract = {Communicative pressures can give rise to regular patterns of language use. These patterns, in turn, can come to shape a language’s structure over time. In a recent study, Kanwal et al. (Cognition, 165:45–52, 2017) investigate whether an interaction of such pressures may underlie the cross-linguistic tendency of frequent forms to be shorter. Using a miniature artificial language, they show that speakers follow this tendency if pressured for brevity and accuracy. In this study, we use probabilistic models of varying complexity to shed light on the individual-level factors behind this trend. We find that a hierarchical model that accommodates for subjects’ heterogeneous beliefs about object frequencies best explains the data. At the population level, this model predicts an association of short forms with frequent meanings, in line with past research. At the individual level, however, it reveals a number of patterns that systematically deviate from this trend. On the one hand, these findings support the hypothesis that individual-level pressures may underlie natural languages’ relationship between frequency and brevity. On the other, by characterizing the individual-level dynamics on which this relationship rests, they highlight the importance of consolidating multiple strata of analysis and of understanding where and why they might diverge.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\8H5VKFLS\\Brochhagen_2021_Brief at the Risk of Being Misunderstood.pdf}
}

@article{broemelingBAYESIANANALYSISLINEAR,
  title = {{{BAYESIAN ANALYSIS OF LINEAR MODELS}}},
  author = {Broemeling, Lyle D},
  pages = {475},
  doi = {10/gprpg3},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\VPMLJHR2\\Broemeling_BAYESIAN ANALYSIS OF LINEAR MODELS.pdf}
}

@book{BrooksEtAl:2011,
  title = {Handbook of {{Markov Chain Monte Carlo}}},
  editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
  date = {2011},
  publisher = {{CRC Press}},
  location = {{New York}}
}

@article{brysbaertPowerAnalysisEffect2018,
  title = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}: {{A Tutorial}}},
  shorttitle = {Power {{Analysis}} and {{Effect Size}} in {{Mixed Effects Models}}},
  author = {Brysbaert, Marc and Stevens, Michaël},
  date = {2018-01-12},
  journaltitle = {Journal of Cognition},
  volume = {1},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10.5334/joc.10},
  url = {http://www.journalofcognition.org/articles/10.5334/joc.10/},
  urldate = {2022-08-31},
  langid = {english},
  file = {D\:\\Zotero\\storage\\DT25UGNZ\\Brysbaert and Stevens - 2018 - Power Analysis and Effect Size in Mixed Effects Mo.pdf}
}

@article{burkiWhatDidWe2020b,
  title = {What Did We Learn from Forty Years of Research on Semantic Interference? {{A Bayesian}} Meta-Analysis},
  shorttitle = {What Did We Learn from Forty Years of Research on Semantic Interference?},
  author = {Bürki, Audrey and Elbuy, Shereen and Madec, Sylvain and Vasishth, Shravan},
  date = {2020-10},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {114},
  pages = {104125},
  issn = {0749596X},
  doi = {10.1016/j.jml.2020.104125},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X20300395},
  urldate = {2021-09-15},
  abstract = {When participants in an experiment have to name pictures while ignoring distractor words superimposed on the picture or presented auditorily (i.e., picture-word interference paradigm), they take more time when the word to be named (or target) and distractor words are from the same semantic category (e.g., cat-dog). This experimental effect is known as the semantic interference effect, and is probably one of the most studied in the language production literature. The functional origin of the effect and the exact conditions in which it occurs are however still debated. Since Lupker (1979) reported the effect in the first response time experiment about 40 years ago, more than 300 similar experiments have been conducted. The semantic interference effect was replicated in many experiments, but several studies also reported the absence of an effect in a subset of experimental conditions. The aim of the present study is to provide a comprehensive theoretical review of the existing evidence to date and several Bayesian meta-analyses and meta-regressions to determine the size of the effect and explore the experimental conditions in which the effect surfaces. The results are discussed in the light of current debates about the functional origin of the semantic interference effect and its implications for our understanding of the language production system.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\8VU3G97K\\Bürki et al_2020_What did we learn from forty years of research on semantic interference.pdf}
}

@misc{burknerAdvancedBayesianMultilevel2017,
  title = {Advanced {{Bayesian Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Bürkner, Paul-Christian},
  date = {2017-10-15},
  number = {arXiv:1705.11123},
  eprint = {1705.11123},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1705.11123},
  urldate = {2022-07-26},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian single-level and multilevel models, which are fitted with the probabilistic programming language Stan behind the scenes. Several response distributions are supported, of which all parameters (e.g., location, scale, and shape) can be predicted at the same time thus allowing for distributional regression. Non-linear relationships may be specified using non-linear predictor terms or semi-parametric approaches such as splines or Gaussian processes. To make all of these modeling options possible in a multilevel framework, brms provides an intuitive and powerful formula syntax, which extends the well known formula syntax of lme4. The purpose of the present paper is to introduce this syntax in detail and to demonstrate its usefulness with four examples, each showing other relevant aspects of the syntax.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Computation},
  file = {D\:\\Zotero\\storage\\HXMUEDRU\\Bürkner - 2017 - Advanced Bayesian Multilevel Modeling with the R P.pdf}
}

@article{burknerBayesianDistributionalNonLinear,
  title = {Bayesian {{Distributional Non-Linear Multilevel Modeling}} with the {{R Package}} Brms},
  author = {Bürkner, Paul-Christian},
  pages = {19},
  abstract = {The brms package allows R users to easily specify a wide range of Bayesian multilevel models, which are fitted with the probabilistic programming language Stan behind the scenes. A wide range of response distributions are supported in combination with an intuitive and powerful multilevel formula syntax. Non-linear relationships may be specified using non-linear predictor terms or smooth functions. Additionally, all parameters of the response distribution can be predicted at the same time allowing for distributional regression. Model fit can be investigated and compared using leave-one-out cross-validation and graphical posterior-predictive checks. Many more post-processing and plotting methods are implemented.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\HRW5AVBB\\Bürkner - Bayesian Distributional Non-Linear Multilevel Mode.pdf}
}

@unpublished{burknerBayesianItemResponse2020,
  title = {Bayesian {{Item Response Modeling}} in {{R}} with Brms and {{Stan}}},
  author = {Bürkner, Paul-Christian},
  date = {2020-02-01},
  eprint = {1905.09501},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1905.09501},
  urldate = {2022-03-25},
  abstract = {Item Response Theory (IRT) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement IRT models, they tend to be restricted to respective prespecified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian IRT models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common IRT model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and post-processed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Computation},
  file = {D\:\\Zotero\\storage\\TDEKTIHA\\Bürkner_2020_Bayesian Item Response Modeling in R with brms and Stan.pdf}
}

@article{burknerBrmsPackageBayesian2013,
  title = {Brms: {{An R Package}} for {{Bayesian Generalized Linear Mixed Models}} Using {{Stan}}},
  author = {Burkner, Paul-Christian},
  date = {2013},
  journaltitle = {Journal of statistical software},
  number = {80},
  pages = {23},
  abstract = {The brms package implements Bayesian generalized linear mixed models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing to fit – among others – linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, and hurdle models. Further modeling options include multiple grouping factors each with multiple random effects, autocorrelation of the response variable, user defined covariance structures, censored data, as well as metaanalytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike-Information Criterion and leave-one-out cross-validation.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\GDWIYPRA\\Burkner - brms An R Package for Bayesian Generalized Linear.pdf}
}

@article{burknerBrmsPackageBayesian2017,
  title = {Brms {{Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {\textbf{Brms}},
  author = {Bürkner, Paul-Christian},
  date = {2017},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {80},
  number = {1},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  url = {http://www.jstatsoft.org/v80/i01/},
  urldate = {2021-09-14},
  abstract = {The brms package implements Bayesian multilevel models in R using the probabilistic programming language Stan. A wide range of distributions and link functions are supported, allowing users to fit – among others – linear, robust linear, binomial, Poisson, survival, ordinal, zero-inflated, hurdle, and even non-linear models all in a multilevel context. Further modeling options include autocorrelation of the response variable, user defined covariance structures, censored data, as well as meta-analytic standard errors. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their beliefs. In addition, model fit can easily be assessed and compared with the Watanabe-Akaike information criterion and leave-one-out cross-validation.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\7MRZBJU3\\Bürkner_2017_brms Package for Bayesian Multilevel Models Using Stan.pdf}
}

@report{burknerModelingMonotonicEffects2018b,
  type = {preprint},
  title = {Modeling {{Monotonic Effects}} of {{Ordinal Predictors}} in {{Bayesian Regression Models}}},
  author = {Bürkner, Paul - Christian and Charpentier, Emmanuel},
  date = {2018-11-02},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/9qkhj},
  url = {https://osf.io/9qkhj},
  urldate = {2021-09-15},
  abstract = {Ordinal predictors are commonly used in regression models. They are often incorrectly treated as either nominal or metric, thus under- or overestimating the contained information. Such practices may lead to worse inference and predictions compared to methods which are specifically designed for this purpose. We propose a new method for modeling ordinal predictors that applies in situations in which it is reasonable to assume their effects to be monotonic. The parameterization of such monotonic effects is realized in terms of a scale parameter b representing the direction and size of the effect and a simplex parameter ζ modeling the normalized differences between categories. This ensures that predictions increase or decrease monotonically, while changes between adjacent categories may vary across categories. This formulation generalizes to interaction terms as well as multilevel structures. 7 Monotonic effects may not only be applied to ordinal predictors, but also to other discrete variables for which a monotonic relationship is plausible. In simulation studies, we show that the model is well calibrated and, in case of monotonicity, has similar or even better predictive performance than other approaches designed to handle ordinal predictors. Using Stan, we developed a Bayesian estimation method for monotonic effects, which allows to incorporate prior information and to check the assumption of monotonicity. We have implemented this method in the R package brms, so that fitting monotonic effects in a fully Bayesian framework is now straightforward.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\UH8XJH2L\\Bürkner_Charpentier_2018_Modeling Monotonic Effects of Ordinal Predictors in Bayesian Regression Models.pdf}
}

@article{burknerModellingMonotonicEffects2020,
  title = {Modelling Monotonic Effects of Ordinal Predictors in {{Bayesian}} Regression Models},
  author = {Bürkner, Paul‐Christian and Charpentier, Emmanuel},
  date = {2020-11},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  shortjournal = {Br J Math Stat Psychol},
  volume = {73},
  number = {3},
  pages = {420--451},
  issn = {0007-1102, 2044-8317},
  doi = {10/ggqtkh},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/bmsp.12195},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\Y9UBPW4P\\Bürkner_Charpentier_2020_Modelling monotonic effects of ordinal predictors in Bayesian regression models.pdf}
}

@article{burknerOrdinalRegressionModels,
  title = {Ordinal {{Regression Models}} in {{Psychology}}: {{A Tutorial}}},
  author = {Bürkner, Paul-Christian and Vuorre, Matti},
  pages = {25},
  abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This practice can lead to distorted effect-size estimates, inflated error rates, and other problems. We argue for the application of ordinal models that make appropriate assumptions about the variables under study. In this Tutorial, we first explain the three major classes of ordinal models: the cumulative, sequential, and adjacent-category models. We then show how to fit ordinal models in a fully Bayesian framework with the R package brms, using data sets on opinions about stem-cell research and time courses of marriage. The appendices provide detailed mathematical derivations of the models and a discussion of censored ordinal models. Compared with metric models, ordinal models provide better theoretical interpretation and numerical inference from ordinal data, and we recommend their widespread adoption in psychology.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\4ZXHFFXI\\Bürkner_Vuorre_Ordinal Regression Models in Psychology.pdf}
}

@article{byrneAcuteStressEnhances2020,
  title = {Acute Stress Enhances Tolerance of Uncertainty during Decision-Making},
  author = {Byrne, Kaileigh A. and Peters, Caitlin and Willis, Hunter C. and Phan, Dana and Cornwall, Astin and Worthy, Darrell A.},
  date = {2020-12},
  journaltitle = {Cognition},
  shortjournal = {Cognition},
  volume = {205},
  pages = {104448},
  issn = {00100277},
  doi = {10/ghbv8x},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027720302675},
  urldate = {2022-04-16},
  abstract = {Acute stress has been shown to influence reward sensitivity, feedback learning, and risk-taking during decisionmaking, primarily through activation of the hypothalamic pituitary axis (HPA). However, it is unclear how acute stress affects decision-making among choices that vary in their degree of uncertainty. To address this question, we conducted two experiments in which participants repeatedly chose between two options—a high-uncertainty option that offered highly variable rewards but was advantageous in the long-term, and a low-uncertainty option that offered smaller yet more consistent rewards. The Socially Evaluated Cold Pressor Task (SECPT) was utilized to induce acute stress. Participants in Experiment 1 (N = 114) were exposed to either the SECPT or a warmwater control condition and then completed the decision-making under uncertainty task. Compared to the control condition, those exposed to the acute stress manipulation chose the high-uncertainty option that pro­ vided highly variable but larger rewards over the option that provided stable, smaller rewards. Experiment 2 (N = 95) incorporated a salivary cortisol measure. Results replicated the behavioral findings in Experiment 1 and demonstrated that the acute stress manipulation increased salivary cortisol. This work suggests that mod­ erate acute stress is associated with tolerance of outcome variability in contexts that depend on learning to maximize rewards.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\8GAL7BNT\\Byrne et al. - 2020 - Acute stress enhances tolerance of uncertainty dur.pdf;D\:\\Zotero\\storage\\PGK9BPGZ\\Byrne et al_2020_Acute stress enhances tolerance of uncertainty during decision-making.pdf}
}

@article{cainFitBayesianEvaluation2019,
  title = {Fit for a {{Bayesian}}: {{An Evaluation}} of {{PPP}} and {{DIC}} for {{Structural Equation Modeling}}},
  shorttitle = {Fit for a {{Bayesian}}},
  author = {Cain, Meghan K. and Zhang, Zhiyong},
  date = {2019-01-02},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {26},
  number = {1},
  pages = {39--50},
  issn = {1070-5511, 1532-8007},
  doi = {10/ggwmhj},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2018.1490648},
  urldate = {2022-03-25},
  abstract = {Despite its importance to structural equation modeling, model evaluation remains underdeveloped in the Bayesian SEM framework. Posterior predictive p-values (PPP) and deviance information criteria (DIC) are now available in popular software for Bayesian model evaluation, but they remain underutilized. This is largely due to the lack of recommendations for their use. To address this problem, PPP and DIC were evaluated in a series of Monte Carlo simulation studies. The results show that both PPP and DIC are influenced by severity of model misspecification, sample size, model size, and choice of prior. The cutoffs PPP {$<$} 0.10 and ΔDIC {$>$} 7 work best in the conditions and models tested here to maintain low false detection rates and misspecified model selection rates, respectively. The recommendations provided in this study will help researchers evaluate their models in a Bayesian SEM analysis and set the stage for future development and evaluation of Bayesian SEM fit indices.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\UYLQI9R8\\Cain_Zhang_2019_Fit for a Bayesian.pdf}
}

@article{caldwellBayesianSampleSize,
  title = {Bayesian {{Sample Size Justification}}},
  author = {Caldwell, Aaron R},
  pages = {7},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\Z38UVPLR\\Caldwell - Bayesian Sample Size Justification.pdf}
}

@inproceedings{carvalhoHandlingSparsityHorseshoe2009,
  title = {Handling Sparsity via the Horseshoe},
  booktitle = {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  author = {Carvalho, Carlos M. and Polson, Nicholas G. and Scott, James G.},
  editor = {van Dyk, David and Welling, Max},
  options = {useprefix=true},
  date = {2009-04-16/2009-04-18},
  series = {Proceedings of Machine Learning Research},
  volume = {5},
  pages = {73--80},
  publisher = {{PMLR}},
  location = {{Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA}},
  url = {http://proceedings.mlr.press/v5/carvalho09a.html},
  pdf = {http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf},
  file = {D\:\\Zotero\\storage\\5NCGSJYM\\Carvalho et al_2009_Handling sparsity via the horseshoe.pdf}
}

@book{CasellaEtAl:2002,
  title = {Statistical Inference},
  author = {Casella, George and Berger, Roger L},
  date = {2002},
  edition = {2},
  publisher = {{Duxbury Thomson Learning}}
}

@article{charlesDynamicSourcesEvidence2019,
  title = {Dynamic Sources of Evidence Supporting Confidence Judgments and Error Detection.},
  author = {Charles, Lucie and Yeung, Nick},
  date = {2019-01},
  journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
  shortjournal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {45},
  number = {1},
  pages = {39--52},
  issn = {1939-1277, 0096-1523},
  doi = {10/gfs9tz},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xhp0000583},
  urldate = {2022-03-29},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\IZDF74WU\\Charles_Yeung_2019_Dynamic sources of evidence supporting confidence judgments and error detection.pdf}
}

@report{cirankaBayesianModelSocial2020,
  type = {preprint},
  title = {A {{Bayesian Model}} of {{Social Influence}} under {{Risk}} and {{Uncertainty}}},
  author = {Ciranka, Simon Kai and van den Bos, Wouter},
  options = {useprefix=true},
  date = {2020-05-26},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/mujek},
  url = {https://osf.io/mujek},
  urldate = {2022-04-16},
  abstract = {Humans live in an uncertain world and often rely on social information in order to reduce uncertainty. However, the relationship between uncertainty and social information use is not yet fully understood. In this work we argue that previous studies have often neglected different degrees of uncertainty that need to be accounted for when studying social information use. We introduce a novel experimental paradigm to measure risky decision making, wherein social information and uncertainty are manipulated. We also developed a Bayesian model of social information use. We show that across different levels of uncertainty; social influence follows similar principles. Social information is more impactful when individuals are more uncertain. Notably, this relationship holds for experimental manipulations of uncertainty but also for subjective uncertainty within experimental conditions. We conclude with discussing that social influence can be better understood when paying credit to subjective uncertainties and preferences.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\3XFPLGH4\\Ciranka and van den Bos - 2020 - A Bayesian Model of Social Influence under Risk an.pdf}
}

@book{CoverEtAl:2006,
  title = {Elements of Information Theory},
  author = {Cover, Thomas M. and Thomas, Joy A.},
  date = {2006},
  edition = {2},
  publisher = {{Wiley-Interscience [John Wiley \& Sons], Hoboken, NJ}}
}

@article{Cox:1972,
  title = {Regression Models and Life-Tables},
  author = {Cox, D. R.},
  date = {1972},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {34},
  number = {2},
  pages = {187--220},
  doi = {10.1111/j.2517-6161.1972.tb00899.x},
  file = {D\:\\Zotero\\storage\\35IQUPS5\\Cox_1972_Regression models and life-tables.pdf}
}

@book{CoxEtAl:1984,
  title = {Analysis of Survival Data},
  author = {Cox, D. R. and Oakes, D.},
  date = {1984},
  series = {Monographs on Statistics and Applied Probability},
  publisher = {{Chapman \& Hall, London}}
}

@book{CramerEtAl:2004,
  title = {Stationary and Related Stochastic Processes},
  author = {Cramér, Harald and Leadbetter, M. R.},
  date = {2004},
  publisher = {{Dover Publications, Inc., Mineola, NY}}
}

@article{Crenshaw:1989,
  title = {Demarginalizing the Intersection of Race and Sex: {{A}} Black Feminist Critique of Antidiscrimination Doctrine, Feminist Theory and Antiracist Politics},
  author = {Crenshaw, Kimberlé},
  date = {1989},
  journaltitle = {University of Chicago Legal Forum},
  volume = {1989},
  pages = {139},
  keywords = {⛔ No DOI found}
}

@article{CsiszarEtAl:2004,
  title = {Information Theory and Statistics: {{A}} Tutorial},
  author = {Csiszár, Imre and Shields, Paul C},
  date = {2004},
  journaltitle = {Communications and Information Theory},
  volume = {1},
  number = {4},
  pages = {417--528},
  doi = {10/cw96hf},
  file = {D\:\\Zotero\\storage\\UKDY6LVW\\Csiszár_Shields_2004_Information theory and statistics.pdf}
}

@article{culpepperImprovedStrategyBayesian2018,
  title = {An {{Improved Strategy}} for {{Bayesian Estimation}} of the {{Reduced Reparameterized Unified Model}}},
  author = {Culpepper, Steven Andrew and Hudson, Aaron},
  date = {2018-03},
  journaltitle = {Applied Psychological Measurement},
  shortjournal = {Applied Psychological Measurement},
  volume = {42},
  number = {2},
  pages = {99--115},
  issn = {0146-6216, 1552-3497},
  doi = {10/gf9hzp},
  url = {http://journals.sagepub.com/doi/10.1177/0146621617707511},
  urldate = {2022-03-25},
  abstract = {A Bayesian formulation for a popular conjunctive cognitive diagnosis model, the reduced reparameterized unified model (rRUM), is developed. The new Bayesian formulation of the rRUM employs a latent response data augmentation strategy that yields tractable full conditional distributions. A Gibbs sampling algorithm is described to approximate the posterior distribution of the rRUM parameters. A Monte Carlo study supports accurate parameter recovery and provides evidence that the Gibbs sampler tended to converge in fewer iterations and had a larger effective sample size than a commonly employed Metropolis–Hastings algorithm. The developed method is disseminated for applied researchers as an R package titled “rRUM.”},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\5XI7T78F\\Culpepper_Hudson_2018_An Improved Strategy for Bayesian Estimation of the Reduced Reparameterized.pdf}
}

@article{dawTrialbytrialDataAnalysis2009,
  title = {Trial-by-Trial Data Analysis Using Computational Models},
  author = {Daw, Nathaniel D},
  date = {2009},
  pages = {26},
  doi = {10/c7mgpz},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\AHVHGC6I\\Daw_2009_Trial-by-trial data analysis using computational models.pdf}
}

@article{debruineFauxSimulationFactorial2021,
  title = {Faux: {{Simulation}} for {{Factorial Designs R}} Package Version 1.1.0. {{Zenodo}}},
  author = {DeBruine, Lisa},
  date = {2021},
  doi = {10.5281/zenodo.2669586},
  file = {D\:\\Zotero\\storage\\A8KGAU44\\faux.pdf}
}

@book{deFinetti:1972,
  title = {Probability, Induction and Statistics. {{The}} Art of Guessing},
  author = {de Finetti, Bruno},
  options = {useprefix=true},
  date = {1972},
  publisher = {{John Wiley \& Sons, London-New York-Sydney}}
}

@article{depaoliImportancePriorSensitivity2020,
  title = {The {{Importance}} of {{Prior Sensitivity Analysis}} in {{Bayesian Statistics}}: {{Demonstrations Using}} an {{Interactive Shiny App}}},
  author = {Depaoli, Sarah},
  date = {2020},
  journaltitle = {Frontiers in Psychology},
  volume = {11},
  pages = {18},
  doi = {10.3389/fpsyg.2020.608045},
  abstract = {The current paper highlights a new, interactive Shiny App that can be used to aid in understanding and teaching the important task of conducting a prior sensitivity analysis when implementing Bayesian estimation methods. In this paper, we discuss the importance of examining prior distributions through a sensitivity analysis. We argue that conducting a prior sensitivity analysis is equally important when so-called diffuse priors are implemented as it is with subjective priors. As a proof of concept, we conducted a small simulation study, which illustrates the impact of priors on final model estimates. The findings from the simulation study highlight the importance of conducting a sensitivity analysis of priors. This concept is further extended through an interactive Shiny App that we developed. The Shiny App allows users to explore the impact of various forms of priors using empirical data. We introduce this Shiny App and thoroughly detail an example using a simple multiple regression model that users at all levels can understand. In this paper, we highlight how to determine the different settings for a prior sensitivity analysis, how to visually and statistically compare results obtained in the sensitivity analysis, and how to display findings and write up disparate results obtained across the sensitivity analysis. The goal is that novice users can follow the process outlined here and work within the interactive Shiny App to gain a deeper understanding of the role of prior distributions and the importance of a sensitivity analysis when implementing Bayesian methods. The intended audience is broad (e.g., undergraduate or graduate students, faculty, and other researchers) and can include those with limited exposure to Bayesian methods or the specific model presented here.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\NLH3AUUC\\Depaoli - 2020 - The Importance of Prior Sensitivity Analysis in Ba.pdf}
}

@article{depaoliIntroductionBayesianStatistics2017,
  title = {An Introduction to {{Bayesian}} Statistics in Health Psychology},
  author = {Depaoli, Sarah and Rus, Holly M. and Clifton, James P. and van de Schoot, Rens and Tiemensma, Jitske},
  options = {useprefix=true},
  date = {2017-07-03},
  journaltitle = {Health Psychology Review},
  shortjournal = {Health Psychology Review},
  volume = {11},
  number = {3},
  pages = {248--264},
  issn = {1743-7199, 1743-7202},
  doi = {10/gg7hsh},
  url = {https://www.tandfonline.com/doi/full/10.1080/17437199.2017.1343676},
  urldate = {2022-03-25},
  abstract = {The aim of the current article is to provide a brief introduction to Bayesian statistics within the field of Health Psychology. Bayesian methods are increasing in prevalence in applied fields, and they have been shown in simulation research to improve the estimation accuracy of structural equation models, latent growth curve (and mixture) models, and hierarchical linear models. Likewise, Bayesian methods can be used with small sample sizes since they do not rely on large sample theory. In this article, we discuss several important components of Bayesian statistics as they relate to health-based inquiries. We discuss the incorporation and impact of prior knowledge into the estimation process and the different components of the analysis that should be reported in an article. We present an example implementing Bayesian estimation in the context of blood pressure changes after participants experienced an acute stressor. We conclude with final thoughts on the implementation of Bayesian statistics in Health Psychology, including suggestions for reviewing Bayesian manuscripts and grant proposals. We have also included an extensive amount of online supplementary material to complement the content presented here, including Bayesian examples using many different software programs and an extensive sensitivity analysis examining the impact of priors.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\84AV6V3E\\Depaoli et al_2017_An introduction to Bayesian statistics in health psychology.pdf}
}

@article{depaoliUsingBayesianStatistics2017,
  title = {Using {{Bayesian Statistics}} to {{Model Uncertainty}} in {{Mixture Models}}: {{A Sensitivity Analysis}} of {{Priors}}},
  shorttitle = {Using {{Bayesian Statistics}} to {{Model Uncertainty}} in {{Mixture Models}}},
  author = {Depaoli, Sarah and Yang, Yuzhu and Felt, John},
  date = {2017-03-04},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {24},
  number = {2},
  pages = {198--215},
  issn = {1070-5511, 1532-8007},
  doi = {10/gprpbr},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2016.1250640},
  urldate = {2022-03-25},
  abstract = {The Bayesian estimation framework has specific benefits that can aid in the estimation of mixture models. Previous research has shown that the use of priors to capture (un)certainty in latent class sizes has the potential to greatly improve estimation accuracy of a mixture model. These priors can be beneficial in mixture modeling, but proper specification is key. A sensitivity analysis of priors is essential to understand the impact of the prior on the latent classes, whether diffuse or informed priors are implemented. We illustrate a full sensitivity analysis on Dirichlet priors for the class proportions of a latent growth mixture model. We show that substantive results can (drastically) shift as the prior setting is modified, even if only slightly. Math assessment data were used from the Early Childhood Longitudinal Study–Kindergarten class. We conclude with a discussion about final model interpretations when estimates are highly influenced by prior settings.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\XD9PAJBE\\Depaoli et al_2017_Using Bayesian Statistics to Model Uncertainty in Mixture Models.pdf}
}

@article{dettweilerBayesianMixedMethodsAnalysis2017,
  title = {A {{Bayesian Mixed-Methods Analysis}} of {{Basic Psychological Needs Satisfaction}} through {{Outdoor Learning}} and {{Its Influence}} on {{Motivational Behavior}} in {{Science Class}}},
  author = {Dettweiler, Ulrich and Lauterbach, Gabriele and Becker, Christoph and Simon, Perikles},
  date = {2017-12-19},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {8},
  pages = {2235},
  issn = {1664-1078},
  doi = {10/gjjqjt},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.02235/full},
  urldate = {2022-03-25},
  abstract = {Research has shown that outdoor educational interventions can lead to students’ increased self-regulated motivational behavior. In this study, we searched into the satisfaction of basic psychological needs (BPN), i.e., autonomy support, the learners’ experience of competence, and relatedness, both within the peer group and with their teachers, through outdoor learning. From 2014 to 2016, n = 281 students attended “research weeks” at a Student Science Lab in the Alpine National Park Berchtesgaden (Germany). The program is a curriculum-based one-week residential course, centered on a 2-day research expedition. Both before and after the course, students completed a composite questionnaire addressing BPN-satisfaction and overall motivational behavior in relation to the Self-Determination Index (SDI). At the latter time-point, students also reported on their experiences during the intervention. Questionnaire data was analyzed using a set of Bayesian General Linear Models with random effects. Those quantitative measures have been complemented by and contextualized with a set of qualitative survey methods. The results showed that the basic psychological needs influence the motivational behavior in both contexts equally, however on different scale levels. The basic needs satisfaction in the outdoor context is decisively higher than indoors. Moreover, the increment of competence-experience from the school context to the hands-on outdoor program appears to have the biggest impact to students’ increased intrinsic motivation during the intervention. Increased autonomy support, student-teacher relations, and student-student relations have much less or no influence on the overall difference of motivational behavior. Gender does not influence the results. The contextualization partly supports those results and provide further explanation for the students’ increased self-regulation in the outdoors. They add some explanatory thrust to the argument that outdoor teaching, be it during a residential week, or during occasional but regular sessions as integral part of the “normal” teaching, fosters intrinsic motivational behavior in science with lower secondary students.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\UTBPZ9PW\\Dettweiler et al_2017_A Bayesian Mixed-Methods Analysis of Basic Psychological Needs Satisfaction.pdf}
}

@report{devineTutorialQuantifyingBetweenParticipant2022,
  type = {preprint},
  title = {A {{Tutorial}} for {{Quantifying Within-}} and {{Between-Participant Variance}} in {{Multilevel Logistic Models}}},
  author = {Devine, Sean and Otto, A. Ross and Uanhoro, James Ohisei and Flake, Jessica Kay},
  date = {2022-07-05},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/v68wb},
  url = {https://osf.io/v68wb},
  urldate = {2022-07-14},
  abstract = {Multilevel modeling techniques have gained traction among experimental psychologists for their ability to account for dependencies in nested data structures, such as responses nested within participants during an experiment. Increasingly, these techniques are extended to the analysis of binary data (e.g., choices, accuracy). Despite their popularity, these logistic multilevel models are often underutilized when researchers focus primarily—or solely—on fixed effects and ignore important heterogeneity that exists within and between participants, the random effects. Multilevel modeling textbooks often describe logistic multilevel models as a “simple” extension of linear models but fail to provide thorough explanations of why the variance components are difficult to estimate and interpret. In this tutorial, we review four techniques for estimating and quantifying residual- and cluster-level variance in logistic multilevel models in an accessible manner using real data. First, we introduce logistic multilevel modeling, including the interpretation of fixed and random effects. Second, we review the challenges associated with the estimation and interpretation of within- and between-participant variation in logistic multilevel models. Third, we demonstrate four existing methods of quantifying within- and betweenparticipant variation in logistic multilevel models and discuss their relative advantages and disadvantages. Fourth, we present bootstrapping methods to make statistical inference about these variance estimates. To facilitate reuse, we developed R code to implement the discussed techniques, which is provided throughout the text and as supplemental materials.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\XB38T9ZW\\Devine et al. - 2022 - A Tutorial for Quantifying Within- and Between-Par.pdf}
}

@book{Devroye:1986,
  title = {Non-Uniform Random Variate Generation},
  author = {Devroye, L},
  date = {1986},
  publisher = {{Springer-Verlag}}
}

@article{DiaconisEtAl:1980,
  title = {Finite Exchangeable Sequences},
  author = {Diaconis, P. and Freedman, D.},
  date = {1980-08},
  journaltitle = {The Annals of Probability},
  volume = {8},
  number = {4},
  pages = {745--764},
  keywords = {⛔ No DOI found}
}

@book{DiaconisEtAl:2017,
  title = {Ten Great Ideas about Chance},
  author = {Diaconis, Persi and Skyrms, Brian},
  date = {2017},
  publisher = {{Princeton University Press}}
}

@book{DoucEtAl:2018,
  title = {Markov Chains},
  author = {Douc, Randal and Moulines, Eric and Priouret, Pierre and Soulier, Philippe},
  date = {2018},
  series = {Springer Series in Operations Research and Financial Engineering},
  publisher = {{Springer, Cham}}
}

@book{DoucetEtAl:2001,
  title = {Sequential Monte Carlo Methods in Practice},
  editor = {Doucet, Arnaud and Freitas, Nando and Gordon, Neil},
  date = {2001},
  series = {Statistics for Engineering and Information Science},
  publisher = {{Springer}}
}

@article{etzBayesianInferenceTesting2018,
  title = {Bayesian {{Inference}} and {{Testing Any Hypothesis You Can Specify}}},
  author = {Etz, Alexander and Haaf, Julia M and Rouder, Jeffrey N and Vandekerckhove, Joachim},
  date = {2018},
  pages = {15},
  abstract = {Hypothesis testing is a special form of model selection. Once a pair of competing models is fully defined, their definition immediately leads to a measure of how strongly each model supports the data. The ratio of their support is often called the likelihood ratio or the Bayes factor. Critical in the model-selection endeavor is the specification of the models. In the case of hypothesis testing, it is of the greatest importance that the researcher specify exactly what is meant by a “null” hypothesis as well as the alternative to which it is contrasted, and that these are suitable instantiations of theoretical positions. Here, we provide an overview of different instantiations of null and alternative hypotheses that can be useful in practice, but in all cases the inferential procedure is based on the same underlying method of likelihood comparison. An associated app can be found at https://osf.io/mvp53/. This article is the work of the authors and is reformatted from the original, which was published under a CC-By Attribution 4.0 International license and is available at https://psyarxiv.com/wmf3r/.},
  langid = {english},
  keywords = {/unread,❓ Multiple DOI},
  file = {D\:\\Zotero\\storage\\H45M2ZMH\\Etz et al_Bayesian Inference and Testing Any Hypothesis You Can Specify.pdf}
}

@article{etzHowBecomeBayesian2018,
  title = {How to Become a {{Bayesian}} in Eight Easy Steps: {{An}} Annotated Reading List},
  shorttitle = {How to Become a {{Bayesian}} in Eight Easy Steps},
  author = {Etz, Alexander and Gronau, Quentin F. and Dablander, Fabian and Edelsbrunner, Peter A. and Baribault, Beth},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {219--234},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9mq5},
  url = {http://link.springer.com/10.3758/s13423-017-1317-5},
  urldate = {2022-03-25},
  abstract = {In this guide, we present a reading list to serve as a concise introduction to Bayesian data analysis. The introduction is geared toward reviewers, editors, and interested researchers who are new to Bayesian statistics. We provide commentary for eight recommended sources, which together cover the theoretical and practical cornerstones of Bayesian statistics in psychology and related sciences. The resources are presented in an incremental order, starting with theoretical foundations and moving on to applied issues. In addition, we outline an additional 32 articles and books that can be consulted to gain background knowledge about various theoretical specifics and Bayesian approaches to frequently used models. Our goal is to offer researchers a starting point for understanding the core tenets of Bayesian analysis, while requiring a low level of time commitment. After consulting our guide, the reader should understand how and why Bayesian methods work, and feel able to evaluate their use in the behavioral and social sciences.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\MX48PY6Z\\Etz et al_2018_How to become a Bayesian in eight easy steps.pdf}
}

@article{etzIntroductionBayesianInference2018,
  title = {Introduction to {{Bayesian Inference}} for {{Psychology}}},
  author = {Etz, Alexander and Vandekerckhove, Joachim},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {5--34},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9pqc},
  url = {http://link.springer.com/10.3758/s13423-017-1262-3},
  urldate = {2022-03-25},
  abstract = {We introduce the fundamental tenets of Bayesian inference, which derive from two basic laws of probability theory. We cover the interpretation of probabilities, discrete and continuous versions of Bayes’ rule, parameter estimation, and model comparison. Using seven worked examples, we illustrate these principles and set up some of the technical background for the rest of this special issue of Psychonomic Bulletin \& Review. Supplemental material is available via https://osf.io/wskex/.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\ZBCMCQF5\\Etz_Vandekerckhove_2018_Introduction to Bayesian Inference for Psychology.pdf}
}

@article{evansBayesFactorsLinear2018,
  title = {Bayes Factors for the Linear Ballistic Accumulator Model of Decision-Making},
  author = {Evans, Nathan J. and Brown, Scott D.},
  date = {2018-04},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {50},
  number = {2},
  pages = {589--603},
  issn = {1554-3528},
  doi = {10/gdbb72},
  url = {http://link.springer.com/10.3758/s13428-017-0887-5},
  urldate = {2022-03-25},
  abstract = {Evidence accumulation models of decision-making have led to advances in several different areas of psychology. These models provide a way to integrate response time and accuracy data, and to describe performance in terms of latent cognitive processes. Testing important psychological hypotheses using cognitive models requires a method to make inferences about different versions of the models which assume different parameters to cause observed effects. The task of model-based inference using noisy data is difficult, and has proven especially problematic with current model selection methods based on parameter estimation. We provide a method for computing Bayes factors through Monte-Carlo integration for the linear ballistic accumulator (LBA; Brown \& Heathcote, 2008), a widely used evidence accumulation model. Bayes factors are used frequently for inference with simpler statistical models, and they do not require parameter estimation. In order to overcome the computational burden of estimating Bayes factors via brute force integration, we exploit general purpose graphical processing units; we provide free code for this. This approach allows estimation of Bayes factors via Monte-Carlo integration within a practical time frame. We demonstrate the method using both simulated and real data. We investigate the stability of the Monte-Carlo approximation, and the LBA’s inferential properties, in simulation studies.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\ZTVZ3MVK\\Evans_Brown_2018_Bayes factors for the linear ballistic accumulator model of decision-making.pdf}
}

@article{faulkenberryBayesianInferenceNumerical2020,
  title = {Bayesian Inference in Numerical Cognition: {{A}} Tutorial Using {{JASP}}},
  shorttitle = {Bayesian Inference in Numerical Cognition},
  author = {Faulkenberry, Thomas J. and Ly, Alexander and Wagenmakers, Eric-Jan},
  date = {2020-09-09},
  journaltitle = {Journal of Numerical Cognition},
  shortjournal = {J. Numer. Cogn.},
  volume = {6},
  number = {2},
  pages = {231--259},
  issn = {2363-8761},
  doi = {10/gmvcj9},
  url = {https://jnc.psychopen.eu/index.php/jnc/article/view/5903},
  urldate = {2022-03-25},
  abstract = {Researchers in numerical cognition rely on hypothesis testing and parameter estimation to evaluate the evidential value of data. Though there has been increased interest in Bayesian statistics as an alternative to the classical, frequentist approach to hypothesis testing, many researchers remain hesitant to change their methods of inference. In this tutorial, we provide a concise introduction to Bayesian hypothesis testing and parameter estimation in the context of numerical cognition. Here, we focus on three examples of Bayesian inference: the t-test, linear regression, and analysis of variance. Using the free software package JASP, we provide the reader with a basic understanding of how Bayesian inference works “under the hood” as well as instructions detailing how to perform and interpret each Bayesian analysis.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\F4MXHHDJ\\Faulkenberry et al_2020_Bayesian inference in numerical cognition.pdf}
}

@book{Folland:1999,
  title = {Real Analysis: {{Modern}} Techniques and Their Applications},
  author = {Folland, G. B.},
  date = {1999},
  publisher = {{John Wiley and Sons, Inc}},
  location = {{New York}}
}

@book{Fox:2010,
  title = {Bayesian Item Response Modeling},
  author = {Fox, Jean-Paul},
  date = {2010},
  publisher = {{Springer New York}}
}

@article{fragosoBayesianModelAveraging2018,
  title = {Bayesian {{Model Averaging}}: {{A Systematic Review}} and {{Conceptual Classification}}: {{BMA}}: {{A Systematic Review}}},
  shorttitle = {Bayesian {{Model Averaging}}},
  author = {Fragoso, Tiago M. and Bertoli, Wesley and Louzada, Francisco},
  date = {2018-04},
  journaltitle = {International Statistical Review},
  shortjournal = {International Statistical Review},
  volume = {86},
  number = {1},
  pages = {1--28},
  issn = {03067734},
  doi = {10/gdfzf6},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/insr.12243},
  urldate = {2022-03-25},
  abstract = {Bayesian model averaging (BMA) provides a coherent and systematic mechanism for accounting for model uncertainty. It can be regarded as an direct application of Bayesian inference to the problem of model selection, combined estimation and prediction. BMA produces a straightforward model choice criterion and less risky predictions. However, the application of BMA is not always straightforward, leading to diverse assumptions and situational choices on its different aspects. Despite the widespread application of BMA in the literature, there were not many accounts of these differences and trends besides a few landmark revisions in the late 1990s and early 2000s, therefore not accounting for advancements made in the last decades. In this work, we present an account of these developments through a careful content analysis of 820 articles in BMA published between 1996 and 2016. We also develop a conceptual classification scheme to better describe this vast literature, understand its trends and future directions and provide guidance for the researcher interested in both the application and development of the methodology. The results of the classification scheme and content review are then used to discuss the present and future of the BMA literature.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\FQSQ9XQ4\\Fragoso et al_2018_Bayesian Model Averaging.pdf}
}

@article{francomBASSPackageFitting,
  title = {{{BASS}}: {{An R Package}} for {{Fitting}} and {{Performing Sensitivity Analysis}} of {{Bayesian Adaptive Spline Surfaces}}},
  author = {Francom, Devin and Sansó, Bruno},
  journaltitle = {Journal of Statistical Software},
  pages = {36},
  abstract = {We present the R package BASS as a tool for nonparametric regression. The primary focus of the package is fitting fully Bayesian adaptive spline surface (BASS) models and performing global sensitivity analyses of these models. The BASS framework is similar to that of Bayesian multivariate adaptive regression splines (BMARS) from Denison, Mallick, and Smith (1998), but with many added features. The software is built to efficiently handle significant amounts of data with many continuous or categorical predictors and with functional response. Under our Bayesian framework, most priors are automatic but these can be modified by the user to focus on parsimony and the avoidance of overfitting. If directed to do so, the software uses parallel tempering to improve the reversible jump Markov chain Monte Carlo (RJMCMC) methods used to perform inference. We discuss the implementation of these features and present the performance of BASS in a number of analyses of simulated and real data.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\7ENBL99K\\Francom and Sansó - BASS An R Package for Fitting and Performing Sens.pdf}
}

@report{frankeBayesianRegressionModeling2019,
  type = {preprint},
  title = {Bayesian Regression Modeling (for Factorial Designs): {{A}} Tutorial},
  shorttitle = {Bayesian Regression Modeling (for Factorial Designs)},
  author = {Franke, Michael and Roettger, Timo Benjamin},
  date = {2019-07-13},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/cdxv3},
  url = {https://osf.io/cdxv3},
  urldate = {2022-03-25},
  abstract = {Generalized linear mixed models are handy tools for statistical inference, and Bayesian approaches to applying these become increasingly popular. This tutorial provides an accessible, non-technical introduction to the use and feel of Bayesian mixed effects regression models. The focus is on data from a factorial-design experiment.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\KK4F9ZP4\\Franke_Roettger_2019_Bayesian regression modeling (for factorial designs).pdf}
}

@article{frankeHandsonNontechnicalTutorial,
  title = {Hands-on Non-Technical Tutorial for {{Bayesian}} Mixed Effects Regression},
  author = {Franke, Michael and Roettger, Timo},
  pages = {15},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\4PXWF7NW\\Franke and Roettger - Hands-on non-technical tutorial for Bayesian mixed.pdf}
}

@article{gabryVisualizationBayesianWorkflow2019,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  date = {2019-02},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  shortjournal = {J. R. Stat. Soc. A},
  volume = {182},
  number = {2},
  pages = {389--402},
  issn = {0964-1998, 1467-985X},
  doi = {10.1111/rssa.12378},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/rssa.12378},
  urldate = {2022-05-13},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\J84YGFJQ\\Gabry et al. - 2019 - Visualization in Bayesian workflow.pdf}
}

@article{Galton:1886,
  title = {Regression towards Mediocrity in Hereditary Stature.},
  author = {Galton, Francis},
  date = {1886},
  journaltitle = {The Journal of the Anthropological Institute of Great Britain and Ireland},
  volume = {15},
  pages = {246--263},
  doi = {10.2307/2841583},
  file = {D\:\\Zotero\\storage\\SF6MFWDM\\Galton_1886_Regression towards mediocrity in hereditary stature.pdf}
}

@book{Gamow:1988,
  title = {One, Two, Three... Infinity: Facts and Speculations of Science},
  author = {Gamow, George},
  date = {1988},
  publisher = {{Dover Publ.}}
}

@article{GelmanEtAl:1992,
  title = {Inference from Iterative Simulation Using Multiple Sequences},
  author = {Gelman, Andrew and Rubin, Donald B},
  date = {1992},
  journaltitle = {Statistical science},
  pages = {457--472},
  keywords = {⛔ No DOI found}
}

@book{GelmanEtAl:2014a,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  date = {2014},
  series = {Texts in Statistical Science Series},
  edition = {3},
  publisher = {{CRC Press, Boca Raton, FL}}
}

@article{GelmanEtAl:2017,
  title = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  date = {2017},
  journaltitle = {Entropy. An International and Interdisciplinary Journal of Entropy and Information Studies},
  shortjournal = {Entropy},
  volume = {19},
  number = {10},
  issn = {1099-4300},
  doi = {10.3390/e19100555},
  url = {http://www.mdpi.com/1099-4300/19/10/555},
  article = {555},
  file = {D\:\\Zotero\\storage\\HRLYRV5A\\Gelman et al_2017_The prior can often only be understood in the context of the likelihood.pdf}
}

@article{GelmanEtAl:2017a,
  title = {The Prior Can Generally Only Be Understood in the Context of the Likelihood},
  author = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
  date = {2017-08},
  keywords = {⛔ No DOI found}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian Regression Models}}},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  date = {2019-07-03},
  journaltitle = {The American Statistician},
  shortjournal = {The American Statistician},
  volume = {73},
  number = {3},
  pages = {307--309},
  issn = {0003-1305, 1537-2731},
  doi = {10/gf2hnb},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\BW5SNMNW\\Gelman et al_2019_R-squared for Bayesian Regression Models.pdf}
}

@article{gelmanStanProbabilisticProgramming2015,
  title = {Stan: {{A Probabilistic Programming Language}} for {{Bayesian Inference}} and {{Optimization}}},
  shorttitle = {Stan},
  author = {Gelman, Andrew and Lee, Daniel and Guo, Jiqiang},
  date = {2015-10},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  shortjournal = {Journal of Educational and Behavioral Statistics},
  volume = {40},
  number = {5},
  pages = {530--543},
  issn = {1076-9986, 1935-1054},
  doi = {10.3102/1076998615606113},
  url = {http://journals.sagepub.com/doi/10.3102/1076998615606113},
  urldate = {2021-09-14},
  abstract = {Stan is a free and open-source C++ program that performs Bayesian inference or optimization for arbitrary user-specified models and can be called from the command line, R, Python, Matlab, or Julia and has great promise for fitting large and complex statistical models in many areas of application. We discuss Stan from users’ and developers’ perspectives and illustrate with a simple but nontrivial nonlinear regression example.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\TBYUW3CN\\Gelman et al_2015_Stan.pdf}
}

@article{gershmanTutorialBayesianNonparametric2012,
  title = {A Tutorial on {{Bayesian}} Nonparametric Models},
  author = {Gershman, Samuel J. and Blei, David M.},
  date = {2012-02},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {56},
  number = {1},
  pages = {1--12},
  issn = {00222496},
  doi = {10/ccpxjr},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S002224961100071X},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\83XDJN2X\\Gershman_Blei_2012_A tutorial on Bayesian nonparametric models.pdf}
}

@article{gerwinnBayesianInferenceGeneralized2010,
  title = {Bayesian Inference for Generalized Linear Models for Spiking Neurons},
  author = {Gerwinn, Sebastian},
  date = {2010},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front. Comput. Neurosci.},
  volume = {4},
  issn = {16625188},
  doi = {10/b6vvn9},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2010.00012/abstract},
  urldate = {2022-03-25},
  abstract = {Generalized Linear Models (GLMs) are commonly used statistical methods for modelling the relationship between neural population activity and presented stimuli. When the dimension of the parameter space is large, strong regularization has to be used in order to fit GLMs to datasets of realistic size without overfitting. By imposing properly chosen priors over parameters, Bayesian inference provides an effective and principled approach for achieving regularization. Here we show how the posterior distribution over model parameters of GLMs can be approximated by a Gaussian using the Expectation Propagation algorithm. In this way, we obtain an estimate of the posterior mean and posterior covariance, allowing us to calculate Bayesian confidence intervals that characterize the uncertainty about the optimal solution. From the posterior we also obtain a different point estimate, namely the posterior mean as opposed to the commonly used maximum a posteriori estimate. We systematically compare the different inference techniques on simulated as well as on multi-electrode recordings of retinal ganglion cells, and explore the effects of the chosen prior and the performance measure used. We find that good performance can be achieved by choosing an Laplace prior together with the posterior mean estimate.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\QFIF4QS3\\Gerwinn_2010_Bayesian inference for generalized linear models for spiking neurons.pdf}
}

@inproceedings{Geweke:1992,
  title = {Evaluating the Accuracy of Sampling-Based Approaches to the Calculation of Posterior Moments},
  booktitle = {{{IN BAYESIAN STATISTICS}}},
  author = {Geweke, John},
  date = {1992},
  pages = {169--193},
  publisher = {{University Press}},
  keywords = {⛔ No DOI found}
}

@article{Geyer:1992,
  title = {Practical {{Markov Chain Monte Carlo}}},
  author = {Geyer, Charles J},
  date = {1992},
  journaltitle = {Statistical Science},
  pages = {473--483},
  keywords = {⛔ No DOI found}
}

@article{GneitingEtAl:2007,
  title = {Strictly Proper Scoring Rules, Prediction, and Estimation},
  author = {Gneiting, Tilmann and Raftery, Adrian E.},
  date = {2007},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {J. Amer. Statist. Assoc.},
  volume = {102},
  number = {477},
  pages = {359--378},
  doi = {10/c6758w},
  file = {D\:\\Zotero\\storage\\3RI8E7RQ\\Gneiting_Raftery_2007_Strictly proper scoring rules, prediction, and estimation.pdf}
}

@book{Good:1950,
  title = {Probability and the Weighing of Evidence},
  author = {Good, I.J.},
  date = {1950},
  publisher = {{Hafners}},
  location = {{New York}}
}

@article{Good:1953,
  title = {The Population Frequencies of Species and the Estimation of Population Parameters},
  author = {Good, I. J.},
  date = {1953},
  journaltitle = {Biometrika},
  volume = {40},
  pages = {237--264},
  keywords = {❓ Multiple DOI}
}

@article{Good:1980,
  title = {Some History of the Hierarchical {{Bayesian}} Methodology},
  author = {Good, I. J.},
  date = {1980},
  journaltitle = {Trabajos de Estadistica Y de Investigacion Operativa},
  volume = {31},
  number = {1},
  pages = {489},
  doi = {10/fbqc99},
  file = {D\:\\Zotero\\storage\\XWSCEUNF\\Good_1980_Some history of the hierarchical Bayesian methodology.pdf}
}

@book{Good:1983,
  title = {Good Thinking},
  author = {Good, Irving John},
  date = {1983},
  publisher = {{University of Minnesota Press, Minneapolis, MN}}
}

@article{goodBayesNonBayesCompromise1992,
  title = {The {{Bayes}}/{{Non-Bayes Compromise}}: {{A Brief Review}}},
  shorttitle = {The {{Bayes}}/{{Non-Bayes Compromise}}},
  author = {Good, I. J.},
  date = {1992-09},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {87},
  number = {419},
  pages = {597--606},
  issn = {0162-1459, 1537-274X},
  doi = {10/gprpf2},
  url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1992.10475256},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\C5QDED7P\\Good_1992_The Bayes-Non-Bayes Compromise.pdf}
}

@inproceedings{GoodfellowEtAl:2014,
  title = {Generative Adversarial Nets},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. and Weinberger, K. Q.},
  date = {2014},
  volume = {27},
  publisher = {{Curran Associates, Inc.}},
  keywords = {⛔ No DOI found}
}

@inproceedings{GorhamEtAl:2017,
  title = {Measuring Sample Quality with Kernels},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  author = {Gorham, Jackson and Mackey, Lester},
  date = {2017},
  pages = {1292--1301},
  organization = {{JMLR. org}},
  keywords = {⛔ No DOI found}
}

@article{GorinovaEtAl:2019,
  title = {Automatic Reparameterisation of Probabilistic Programs},
  author = {Gorinova, Maria I. and Moore, Dave and Hoffman, Matthew D.},
  date = {2019-06},
  keywords = {⛔ No DOI found}
}

@article{grangeComputationalModellingSpeed2022,
  title = {Computational Modelling of the Speed–Accuracy Tradeoff: {{No}} Evidence for an Association with Depression Symptomatology},
  shorttitle = {Computational Modelling of the Speed–Accuracy Tradeoff},
  author = {Grange, James A.},
  date = {2022-03},
  journaltitle = {Journal of Psychiatric Research},
  shortjournal = {Journal of Psychiatric Research},
  volume = {147},
  pages = {111--125},
  issn = {00223956},
  doi = {10/gpwszf},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022395621007688},
  urldate = {2022-04-16},
  abstract = {Successful decision making often requires finding the right balance between the speed and accuracy of responding: Emphasising speed can lead to error-prone performance, yet emphasising accuracy leads to a slowing of performance. Such speed–accuracy tradeoffs (SATs) therefore require establishing appropriate response set­ tings to optimise performance in response to changing environmental demands. Such strategic adaptation of response settings relies on the striatum component of the basal ganglia, an area implicated in depression. The current study explored the association between depression symptomatology and SAT performance. Two exper­ iments presented participants with an SAT paradigm embedded within a simple decision-making task, together with measures of depression symptomatology. Experiment 1 (N = 349) was correlational, whereas Experiment 2 was a two-phase experiment where participants (N = 501) were first pre-screened on depression symptom­ atology and extreme-low and extreme-high responders (total N = 91) were invited to Phase 2. Behavioural data were modelled with a drift diffusion model. Behavioural data and associated diffusion modelling showed large and robust SAT effects. Emphasising accuracy led to an increase in boundary separation, an increase in drift rate, and an increase in non-decision time. However, the magnitude of the changes of these parameters with SAT instructions was not associated with measures of depression symptomatology. The results suggest that the strategic adaptation of response settings in response to environmental changes in speed–accuracy instructions does not appear to be associated with depression symptomatology.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\2HGEJYAH\\Grange - 2022 - Computational modelling of the speed–accuracy trad.pdf}
}

@article{greenhillBayesianOptimizationAdaptive2020,
  title = {Bayesian {{Optimization}} for {{Adaptive Experimental Design}}: {{A Review}}},
  shorttitle = {Bayesian {{Optimization}} for {{Adaptive Experimental Design}}},
  author = {Greenhill, Stewart and Rana, Santu and Gupta, Sunil and Vellanki, Pratibha and Venkatesh, Svetha},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {13937--13948},
  issn = {2169-3536},
  doi = {10/gmmwqk},
  url = {https://ieeexplore.ieee.org/document/8957442/},
  urldate = {2022-03-25},
  abstract = {Bayesian optimisation is a statistical method that efficiently models and optimises expensive ‘‘black-box’’ functions. This review considers the application of Bayesian optimisation to experimental design, in comparison to existing Design of Experiments (DOE) methods. Solutions are surveyed for a range of core issues in experimental design including: the incorporation of prior knowledge, high dimensional optimisation, constraints, batch evaluation, multiple objectives, multi-fidelity data, and mixed variable types.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\IICV56X5\\Greenhill et al_2020_Bayesian Optimization for Adaptive Experimental Design.pdf}
}

@article{greenSIMRPackagePower2016,
  title = {{{{\textsc{SIMR}}}} : An {{R}} Package for Power Analysis of Generalized Linear Mixed Models by Simulation},
  author = {Green, Peter and MacLeod, Catriona J.},
  editor = {Nakagawa, Shinichi},
  date = {2016-04},
  journaltitle = {Methods in Ecology and Evolution},
  shortjournal = {Methods Ecol Evol},
  volume = {7},
  number = {4},
  pages = {493--498},
  issn = {2041-210X, 2041-210X},
  doi = {10.1111/2041-210X.12504},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12504},
  urldate = {2022-08-31},
  langid = {english},
  file = {D\:\\Zotero\\storage\\8RMWNJZV\\green2016.pdf.pdf;D\:\\Zotero\\storage\\B6VYM4UJ\\Green and MacLeod - 2016 - SIMR.pdf}
}

@article{grezesImpactTotalSleep2021,
  title = {Impact of Total Sleep Deprivation and Related Mood Changes on Approach-Avoidance Decisions to Threat-Related Facial Displays},
  author = {Grèzes, Julie and Erblang, Mégane and Vilarem, Emma and Quiquempoix, Michael and Van Beers, Pascal and Guillard, Mathias and Sauvet, Fabien and Mennella, Rocco and Rabat, Arnaud},
  date = {2021-12-10},
  journaltitle = {Sleep},
  volume = {44},
  number = {12},
  pages = {zsab186},
  issn = {0161-8105, 1550-9109},
  doi = {10/gpwrx6},
  url = {https://academic.oup.com/sleep/article/doi/10.1093/sleep/zsab186/6329135},
  urldate = {2022-04-16},
  abstract = {Methods:\hspace{0.6em} Participants (n = 34) made spontaneous approach/avoidance decisions in the presence of task-irrelevant angry or fearful individuals, while rested or totally sleep deprived (27 h of continuous wakefulness). Sleep-related changes in mood and sustained attention were assessed using the Positive and Negative Affective Scale and the psychomotor vigilance task, respectively. Results:\hspace{0.6em} Rested participants avoided both fearful and angry individuals, with stronger avoidance for angry individuals, in line with previous results. On the contrary, totally sleep deprived participants favored neither approach nor avoidance of fearful individuals, while they still comparably avoided angry individuals. Driftdiffusion models showed that this effect was accounted for by the fact that total sleep deprivation reduced value-based evidence accumulation toward avoidance during decision making. Finally, the reduction of positive mood after total sleep deprivation positively correlated with the reduction of fearful display avoidance. Importantly, this correlation was not mediated by a sleep-related reduction in sustained attention. Conclusions:\hspace{0.6em} All together, these findings support the underestimated role of positive mood-state alterations caused by total sleep loss on approach/avoidance decisions when facing ambiguous socio-emotional displays, such as fear.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\ARYWEDDJ\\Grèzes et al. - 2021 - Impact of total sleep deprivation and related mood.pdf}
}

@article{gronauSimpleMethodComparing2019,
  title = {A {{Simple Method}} for {{Comparing Complex Models}}: {{Bayesian Model Comparison}} for {{Hierarchical Multinomial Processing Tree Models Using Warp-III Bridge Sampling}}},
  shorttitle = {A {{Simple Method}} for {{Comparing Complex Models}}},
  author = {Gronau, Quentin F. and Wagenmakers, Eric-Jan and Heck, Daniel W. and Matzke, Dora},
  date = {2019-03},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {84},
  number = {1},
  pages = {261--284},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-018-9648-3},
  url = {http://link.springer.com/10.1007/s11336-018-9648-3},
  urldate = {2022-03-25},
  abstract = {Multinomial processing trees (MPTs) are a popular class of cognitive models for categorical data. Typically, researchers compare several MPTs, each equipped with many parameters, especially when the models are implemented in a hierarchical framework. A Bayesian solution is to compute posterior model probabilities and Bayes factors. Both quantities, however, rely on the marginal likelihood, a highdimensional integral that cannot be evaluated analytically. In this case study, we show how Warp-III bridge sampling can be used to compute the marginal likelihood for hierarchical MPTs. We illustrate the procedure with two published data sets and demonstrate how Warp-III facilitates Bayesian model averaging.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\LYVJ6HWK\\Gronau et al_2019_A Simple Method for Comparing Complex Models.pdf}
}

@article{hainesAnxietyModulatesPreference2020,
  title = {Anxiety {{Modulates Preference}} for {{Immediate Rewards Among Trait-Impulsive Individuals}}: {{A Hierarchical Bayesian Analysis}}},
  shorttitle = {Anxiety {{Modulates Preference}} for {{Immediate Rewards Among Trait-Impulsive Individuals}}},
  author = {Haines, Nathaniel and Beauchaine, Theodore P. and Galdo, Matthew and Rogers, Andrew H. and Hahn, Hunter and Pitt, Mark A. and Myung, Jay I. and Turner, Brandon M. and Ahn, Woo-Young},
  date = {2020-11},
  journaltitle = {Clinical Psychological Science},
  shortjournal = {Clinical Psychological Science},
  volume = {8},
  number = {6},
  pages = {1017--1036},
  issn = {2167-7026, 2167-7034},
  doi = {10.1177/2167702620929636},
  url = {http://journals.sagepub.com/doi/10.1177/2167702620929636},
  urldate = {2021-09-14},
  abstract = {Trait impulsivity—defined by strong preference for immediate over delayed rewards and difficulties inhibiting prepotent behaviors—is observed in all externalizing disorders, including substance-use disorders. Many laboratory tasks have been developed to identify decision-making mechanisms and correlates of impulsive behavior, but convergence between task measures and self-reports of impulsivity are consistently low. Long-standing theories of personality and decisionmaking predict that neurally mediated individual differences in sensitivity to (a) reward cues and (b) punishment cues (frustrative nonreward) interact to affect behavior. Such interactions obscure one-to-one correspondences between single personality traits and task performance. We used hierarchical Bayesian analysis in three samples with differing levels of substance use (N = 967) to identify interactive dependencies between trait impulsivity and state anxiety on impulsive decision-making. Our findings reveal how anxiety modulates impulsive decision-making and demonstrate benefits of hierarchical Bayesian analysis over traditional approaches for testing theories of psychopathology spanning levels of analysis.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\2GH7XASA\\Haines et al. - 2020 - Anxiety Modulates Preference for Immediate Rewards.pdf;D\:\\Zotero\\storage\\XH7LVF2P\\Haines et al_2020_Anxiety Modulates Preference for Immediate Rewards Among Trait-Impulsive.pdf}
}

@article{hallDisentanglingCognitiveProcesses2021,
  title = {Disentangling Cognitive Processes in Externalizing Psychopathology Using Drift Diffusion Modeling: {{Antagonism}}, but Not Disinhibition, Is Associated with Poor Cognitive Control},
  shorttitle = {Disentangling Cognitive Processes in Externalizing Psychopathology Using Drift Diffusion Modeling},
  author = {Hall, Nathan T. and Schreiber, Alison M. and Allen, Timothy A. and Hallquist, Michael N.},
  date = {2021-10},
  journaltitle = {Journal of Personality},
  shortjournal = {J Pers},
  volume = {89},
  number = {5},
  pages = {970--985},
  issn = {0022-3506, 1467-6494},
  doi = {10/gh4hzj},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/jopy.12628},
  urldate = {2022-04-16},
  abstract = {Although externalizing psychopathology has been linked to deficits in cognitive control, the cognitive processes underlying this association are unclear. Here, we provide a theoretical account of how research on cognitive processes can help to integrate and distinguish personality and psychopathology. We then apply this account to connect the two major subcomponents of externalizing, Antagonism and Disinhibition, with specific control processes using a battery of inhibitory control tasks and corresponding computational modeling. Participants (final N = 104) completed the flanker, go/ no-­go, and recent probes tasks, as well as normal and maladaptive personality inventories and measures of psychological distress. We fit participants' task behavior using a hierarchical drift diffusion model (DDM) to decompose their responses into specific cognitive processes. Using multilevel structural equation models, we found that Antagonism was associated with faster RTs on the flanker task and lower accuracy on flanker and go/no-g­ o tasks. These results were complemented by DDM parameter associations: Antagonism was linked to decreased threshold and drift rate parameter estimates in the flanker task and a decreased drift rate on no-­go trials. Altogether, our findings indicate that Antagonism is associated with specific impairments in fast (sub-­second) inhibitory control processes involved in withholding prepared/prepotent responses and filtering distracting information. Disinhibition and momentary distress, however, were not associated with task performance.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\GVCMSGGR\\Hall et al. - 2021 - Disentangling cognitive processes in externalizing.pdf;D\:\\Zotero\\storage\\VMQIF26H\\Hall et al. - 2021 - Disentangling cognitive processes in externalizing.pdf}
}

@article{Halphen:1941,
  title = {Sur Un Nouveau Type de Courbe de Fréquence},
  author = {Halphen, E},
  date = {1941},
  journaltitle = {Comptes Rendus de l'Académie des Sciences},
  volume = {213},
  pages = {633--635},
  keywords = {⛔ No DOI found}
}

@article{hanExploringAssociationCompliance2021,
  title = {Exploring the Association between Compliance with Measures to Prevent the Spread of {{COVID-19}} and Big Five Traits with {{Bayesian}} Generalized Linear Model},
  author = {Han, Hyemin},
  date = {2021-07},
  journaltitle = {Personality and Individual Differences},
  shortjournal = {Personality and Individual Differences},
  volume = {176},
  pages = {110787},
  issn = {01918869},
  doi = {10/gmf7gr},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0191886921001628},
  urldate = {2022-03-25},
  abstract = {Research has examined the association between people’s compliance with measures to prevent the spread of COVID-19 and personality traits. However, previous studies were conducted with relatively small-size datasets and employed frequentist analysis that does not allow data-driven model exploration. To address the limitations, a large-scale international dataset, COVIDiSTRESS Global Survey dataset, was explored with Bayesian general­ ized linear model that enables identification of the best regression model. The best regression models predicting participants’ compliance with Big Five traits were explored. The findings demonstrated first, all Big Five traits, except extroversion, were positively associated with compliance with general measures and distancing. Second, neuroticism, extroversion, and agreeableness were positively associated with the perceived cost of complying with the measures while conscientiousness showed negative association. The findings and the implications of the present study were discussed.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\RLMB3YW2\\Han_2021_Exploring the association between compliance with measures to prevent the.pdf}
}

@article{harrisBayesianModelSelection2018,
  title = {Bayesian {{Model Selection Maps}} for {{Group Studies Using M}}/{{EEG Data}}},
  author = {Harris, Clare D},
  date = {2018},
  journaltitle = {Frontiers in Neuroscience},
  volume = {12},
  pages = {12},
  doi = {10.3389/fnins.2018.00598},
  abstract = {Predictive coding postulates that we make (top-down) predictions about the world and that we continuously compare incoming (bottom-up) sensory information with these predictions, in order to update our models and perception so as to better reflect reality. That is, our so-called “Bayesian brains” continuously create and update generative models of the world, inferring (hidden) causes from (sensory) consequences. Neuroimaging datasets enable the detailed investigation of such modeling and updating processes, and these datasets can themselves be analyzed with Bayesian approaches. These offer methodological advantages over classical statistics. Specifically, any number of models can be compared, the models need not be nested, and the “null model” can be accepted (rather than only failing to be rejected as in frequentist inference). This methodological paper explains how to construct posterior probability maps (PPMs) for Bayesian Model Selection (BMS) at the group level using electroencephalography (EEG) or magnetoencephalography (MEG) data. The method has only recently been used for EEG data, after originally being developed and applied in the context of functional magnetic resonance imaging (fMRI) analysis. Here, we describe how this method can be adapted for EEG using the Statistical Parametric Mapping (SPM) software package for MATLAB. The method enables the comparison of an arbitrary number of hypotheses (or explanations for observed responses), at each and every voxel in the brain (source level) and/or in the scalp-time volume (scalp level), both within participants and at the group level. The method is illustrated here using mismatch negativity (MMN) data from a group of participants performing an audio-spatial oddball attention task. All data and code are provided in keeping with the Open Science movement. In doing so, we hope to enable others in the field of M/EEG to implement our methods so as to address their own questions of interest.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\SSQ85YHN\\Harris_2018_Bayesian Model Selection Maps for Group Studies Using M-EEG Data.pdf}
}

@article{heatonBayesianComputationLinear2009,
  title = {Bayesian {{Computation}} and the {{Linear Model}}},
  author = {Heaton, Matthew J and Scott, James G},
  date = {2009},
  pages = {23},
  abstract = {This paper is a review of computational strategies for Bayesian shrinkage and variable selection in the linear model. Our focus is less on traditional MCMC methods, which are covered in depth by earlier review papers. Instead, we focus more on recent innovations in stochastic search and adaptive MCMC, along with some comparatively new research on shrinkage priors. One of our conclusions is that true MCMC seems inferior to stochastic search if one’s goal is to discover good models, but that stochastic search can result in biased estimates of variable inclusion probabilities. We also find reasons to question the accuracy of inclusion probabilities generated by traditional MCMC on high-dimensional, nonorthogonal problems, though the matter is far from settled.},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\5ESLET8L\\Heaton_Scott_2009_Bayesian Computation and the Linear Model.pdf}
}

@article{heckCaveatSavageDickey2019,
  title = {A Caveat on the {{Savage}}–{{Dickey}} Density Ratio: {{The}} Case of Computing {{Bayes}} Factors for Regression Parameters},
  shorttitle = {A Caveat on the {{Savage}}–{{Dickey}} Density Ratio},
  author = {Heck, Daniel W.},
  date = {2019-05},
  journaltitle = {British Journal of Mathematical and Statistical Psychology},
  shortjournal = {Br J Math Stat Psychol},
  volume = {72},
  number = {2},
  pages = {316--333},
  issn = {0007-1102, 2044-8317},
  doi = {10/gk4zsz},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/bmsp.12150},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\VFQYLG59\\Heck_2019_A caveat on the Savage–Dickey density ratio.pdf}
}

@article{heckReviewApplicationsBayes2022,
  title = {A Review of Applications of the {{Bayes}} Factor in Psychological Research},
  author = {Heck, Daniel W. and Boehm, Udo and Böing-Messing, Florian and Bürkner, Paul-Christian and Derks, Koen and Dienes, Zoltan and Fu, Qianrao and Gu, Xin and Karimova, Diana and Kiers, Henk A. L. and Klugkist, Irene and Kuiper, Rebecca M. and Lee, Michael D. and Leenders, Roger and Leplaa, Hidde J. and Linde, Maximilian and Ly, Alexander and Meijerink-Bosman, Marlyne and Moerbeek, Mirjam and Mulder, Joris and Palfi, Bence and Schönbrodt, Felix D. and Tendeiro, Jorge N. and van den Bergh, Don and Van Lissa, Caspar J. and van Ravenzwaaij, Don and Vanpaemel, Wolf and Wagenmakers, Eric-Jan and Williams, Donald R. and Zondervan-Zwijnenburg, Mariëlle and Hoijtink, Herbert},
  options = {useprefix=true},
  date = {2022-03-17},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  issn = {1939-1463, 1082-989X},
  doi = {10/gprs76},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000454},
  urldate = {2022-03-26},
  abstract = {The last 25 years have shown a steady increase in attention for the Bayes factor as a tool for hypothesis evaluation and model selection. The present review highlights the potential of the Bayes factor in psychological research. We discuss six types of applications: Bayesian evaluation of point null, interval, and informative hypotheses, Bayesian evidence synthesis, Bayesian variable selection and model averaging, and Bayesian evaluation of cognitive models. We elaborate what each application entails, give illustrative examples, and provide an overview of key references and software with links to other applications. The paper is concluded with a discussion of the opportunities and pitfalls of Bayes factor applications and a sketch of corresponding future research lines.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\2Q2LSPEI\\Heck et al_2022_A review of applications of the Bayes factor in psychological research.pdf}
}

@article{HillEtAl:2020,
  title = {Bayesian Additive Regression Trees: {{A}} Review and Look Forward},
  author = {Hill, Jennifer and Linero, Antonio and Murray, Jared},
  date = {2020},
  journaltitle = {Annual Review of Statistics and Its Application},
  volume = {7},
  number = {1},
  pages = {251--278},
  doi = {10.1146/annurev-statistics-031219-041110},
  file = {D\:\\Zotero\\storage\\W53XK7YR\\Hill et al_2020_Bayesian additive regression trees.pdf}
}

@article{hoijtinkTutorialTestingHypotheses2019,
  title = {A Tutorial on Testing Hypotheses Using the {{Bayes}} Factor},
  author = {Hoijtink, Herbert and Mulder, Joris and van Lissa, Caspar and Gu, Xin},
  options = {useprefix=true},
  date = {2019-10},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {24},
  number = {5},
  pages = {539--556},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000201},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000201},
  urldate = {2021-10-09},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\I34D4BJV\\Tutorial5.zip;D\:\\Zotero\\storage\\XZNCFJJ5\\Hoijtink et al_2019_A tutorial on testing hypotheses using the Bayes factor.pdf}
}

@article{holmesBayesianAnalysisPiecewise2018,
  title = {Bayesian Analysis of the Piecewise Diffusion Decision Model},
  author = {Holmes, William R. and Trueblood, Jennifer S.},
  date = {2018-04},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {50},
  number = {2},
  pages = {730--743},
  issn = {1554-3528},
  doi = {10/gdbfdm},
  url = {http://link.springer.com/10.3758/s13428-017-0901-y},
  urldate = {2022-03-25},
  abstract = {Most past research on sequential sampling models of decision-making have assumed a time homogeneous process (i.e., parameters such as drift rates and boundaries are constant and do not change during the deliberation process). This has largely been due to the theoretical difficulty in testing and fitting more complex models. In recent years, the development of simulation-based modeling approaches matched with Bayesian fitting methodologies has opened the possibility of developing more complex models such as those with time-varying properties. In the present work, we discuss a piecewise variant of the well-studied diffusion decision model (termed pDDM) that allows evidence accumulation rates to change during the deliberation process. Given the complex, time-varying nature of this model, standard Bayesian parameter estimation methodologies cannot be used to fit the model. To overcome this, we apply a recently developed simulation-based, hierarchal Bayesian methodology called the probability density approximation (PDA) method. We provide an analysis of this methodology and present results of parameter recovery experiments to demonstrate the strengths and limitations of this approach. With those established, we fit pDDM to data from a perceptual experiment where information changes during the course of trials. This extensible modeling platform opens the possibility of applying sequential sampling models to a range of complex non-stationary decision tasks.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\MGGPAU2K\\Holmes_Trueblood_2018_Bayesian analysis of the piecewise diffusion decision model.pdf}
}

@book{HosmerEtAl:2008,
  title = {Applied Survival Analysis: {{Regression}} Modeling of Time-to-Event Data},
  author = {Hosmer, D.W. and Lemeshow, S. and May, S.},
  date = {2008},
  series = {Wiley Series in Probability and Statistics},
  publisher = {{Wiley}}
}

@article{houptHierarchicalBayesianApproach2017,
  title = {A Hierarchical {{Bayesian}} Approach to Distinguishing Serial and Parallel Processing},
  author = {Houpt, Joseph W. and Fifić, Mario},
  date = {2017-08},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {79},
  pages = {13--22},
  issn = {00222496},
  doi = {10.1016/j.jmp.2017.05.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249617301037},
  urldate = {2022-03-25},
  abstract = {Research in cognitive psychology often focuses on how people deal with multiple sources of information. One important aspect of this research is whether people use the information in parallel (at the same time) or in series (one at a time). Various approaches to distinguishing parallel and serial processing have been proposed, but many do not satisfactorily address the mimicking dilemma between serial and parallel classes of models. The mean interaction contrast (MIC) is one measure designed to improve discriminability of serial–parallel model properties. The MIC has been applied in limited settings because the measure required a large number of trials and lacked a mechanism for group level inferences. We address these shortcomings by using hierarchical Bayesian analyses. The combination of the MIC with hierarchical Bayesian modeling gives a powerful method for distinguishing serial and parallel processing at both individual and group levels, even with a limited number of participants and trials.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\93RWV72L\\Houpt_Fifić_2017_A hierarchical Bayesian approach to distinguishing serial and parallel.pdf}
}

@article{hoxMultilevelAnalysisTechniques,
  title = {Multilevel {{Analysis}}: {{Techniques}} and {{Applications}}},
  author = {Hox, Joop J},
  pages = {364},
  doi = {10/dt37},
  langid = {english},
  keywords = {/unread,book,I 级文献},
  file = {D\:\\Zotero\\storage\\5D56FZLI\\Hox_Multilevel Analysis.pdf}
}

@article{huBayesFactorIts2018,
  title = {The Bayes factor and its implementation in JASP: A practical primer},
  shorttitle = {The Bayes factor and its implementation in JASP},
  author = {Hu, Chuan-Peng and Kong, Xiang-Zhen and Eric-Jan, Wagenmakers and Alexander, Ly and Peng, Kaiping},
  date = {2018},
  journaltitle = {Advances in Psychological Science},
  shortjournal = {Advances in Psychological Science},
  volume = {26},
  number = {6},
  pages = {951},
  issn = {1671-3710},
  doi = {10.3724/SP.J.1042.2018.00951},
  url = {http://journal.psych.ac.cn/xlkxjz/CN/10.3724/SP.J.1042.2018.00951},
  urldate = {2022-04-26},
  langid = {chinese},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\F8BSA32B\\Hu et al. - 2018 - The Bayes factor and its implementation in JASP A.pdf}
}

@article{HugginsEtAl:2019,
  title = {Practical Posterior Error Bounds from Variational Objectives},
  author = {Huggins, Jonathan H. and Kasprzak, Mikołaj and Campbell, Trevor and Broderick, Tamara},
  date = {2019-10},
  keywords = {⛔ No DOI found}
}

@book{IbrahimEtAl:2001,
  title = {Bayesian Survival Analysis},
  author = {Ibrahim, Joseph G. and Chen, Ming-Hui and Sinha, Debajyoti},
  date = {2001},
  publisher = {{Springer New York}}
}

@article{ibrahimMissingDataMethodsGeneralized2005,
  title = {Missing-{{Data Methods}} for {{Generalized Linear Models}}: {{A Comparative Review}}},
  shorttitle = {Missing-{{Data Methods}} for {{Generalized Linear Models}}},
  author = {Ibrahim, Joseph G and Chen, Ming-Hui and Lipsitz, Stuart R and Herring, Amy H},
  date = {2005-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {100},
  number = {469},
  pages = {332--346},
  issn = {0162-1459, 1537-274X},
  doi = {10/dgktr4},
  url = {http://www.tandfonline.com/doi/abs/10.1198/016214504000001844},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\NI35L95N\\Ibrahim et al_2005_Missing-Data Methods for Generalized Linear Models.pdf}
}

@article{ImpactDepressionCooperation2020,
  title = {Impact of Depression on Cooperation: {{An fNIRS}} Hyperscanning Study},
  shorttitle = {Impact of Depression on Cooperation},
  date = {2020},
  journaltitle = {Acta Psychologica Sinica},
  shortjournal = {Acta Psychologica Sinica},
  volume = {52},
  number = {5},
  pages = {609},
  issn = {0439-755X},
  doi = {10/gpwsxk},
  url = {http://journal.psych.ac.cn/xlxb/EN/10.3724/SP.J.1041.2020.00609},
  urldate = {2022-04-16},
  abstract = {Cooperation is a prosocial behavior that develops along with human social development. Cooperation involves brain activation of the reward system and enables people to form cooperative relationships so as to pursuit social rewards and self-affirmation. Previous studies have shown that depressed patients have severe social dysfunctions, e.g., they have reduced willingness to cooperate and exhibited increased negative emotions during cooperation. This study employed the prisoner’s dilemma game (PDG) to investigate the effect of depression on social cooperation using functional near-infrared spectroscopy (fNIRS) hyper scanning technique. A total of 156 participants were screened using Beck Depression Inventory Second Edition and were allocated into three paired groups, i.e., low-low depressive tendency pairs (n = 26), low-high depressive tendency pairs (n = 26), and high-high depressive tendency pairs (n = 26). The fNIRS optrodes were placed at frontal and right temporoparietal junction of two participants, with 29 channels in each participant. Behavioral and self-reported emotion ratings showed that compared to participants with low depressive tendency, the high depressive tendency group was less cooperative and less satisfied with their partner during the prisoner’s dilemma task. The brain imaging results showed that, first, the orbitofrontal cortex (OFC) was activated the most significantly in the reciprocal cooperation condition, followed by the condition with self defection but opponent cooperation. Furthermore, the significantly increased neural activation in these two conditions could only be observed in the low depressive tendency group. This finding suggests that people with high depressive tendency have deficits in reward processing, especially in social reward processing. Second, the neural activation of bilateral dorsolateral prefrontal cortex (dlPFC) in participants with high depressive tendency was significantly weaker than that of participants with low depressive tendency. Depressive tendency had a significant modulation effect on inter-brain synchronization of the right dlPFC, i.e., the enhanced inter-brain synchronization induced by reciprocal cooperation could not be observed in participants with high depressive tendency. Third, the right temporoparietal junction (TPJ) inter-brain synchronization in the low-low depressive tendency group was higher than that in the high-high and high-low depressive tendency groups. Furthermore, this effect was significant only if both participants in the PDG made the same choice (both cooperation or both defection). The result of this study suggests that depressive population has dysfunctions in the brain regions involved in social reward processing (reflected by the OFC), conflict control (reflected by the dlPFC) and theory of mind (reflected by the right TPJ). Our findings provide experimental evidence to help understand the brain mechanism of decreased cooperation in depressed individuals, which further lays a foundation to improve social functions in depressed patients in clinical practice.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\D38HVB7V\\2020 - Impact of depression on cooperation An fNIRS hype.pdf}
}

@article{iyerProbingRelationshipsReinforcement2020,
  title = {Probing Relationships between Reinforcement Learning and Simple Behavioral Strategies to Understand Probabilistic Reward Learning},
  author = {Iyer, Eshaan S. and Kairiss, Megan A. and Liu, Adrian and Otto, A. Ross and Bagot, Rosemary C.},
  date = {2020-07},
  journaltitle = {Journal of Neuroscience Methods},
  shortjournal = {Journal of Neuroscience Methods},
  volume = {341},
  pages = {108777},
  issn = {01650270},
  doi = {10.1016/j.jneumeth.2020.108777},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027020302004},
  urldate = {2022-03-26},
  abstract = {Background: Reinforcement learning (RL) and win stay/lose shift model accounts of decision making are both widely used to describe how individuals learn about and interact with rewarding environments. Though mutually informative, these accounts are often conceptualized as independent processes and so the potential relationships between win stay/lose shift tendencies and RL parameters have not been explored. New method: We introduce a methodology to directly relate RL parameters to behavioral strategy. Specifically, by calculating a truncated multivariate normal distribution of RL parameters given win stay/lose shift tendencies from simulating these tendencies across the parameter space, we maximize the normal distribution for a given set of win stay/lose shift tendencies to approximate reinforcement learning parameters. Results: We demonstrate novel relationships between win stay/lose shift tendencies and RL parameters that challenge conventional interpretations of lose shift as a metric of loss sensitivity. Further, we demonstrate in both simulated and empirical data that this method of parameter approximation yields reliable parameter recovery. Comparison with existing method: We compare this method against the conventionally used maximum likelihood estimation method for parameter approximation in simulated noisy and empirical data. For simulated noisy data, we show that this method performs similarly to maximum likelihood estimation. For empirical data, however, this method provides a more reliable approximation of reinforcement learning parameters than maximum likelihood estimation. Conclusions: We demonstrate the existence of relationships between win stay/lose shift tendencies and RL parameters and introduce a method that leverages these relationships to enable recovery of RL parameters exclusively from win stay/lose shift tendencies.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\FDNKPRXT\\Iyer et al_2020_Probing relationships between reinforcement learning and simple behavioral.pdf}
}

@article{jacobsBayesianLearningTheory2011,
  title = {Bayesian Learning Theory Applied to Human Cognition},
  author = {Jacobs, Robert A. and Kruschke, John K.},
  date = {2011-01},
  journaltitle = {WIREs Cognitive Science},
  shortjournal = {WIREs Cogn Sci},
  volume = {2},
  number = {1},
  pages = {8--21},
  issn = {1939-5078, 1939-5086},
  doi = {10/ctxk27},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/wcs.80},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\9EC5RLCJ\\Jacobs_Kruschke_2011_Bayesian learning theory applied to human cognition.pdf}
}

@book{Jaynes:2003,
  title = {Probability Theory: {{The}} Logic of Science},
  author = {Jaynes, E. T.},
  date = {2003},
  publisher = {{Cambridge University Press}}
}

@article{jiangBayesianModelingFlexible2014,
  title = {Bayesian Modeling of Flexible Cognitive Control},
  author = {Jiang, Jiefeng and Heller, Katherine and Egner, Tobias},
  date = {2014-10},
  journaltitle = {Neuroscience \& Biobehavioral Reviews},
  shortjournal = {Neuroscience \& Biobehavioral Reviews},
  volume = {46},
  pages = {30--43},
  issn = {01497634},
  doi = {10/bb6s},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763414001390},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\GNDUTYHV\\Jiang et al_2014_Bayesian modeling of flexible cognitive control.pdf}
}

@article{jiangUsingHamiltonianMonte2019,
  title = {Using {{Hamiltonian Monte Carlo}} to Estimate the Log-Linear Cognitive Diagnosis Model via {{Stan}}},
  author = {Jiang, Zhehan and Carter, Richard},
  date = {2019-04},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {51},
  number = {2},
  pages = {651--662},
  issn = {1554-3528},
  doi = {10/gprpbf},
  url = {http://link.springer.com/10.3758/s13428-018-1069-9},
  urldate = {2022-03-25},
  abstract = {The Bayesian literature has shown that the Hamiltonian Monte Carlo (HMC) algorithm is powerful and efficient for statistical model estimation, especially for complicated models. Stan, a software program built upon HMC, has been introduced as a means of psychometric modeling estimation. However, there are no systemic guidelines for implementing Stan with the log-linear cognitive diagnosis model (LCDM), which is the saturated version of many cognitive diagnostic model (CDM) variants. This article bridges the gap between Stan application and Bayesian LCDM estimation: Both the modeling procedures and Stan code are demonstrated in detail, such that this strategy can be extended to other CDMs straightforwardly.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\QKBWYI4K\\Jiang_Carter_2019_Using Hamiltonian Monte Carlo to estimate the log-linear cognitive diagnosis.pdf}
}

@book{Jorgensen:1982,
  title = {Statistical Properties of the Generalized Inverse {{Gaussian}} Distribution},
  author = {Jørgensen, Bent},
  date = {1982},
  series = {Lecture Notes in Statistics},
  volume = {9},
  publisher = {{Springer-Verlag, New York-Berlin}}
}

@report{jorgesDataAnalysisPower2021a,
  type = {preprint},
  title = {Data {{Analysis}} and {{Power Simulations}} with {{General Linear Mixed Modelling}} for {{Psychophysical Data}} – {{A Practical}}, {{R-Based Guide}}},
  author = {Jörges, Björn},
  date = {2021-07-14},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/ack8u},
  url = {https://osf.io/ack8u},
  urldate = {2022-04-16},
  abstract = {Sample size planning is not straight-forward for the complex designs that are usually employed in psychophysical (two-alternative forced-choice) experiments: characteristics such as binary response variables and nested data structures where responses may be correlated differently within participants and experimental sessions than across participants and experimental sessions make it harder to estimate the necessary number of participants and trials with traditional means. In this practical R-based guide, we first show in detail how we can simulate verisimilar psychophysical data. We then use these simulations to compare two different methods by which two-alternative forced-choice data can be analyzed: (1) the “two-step” approach, where first psychometric functions are fitted and then statistical tests are performed over the parameters of these fitted psychometric functions; (2) an approach based on Generalized Linear Mixed Modeling (GLMM) that does not require the intermediary step of fitting psychometric functions. We argue that the GLMM approach enhances statistical validity and show that it can increase statistical power. Finally, we provide a sample implementation of a simulation-based power analysis that can be used as-is for many simple designs, but is also easily adaptable for more complex designs. Overall, we show that a GLMM-based approach can be beneficial for data analysis and sample size planning for typical (two-alternative forced-choice) psychophysical designs.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\DBAHDL9M\\Jörges - 2021 - Data Analysis and Power Simulations with General L.pdf}
}

@book{JoseEtAl:1998,
  title = {Classical Dynamics: {{A}} Contemporary Approach},
  author = {José, Jorge V. and Saletan, Eugene J.},
  date = {1998},
  publisher = {{Cambridge University Press}},
  location = {{New York}}
}

@article{JoulinEtAl:2010,
  title = {Curvature, Concentration and Error Estimates for {{Markov Chain Monte Carlo}}},
  author = {Joulin, Aldéric and Ollivier, Yann},
  date = {2010},
  journaltitle = {The Annals of Probability},
  volume = {38},
  number = {6},
  pages = {2418--2442},
  doi = {10.1214/10-AOP541},
  file = {D\:\\Zotero\\storage\\C4JVEX9A\\Joulin_Ollivier_2010_Curvature, concentration and error estimates for Markov Chain Monte Carlo.pdf}
}

@article{juddExperimentsMoreOne2017,
  title = {Experiments with {{More Than One Random Factor}}: {{Designs}}, {{Analytic Models}}, and {{Statistical Power}}},
  shorttitle = {Experiments with {{More Than One Random Factor}}},
  author = {Judd, Charles M. and Westfall, Jacob and Kenny, David A.},
  date = {2017-01-03},
  journaltitle = {Annual Review of Psychology},
  shortjournal = {Annu. Rev. Psychol.},
  volume = {68},
  number = {1},
  pages = {601--625},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-122414-033702},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-psych-122414-033702},
  urldate = {2022-08-31},
  abstract = {Traditional methods of analyzing data from psychological experiments are based on the assumption that there is a single random factor (normally participants) to which generalization is sought. However, many studies involve at least two random factors (e.g., participants and the targets to which they respond, such as words, pictures, or individuals). The application of traditional analytic methods to the data from such studies can result in serious bias in testing experimental effects. In this review, we develop a comprehensive typology of designs involving two random factors, which may be either crossed or nested, and one fixed factor, condition. We present appropriate linear mixed models for all designs and develop effect size measures. We provide the tools for power estimation for all designs. We then discuss issues of design choice, highlighting power and feasibility considerations. Our goal is to encourage appropriate analytic methods that produce replicable results for studies involving new samples of both participants and targets.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\FTB7RSQL\\Judd et al. - 2017 - Experiments with More Than One Random Factor Desi.pdf;D\:\\Zotero\\storage\\T44D8EFG\\Judd et al_2017_Experiments with More Than One Random Factor.pdf}
}

@article{junaidiPriorSensitivityAnalysis,
  title = {Prior {{Sensitivity Analysis}} for a {{Hierarchical Model}}},
  author = {Junaidi, Elizabeth Stojanovski and , Darfiana Nur},
  pages = {6},
  abstract = {Meta-analysis can be presented in the Frequentist or Bayesian framework. Based on the model of DuMouchel, a simulation study is conducted which fixes the overall mean and variance-covariance matrix to generate estimates of the true mean effect. These estimates will be compared to the true effect to assess bias. A sensitivity analysis, to measure the robustness of results to the selection of prior distributions, is conducted by employing Uniform and Pareto distributions for the variance components, the t-distribution for the overall mean component and a combination of priors for both variance and mean components respectively. Results were more sensitive when the prior was changed only on the overall mean component.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\JN47UQKV\\Junaidi and  - Prior Sensitivity Analysis for a Hierarchical Mode.pdf}
}

@misc{kallioinenDetectingDiagnosingPrior2022,
  title = {Detecting and Diagnosing Prior and Likelihood Sensitivity with Power-Scaling},
  author = {Kallioinen, Noa and Paananen, Topi and Bürkner, Paul-Christian and Vehtari, Aki},
  date = {2022-05-05},
  number = {arXiv:2107.14054},
  eprint = {2107.14054},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2107.14054},
  urldate = {2022-09-01},
  abstract = {Determining the sensitivity of the posterior to perturbations of the prior and likelihood is an important part of the Bayesian workflow. We introduce a practical and computationally efficient sensitivity analysis approach using importance sampling to estimate properties of posteriors resulting from power-scaling the prior or likelihood. On this basis, we suggest a diagnostic that can indicate the presence of prior-data conflict or likelihood noninformativity and discuss limitations to the power-scaling approach. The approach can be easily included in Bayesian workflows with minimal effort by the model builder and we present an implementation in our new R package \textbackslash texttt\{priorsense\}. We further demonstrate the workflow on case studies of real data using models varying in complexity from simple linear models to Gaussian process models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\SH6JTT3Z\\Kallioinen et al. - 2022 - Detecting and diagnosing prior and likelihood sens.pdf}
}

@misc{kallioinenDetectingDiagnosingPrior2022a,
  title = {Detecting and Diagnosing Prior and Likelihood Sensitivity with Power-Scaling},
  author = {Kallioinen, Noa and Paananen, Topi and Bürkner, Paul-Christian and Vehtari, Aki},
  date = {2022-05-05},
  number = {arXiv:2107.14054},
  eprint = {2107.14054},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2107.14054},
  urldate = {2022-09-01},
  abstract = {Determining the sensitivity of the posterior to perturbations of the prior and likelihood is an important part of the Bayesian workflow. We introduce a practical and computationally efficient sensitivity analysis approach using importance sampling to estimate properties of posteriors resulting from power-scaling the prior or likelihood. On this basis, we suggest a diagnostic that can indicate the presence of prior-data conflict or likelihood noninformativity and discuss limitations to the power-scaling approach. The approach can be easily included in Bayesian workflows with minimal effort by the model builder and we present an implementation in our new R package \textbackslash texttt\{priorsense\}. We further demonstrate the workflow on case studies of real data using models varying in complexity from simple linear models to Gaussian process models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\N9XZU7PL\\Kallioinen et al. - 2022 - Detecting and diagnosing prior and likelihood sens.pdf}
}

@book{Keener:2011,
  title = {Theoretical Statistics: {{Topics}} for a Core Course},
  author = {Keener, Robert W},
  date = {2011},
  publisher = {{Springer}}
}

@article{klausImportanceRandomSlopes2022,
  title = {The~{{Importance}}~of~{{Random~Slopes}}~in~{{Mixed~Models}}~for~{{Bayesian~Hypothesis~Testing}}},
  author = {Klaus, Oberauer},
  date = {2022},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\YMPUGSGF\\The Importance of Random Slopes in Mixed Models fo.pdf}
}

@book{Knuth:1998,
  title = {The Art of Computer Programming. {{Vol}}. 2},
  author = {Knuth, Donald E.},
  date = {1998},
  publisher = {{Addison-Wesley, Reading, MA}}
}

@article{kolossaComputationalAnalysisNeural2015,
  title = {A Computational Analysis of the Neural Bases of {{Bayesian}} Inference},
  author = {Kolossa, Antonio and Kopp, Bruno and Fingscheidt, Tim},
  date = {2015-02},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {106},
  pages = {222--237},
  issn = {10538119},
  doi = {10/f6tz5d},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811914009094},
  urldate = {2021-09-14},
  abstract = {Empirical support for the Bayesian brain hypothesis, although of major theoretical importance for cognitive neuroscience, is surprisingly scarce. This hypothesis posits simply that neural activities code and compute Bayesian probabilities. Here, we introduce an urn–ball paradigm to relate event-related potentials (ERPs) such as the P300 wave to Bayesian inference. Bayesian model comparison is conducted to compare various models in terms of their ability to explain trial-by-trial variation in ERP responses at different points in time and over different regions of the scalp. Specifically, we are interested in dissociating specific ERP responses in terms of Bayesian updating and predictive surprise. Bayesian updating refers to changes in probability distributions given new observations, while predictive surprise equals the surprise about observations under current probability distributions. Components of the late positive complex (P3a, P3b, Slow Wave) provide dissociable measures of Bayesian updating and predictive surprise. Specifically, the updating of beliefs about hidden states yields the best fit for the anteriorly distributed P3a, whereas the updating of predictions of observations accounts best for the posteriorly distributed Slow Wave. In addition, parietally distributed P3b responses are best fit by predictive surprise. These results indicate that the three components of the late positive complex reflect distinct neural computations. As such they are consistent with the Bayesian brain hypothesis, but these neural computations seem to be subject to nonlinear probability weighting. We integrate these findings with the free-energy principle that instantiates the Bayesian brain hypothesis.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\CDHRRGRK\\Kolossa et al_2015_A computational analysis of the neural bases of Bayesian inference.pdf}
}

@article{konigBayesianStatisticsEducational2018,
  title = {Bayesian Statistics in Educational Research: A Look at the Current State of Affairs},
  shorttitle = {Bayesian Statistics in Educational Research},
  author = {König, Christoph and van de Schoot, Rens},
  options = {useprefix=true},
  date = {2018-08-08},
  journaltitle = {Educational Review},
  shortjournal = {Educational Review},
  volume = {70},
  number = {4},
  pages = {486--509},
  issn = {0013-1911, 1465-3397},
  doi = {10/gfj8nd},
  url = {https://www.tandfonline.com/doi/full/10.1080/00131911.2017.1350636},
  urldate = {2022-03-25},
  abstract = {The ability of a scientific discipline to build cumulative knowledge depends on its predominant method of data analysis. A steady accumulation of knowledge requires approaches which allow researchers to consider results from comparable prior research. Bayesian statistics is especially relevant for establishing a cumulative scientific discipline, because the incorporation of background (or prior) knowledge is fundamentally anchored in its basic principles. The aim of the current systematic review is to provide insights into the current state of methodological affairs in educational research, with a focus on Bayesian statistics and the use of prior information. An analysis of publication histories of the 224 educational journals currently listed in the Thomson Reuters Journal Citation Report 2015 indicates that Bayesian statistics is primarily used to solve methodological problems, rather than used to build cumulative knowledge based on a combination of study results with comparable prior research. The utilisation of Bayesian statistics is motivated by its flexibility: models are estimated which would not be estimable with frequentist approaches, thus expanding the methodological repertoire of educational researchers and producing knowledge which otherwise would not have been available. Lastly, the predominant use of noninformative prior distributions indicates that one of the biggest advantages of Bayesian statistics, namely the combination of study results with comparable prior research, remains underutilised in educational research. Practical implications of these findings for educational research are illustrated and discussed.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\XIWS6DNW\\König_van de Schoot_2018_Bayesian statistics in educational research.pdf}
}

@article{kowalBayesianMultivariateFunctional2017,
  title = {A {{Bayesian Multivariate Functional Dynamic Linear Model}}},
  author = {Kowal, Daniel R. and Matteson, David S. and Ruppert, David},
  date = {2017-04-03},
  journaltitle = {Journal of the American Statistical Association},
  shortjournal = {Journal of the American Statistical Association},
  volume = {112},
  number = {518},
  pages = {733--744},
  issn = {0162-1459, 1537-274X},
  doi = {10/gb2db8},
  url = {https://www.tandfonline.com/doi/full/10.1080/01621459.2016.1165104},
  urldate = {2022-03-25},
  abstract = {We present a Bayesian approach for modeling multivariate, dependent functional data. To account for the three dominant structural features in the data—functional, time dependent, and multivariate components—we extend hierarchical dynamic linear models for multivariate time series to the functional data setting. We also develop Bayesian spline theory in a more general constrained optimization framework. The proposed methods identify a time-invariant functional basis for the functional observations, which is smooth and interpretable, and can be made common across multivariate observations for additional information sharing. The Bayesian framework permits joint estimation of the model parameters, provides exact inference (up to MCMC error) on specific parameters, and allows generalized dependence structures. Sampling from the posterior distribution is accomplished with an efficient Gibbs sampling algorithm. We illustrate the proposed framework with two applications: (1) multi-economy yield curve data from the recent global recession, and (2) local field potential brain signals in rats, for which we develop a multivariate functional time series approach for multivariate time–frequency analysis. Supplementary materials, including R code and the multi-economy yield curve data, are available online.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\CGAQ7WJE\\Kowal et al_2017_A Bayesian Multivariate Functional Dynamic Linear Model.pdf}
}

@article{kruschkeBayesianAnalysisReporting2021,
  title = {Bayesian {{Analysis Reporting Guidelines}}},
  author = {Kruschke, John K.},
  date = {2021-08-16},
  journaltitle = {Nature Human Behaviour},
  shortjournal = {Nat Hum Behav},
  issn = {2397-3374},
  doi = {10/gmhrkc},
  url = {https://www.nature.com/articles/s41562-021-01177-7},
  urldate = {2021-09-14},
  abstract = {Abstract             Previous surveys of the literature have shown that reports of statistical analyses often lack important information, causing lack of transparency and failure of reproducibility. Editors and authors agree that guidelines for reporting should be encouraged. This Review presents a set of Bayesian analysis reporting guidelines (BARG). The BARG encompass the features of previous guidelines, while including many additional details for contemporary Bayesian analyses, with explanations. An extensive example of applying the BARG is presented. The BARG should be useful to researchers, authors, reviewers, editors, educators and students. Utilization, endorsement and promotion of the BARG may improve the quality, transparency and reproducibility of Bayesian analyses.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\GKJD3ZBM\\Kruschke_2021_Bayesian Analysis Reporting Guidelines.pdf}
}

@article{kruschkeBayesianDataAnalysis2010,
  title = {Bayesian Data Analysis},
  author = {Kruschke, John K.},
  date = {2010-09},
  journaltitle = {WIREs Cognitive Science},
  shortjournal = {WIREs Cogn Sci},
  volume = {1},
  number = {5},
  pages = {658--676},
  issn = {1939-5078, 1939-5086},
  doi = {10.1002/wcs.72},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/wcs.72},
  urldate = {2022-07-29},
  langid = {english},
  file = {D\:\\Zotero\\storage\\RRCAY2DX\\kruschke2010.pdf.pdf;D\:\\Zotero\\storage\\SSYUXSET\\Kruschke - 2010 - Bayesian data analysis.pdf}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {178--206},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  url = {http://link.springer.com/10.3758/s13423-016-1221-4},
  urldate = {2022-03-27},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed “the New Statistics” (Cumming, 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\BKUXBE4S\\Kruschke_Liddell_2018_The Bayesian New Statistics.pdf}
}

@article{kruschkeRejectingAcceptingParameter2018,
  title = {Rejecting or {{Accepting Parameter Values}} in {{Bayesian Estimation}}},
  author = {Kruschke, John K},
  date = {2018},
  pages = {11},
  abstract = {This article explains a decision rule that uses Bayesian posterior distributions as the basis for accepting or rejecting null values of parameters. This decision rule focuses on the range of plausible values indicated by the highest density interval of the posterior distribution and the relation between this range and a region of practical equivalence (ROPE) around the null value. The article also discusses considerations for setting the limits of a ROPE and emphasizes that analogous considerations apply to setting the decision thresholds for p values and Bayes factors.},
  langid = {english},
  keywords = {/unread,❓ Multiple DOI},
  file = {D\:\\Zotero\\storage\\7SJD9359\\Kruschke_2018_Rejecting or Accepting Parameter Values in Bayesian Estimation.pdf}
}

@article{kruschkeWhatBelieveBayesian2010,
  title = {What to Believe: {{Bayesian}} Methods for Data Analysis},
  shorttitle = {What to Believe},
  author = {Kruschke, John K.},
  date = {2010-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {14},
  number = {7},
  pages = {293--300},
  issn = {13646613},
  doi = {10.1016/j.tics.2010.05.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661310000926},
  urldate = {2022-08-03},
  langid = {english},
  file = {D\:\\Zotero\\storage\\FW3WFYHH\\kruschke2010.pdf.pdf;D\:\\Zotero\\storage\\IDB5VFSY\\Kruschke - 2010 - What to believe Bayesian methods for data analysi.pdf}
}

@article{kubeHowNegativeMood2021,
  title = {How Negative Mood Hinders Belief Updating in Depression: Results from Two Experimental Studies},
  shorttitle = {How Negative Mood Hinders Belief Updating in Depression},
  author = {Kube, Tobias and Kirchner, Lukas and Gärtner, Thomas and Glombiewski, Julia Anna},
  date = {2021-07-12},
  journaltitle = {Psychological Medicine},
  shortjournal = {Psychol. Med.},
  pages = {1--14},
  issn = {0033-2917, 1469-8978},
  doi = {10/gpws2g},
  url = {https://www.cambridge.org/core/product/identifier/S0033291721002798/type/journal_article},
  urldate = {2022-04-16},
  abstract = {Background. In two experimental studies, we tested the hypothesis that negative mood would hinder the revision of negative beliefs in response to unexpectedly positive information in depression, whereas positive mood was expected to enhance belief updating. Methods. In study 1 (N = 101), we used a subclinical sample to compare the film-based induction of sad v. happy mood with a distraction control group. Subsequently, participants underwent a well-established paradigm to examine intra-individual changes in performance-related expectations after unexpectedly positive performance feedback. In study 2, we applied the belief-updating task from study 1 to an inpatient sample (N = 81) and induced sad v. happy mood via film-clips v. recall of autobiographic events. Results. The results of study 1 showed no significant group differences in belief updating; the severity of depressive symptoms was a negative predictor of belief revision, though, and there was a non-significant trend suggesting that the presence of sad mood hindered belief updating in the subgroup of participants with a diagnosed depressive episode. Study 2 revealed that participants updated their expectations significantly less in line with positive feedback when they underwent the induction of negative mood prior to feedback, relative to positive mood. Conclusions. By indicating that the presence of negative mood can hinder the revision of negative beliefs in clinically depressed people, our findings suggest that learning from new experiences can be hampered if state negative mood is activated. Thus, interventions relying on learning from novel positive experiences should aim at reducing state negative mood in depression.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\TDRX4I63\\Kube et al. - 2021 - How negative mood hinders belief updating in depre.pdf}
}

@article{kucharskyHiddenMarkovModels2021,
  title = {Hidden {{Markov Models}} of {{Evidence Accumulation}} in {{Speeded Decision Tasks}}},
  author = {Kucharský, Šimon and Tran, N.-Han and Veldkamp, Karel and Raijmakers, Maartje and Visser, Ingmar},
  date = {2021-12},
  journaltitle = {Computational Brain \& Behavior},
  shortjournal = {Comput Brain Behav},
  volume = {4},
  number = {4},
  pages = {416--441},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-021-00115-0},
  url = {https://link.springer.com/10.1007/s42113-021-00115-0},
  urldate = {2022-06-05},
  abstract = {Abstract                            Speeded decision tasks are usually modeled within the evidence accumulation framework, enabling inferences on latent cognitive parameters, and capturing dependencies between the observed response times and accuracy. An example is the speed-accuracy trade-off, where people sacrifice speed for accuracy (or vice versa). Different views on this phenomenon lead to the idea that participants may not be able to control this trade-off on a continuum, but rather switch between distinct states (Dutilh et al.,               Cognitive Science               35(2):211–250, 2010). Hidden Markov models are used to account for switching between distinct states. However, combining evidence accumulation models with a hidden Markov structure is a challenging problem, as evidence accumulation models typically come with identification and computational issues that make them challenging on their own. Thus, an integration of hidden Markov models with evidence accumulation models has still remained elusive, even though such models would allow researchers to capture potential dependencies between response times and accuracy within the states, while concomitantly capturing different behavioral modes during cognitive processing. This article presents a model that uses an evidence accumulation model as part of a hidden Markov structure. This model is considered as a proof of principle that evidence accumulation models can be combined with Markov switching models. As such, the article considers a very simple case of a simplified Linear Ballistic Accumulation. An extensive simulation study was conducted to validate the model’s implementation according to principles of robust Bayesian workflow. Example reanalysis of data from Dutilh et al. (               Cognitive Science               35(2):211–250, 2010) demonstrates the application of the new model. The article concludes with limitations and future extensions or alternatives to the model and its application.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\YA6I237I\\Kucharský2021_Article_HiddenMarkovModelsOfEvidenceAc.pdf}
}

@article{KullbackEtAl:1951,
  title = {On Information and Sufficiency},
  author = {Kullback, S. and Leibler, R. A.},
  date = {1951},
  shortjournal = {Ann. Math. Statistics},
  volume = {22},
  pages = {79--86}
}

@article{kumleEstimatingPowerGeneralized,
  title = {Estimating Power in (Generalized) Linear Mixed Models: An Open Introduction and Tutorial in {{R}}.},
  author = {Kumle, Leah},
  pages = {29},
  abstract = {Linear mixed-effect models are a powerful tool for modelling fixed and random effects simultaneously, but do not offer a feasible analytic solution for estimating the probability that a test correctly rejects the null hypothesis. Being able to estimate this probability, however, is critical for sample size planning, as power is closely linked to the reliability and replicability of empirical findings. Although various tools for conducting a simulation-based power analysis for mixed-effect models are available, there is a lack of guidance on how to appropriately use them in different scenarios. In this tutorial paper, we discuss and elaborate how to estimate power for mixed-effects models in different use cases and outline important considerations and pitfalls. We provide code and resources for performing simulation-based power analyses on openly accessible data sets. Our aim is to help researchers build intuitions about simulationbased power analyses and empower them to set up highly powered research designs when sophisticated analysis procedures like mixed-effect models are outlined as inferential procedures.},
  langid = {english},
  keywords = {/unread,❓ Multiple DOI},
  file = {D\:\\Zotero\\storage\\SIZD3SEG\\Kumle et al_2021_Estimating power in (generalized) linear mixed models.pdf}
}

@article{ladislasIntroductionBayesianMultilevel2019,
  title = {An {{Introduction}} to {{Bayesian Multilevel Models Using}} Brms: {{A Case Study}} of {{Gender Effects}} on {{Vowel Variability}} in {{Standard Indonesian}}},
  author = {Ladislas, Nalborczyk and Cédric, Batailler and Hélène, Lœvenbruck and Anne, Vilain and Paul-Christian, Bürkner},
  date = {2019},
  pages = {50},
  langid = {english},
  keywords = {/unread,170204 Linguistic Processes (incl. Speech Production and Comprehension),FOS: Mathematics,FOS: Psychology,I 级文献,Statistics},
  file = {D\:\\Zotero\\storage\\ACM4ZKZ9\\Nalborczyk et al. - 2019 - An Introduction to Bayesian Multilevel Models Usin.pdf;D\:\\Zotero\\storage\\G6FBDKTI\\An Introduction to Bayesian Multilevel Models Using brms.pdf}
}

@article{lakensSampleSizeJustification2022,
  title = {Sample {{Size Justification}}},
  author = {Lakens, Daniël},
  date = {2022-03-22},
  journaltitle = {Collabra: Psychology},
  volume = {8},
  number = {1},
  pages = {33267},
  issn = {2474-7394},
  doi = {10.1525/collabra.33267},
  url = {https://online.ucpress.edu/collabra/article/8/1/33267/120491/Sample-Size-Justification},
  urldate = {2022-08-31},
  abstract = {An important step when designing an empirical study is to justify the sample size that will be collected. The key aim of a sample size justification for such studies is to explain how the collected data is expected to provide valuable information given the inferential goals of the researcher. In this overview article six approaches are discussed to justify the sample size in a quantitative empirical study: 1) collecting data from (almost) the entire population, 2) choosing a sample size based on resource constraints, 3) performing an a-priori power analysis, 4) planning for a desired accuracy, 5) using heuristics, or 6) explicitly acknowledging the absence of a justification. An important question to consider when justifying sample sizes is which effect sizes are deemed interesting, and the extent to which the data that is collected informs inferences about these effect sizes. Depending on the sample size justification chosen, researchers could consider 1) what the smallest effect size of interest is, 2) which minimal effect size will be statistically significant, 3) which effect sizes they expect (and what they base these expectations on), 4) which effect sizes would be rejected based on a confidence interval around the effect size, 5) which ranges of effects a study has sufficient power to detect based on a sensitivity power analysis, and 6) which effect sizes are expected in a specific research area. Researchers can use the guidelines presented in this article, for example by using the interactive form in the accompanying online Shiny app, to improve their sample size justification, and hopefully, align the informational value of a study with their inferential goals.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\UY9GIX4A\\Lakens - 2022 - Sample Size Justification.pdf}
}

@article{lampinenBayesianApproachNeural2001,
  title = {Bayesian Approach for Neural Networks Review and Case Studies},
  author = {Lampinen, Jouko and Vehtari, Aki},
  date = {2001},
  journaltitle = {Neural Networks},
  pages = {18},
  doi = {10/cn6csb},
  abstract = {We give a short review on the Bayesian approach for neural network learning and demonstrate the advantages of the approach in three real applications. We discuss the Bayesian approach with emphasis on the role of prior knowledge in Bayesian models and in classical error minimization approaches. The generalization capability of a statistical model, classical or Bayesian, is ultimately based on the prior assumptions. The Bayesian approach permits propagation of uncertainty in quantities which are unknown to other assumptions in the model, which may be more generally valid or easier to guess in the problem. The case problem studied in this paper include a regression, a classi®cation, and an inverse problem. In the most thoroughly analyzed regression problem, the best models were those with less restrictive priors. This emphasizes the major advantage of the Bayesian approach, that we are not forced to guess attributes that are unknown, such as the number of degrees of freedom in the model, non-linearity of the model with respect to each input variable, or the exact form for the distribution of the model residuals. q 2001 Elsevier Science Ltd. All rights reserved.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\G9XFFMWM\\Lampinen_Vehtari_2001_Bayesian approach for neural networksÐreview and case studies.pdf}
}

@article{langenbergTutorialUsingPaired2022,
  title = {A Tutorial on Using the Paired t Test for Power Calculations in Repeated Measures {{ANOVA}} with Interactions},
  author = {Langenberg, Benedikt and Janczyk, Markus and Koob, Valentin and Kliegl, Reinhold and Mayer, Axel},
  date = {2022-08-24},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  issn = {1554-3528},
  doi = {10.3758/s13428-022-01902-8},
  url = {https://link.springer.com/10.3758/s13428-022-01902-8},
  urldate = {2022-08-31},
  abstract = {Abstract                            The a priori calculation of statistical power has become common practice in behavioral and social sciences to calculate the necessary sample size for detecting an expected effect size with a certain probability (i.e., power). In multi-factorial repeated measures ANOVA, these calculations can sometimes be cumbersome, especially for higher-order interactions. For designs that only involve factors with two levels each, the paired               t               test can be used for power calculations, but some pitfalls need to be avoided. In this tutorial, we provide practical advice on how to express main and interaction effects in repeated measures ANOVA as single difference variables. In particular, we demonstrate how to calculate the effect size Cohen’s               d               of this difference variable either based on means, variances, and covariances of conditions or by transforming                                                   \$\$\{\textbackslash eta \_\{p\}\^\{2\}\}\$\$                                                               η                                                p                                              2                                                                                       or                                                   \$\$\{\textbackslash omega \_\{p\}\^\{2\}\}\$\$                                                               ω                                                p                                              2                                                                                       from the ANOVA framework into               d               . With the effect size correctly specified, we then show how to use the               t               test for sample size considerations by means of an empirical example. The relevant R code is provided in an online repository for all example calculations covered in this article.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\QYJ2WYRD\\Langenberg et al. - 2022 - A tutorial on using the paired t test for power ca.pdf}
}

@article{LattimoreEtAl:2019a,
  title = {Replacing the Do-Calculus with {{Bayes}} Rule},
  author = {Lattimore, Finnian and Rohde, David},
  date = {2019-06},
  keywords = {⛔ No DOI found}
}

@article{LattimoreEtAl:2019b,
  title = {Causal Inference with {{Bayes}} Rule},
  author = {Lattimore, Finnian and Rohde, David},
  date = {2019-10},
  keywords = {⛔ No DOI found}
}

@inproceedings{LEcuyer:2015,
  title = {Random Number Generation with Multiple Streams for Sequential and Parallel Computing},
  booktitle = {Proceedings of the 2015 Winter Simulation Conference},
  author = {L'Ecuyer, Pierre},
  editor = {Yilmaz, L. and W. K V. Chan, I. Moon, C. Macal, T. M. K. Roeder and Rossetti, M. D.},
  date = {2015-12},
  pages = {31--44},
  publisher = {{IEEE Press}}
}

@article{LEcuyerEtAl:2007,
  title = {{{TestU01}}: {{A C}} Library for Empirical Testing of Random Number Generators},
  author = {L'Ecuyer, Pierre and Simard, Richard},
  date = {2007-08},
  journaltitle = {ACM Trans. Math. Softw.},
  volume = {33},
  number = {4},
  doi = {10.1145/1268776.1268777},
  file = {D\:\\Zotero\\storage\\2TQ9WYGA\\L'Ecuyer_Simard_2007_TestU01.pdf}
}

@report{lederBackgroundUncertaintyCan2021b,
  type = {preprint},
  title = {Background {{Uncertainty Can Increase Risk Aversion}} in {{Decision Making}}},
  author = {Leder, Johannes and Lauer, Thomas and Schütz, Astrid and Gürerk, Özgür},
  date = {2021-09-29},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/6s4vf},
  url = {https://osf.io/6s4vf},
  urldate = {2022-04-16},
  abstract = {Some theories based on economics and psychology propose that background uncertainty, that is uncertainty which is independent of the actual decision, can alter people’s risk preferences. Previous empirical research testing this proposition, however, is inconclusive and relies on single studies. Here, we aim to investigate the effect of background uncertainty on decision making systematically. After reviewing the existing empirical studies, we argue that two types of uncertainty should be distinguished: a) ambiguity, i.e., uncertain outcomes without probability information and b) risk, i.e., uncertainties involving probabilities regarding a negative outcome. We test the hypothesis that the type of uncertainty moderates the effect of background uncertainty on risk preferences. In four studies (total N = 405), we induced background uncertainty (ambiguity and risk) with different methods, and measured risk preferences with multiple behavioral tasks. Study 2 was carried out using virtual reality to induce background uncertainty in a naturalistic way, all other studies were computer-based. Using a mini metaanalysis, we found a small but consistent positive effect of increased risk aversion with background uncertainty. As predicted, the type of background uncertainty moderated the observed effects: background ambiguity compared to background risk resulted in a higher increase of risk aversion.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\4HLMD4FD\\Leder et al. - 2021 - Background Uncertainty Can Increase Risk Aversion .pdf}
}

@book{Lee:2011,
  title = {Introduction to Topological Manifolds},
  author = {Lee, John M},
  date = {2011},
  publisher = {{Springer}}
}

@book{Lehmann:2006,
  title = {Theory of Point Estimation},
  author = {Lehmann, Erich L and Casella, George},
  date = {2006},
  publisher = {{Springer Science \&amp; Business Media}}
}

@book{Lemieux:2009,
  title = {Monte {{Carlo}} and Quasi-{{Monte Carlo}} Sampling},
  author = {Lemieux, Christiane},
  date = {2009},
  series = {Springer Series in Statistics},
  edition = {1},
  publisher = {{Springer, New York, NY}}
}

@article{lenkBayesianInferenceFinite2000,
  title = {Bayesian Inference for Finite Mixtures of Generalized Linear Models with Random Effects},
  author = {Lenk, Peter J. and DeSarbo, Wayne S.},
  date = {2000-03},
  journaltitle = {Psychometrika},
  shortjournal = {Psychometrika},
  volume = {65},
  number = {1},
  pages = {93--119},
  issn = {0033-3123, 1860-0980},
  doi = {10/b52x9w},
  url = {http://link.springer.com/10.1007/BF02294188},
  urldate = {2022-03-25},
  abstract = {We present an hierarchical Bayes approach to modeling parameter heterogeneity in generalized linear models. The model assumes that there are relevant subpopulations and that within each subpopulation the individual-level regression coefficients have a multivariate normal distribution. However, class membership is not known a priori, so the heterogeneity in the regression coefficients becomes a finite mixture of normal distributions. This approach combines the flexibility of semiparametric, latent class models that assume common parameters for each sub-population and the parsimony of random effects models that assume normal distributions for the regression parameters. The number of subpopulations is selected to maximize the posterior probability of the model being true. Simulations are presented which document the performance of the methodology for synthetic data with known heterogeneity and number of sub-populations. An application is presented concerning preferences for various aspects of personal computers.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\L2BLBF3Z\\Lenk_DeSarbo_2000_Bayesian inference for finite mixtures of generalized linear models with random.pdf}
}

@article{LewandowskiEtAl:2009,
  title = {Generating Random Correlation Matrices Based on Vines and Extended Onion Method},
  author = {Lewandowski, Daniel and Kurowicka, Dorota and Joe, Harry},
  date = {2009},
  journaltitle = {Journal of multivariate analysis},
  volume = {100},
  number = {9},
  pages = {1989--2001},
  doi = {10/bs7dst},
  file = {D\:\\Zotero\\storage\\EMXCSY2H\\Lewandowski et al_2009_Generating random correlation matrices based on vines and extended onion method.pdf}
}

@article{liBeiYeSiTongJiFangFaDeYingYongYuXianZhuang2021,
  title = {贝叶斯统计方法的应用与现状},
  author = {李, 贵玉 and 顾, 昕},
  date = {2021},
  journaltitle = {心理学探新},
  volume = {41},
  number = {5},
  pages = {466--473},
  issn = {1003-5184},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDAUTO&filename=XLXT202105013&v=},
  abstract = {贝叶斯统计方法是心理学数据分析的热门方法。研究全面论述贝叶斯方法在心理学领域的应用与方向。现阶段贝叶斯方法以模拟研究为主，应用方向为心理学研究常用的项目反应理论、认知诊断、计算机自适应、结构方程模型。同时，评述发现贝叶斯方法正逐步被国内心理学研究者所接受。最后，文章讨论了当下贝叶斯统计在心理学研究中应用的局限性及可能的原因，建议统计学者开发界面友好的贝叶斯软件，并在心理学课程中加入贝叶斯知识。},
  langid = {chinese},
  keywords = {⛔ No DOI found,posterior,prior,regression model,systematic review,先验,后验,回归模型,系统性评述 Bayesian statistics,贝叶斯统计},
  annotation = {{$<$}北大核心, CSSCI{$>$}},
  file = {D\:\\Zotero\\storage\\V4JSKDXD\\李_顾_2021_贝叶斯统计方法的应用与现状.pdf}
}

@article{LindgrenEtAl:2011,
  title = {An Explicit Link between {{Gaussian}} Fields and {{Gaussian Markov}} Random Fields: The Stochastic Partial Differential Equation Approach},
  author = {Lindgren, Finn and Rue, Håvard and Lindström, Johan},
  date = {2011},
  journaltitle = {Journal of the Royal Statistical Society},
  shortjournal = {J. R. Stat. Soc. Ser. B Stat. Methodol.},
  volume = {73},
  number = {4},
  pages = {423--498},
  doi = {10.1111/j.1467-9868.2011.00777.x},
  file = {D\:\\Zotero\\storage\\N49U34QZ\\Lindgren et al_2011_An explicit link between Gaussian fields and Gaussian Markov random fields.pdf}
}

@misc{LindgrenEtAl:2021,
  title = {The {{SPDE}} Approach for {{Gaussian}} and Non-{{Gaussian}} Fields: 10 Years and Still Running},
  author = {Lindgren, Finn and Bolin, David and Rue, Håvard},
  date = {2021-11},
  howpublished = {arXiv e-prints}
}

@book{Lindley:2014,
  title = {Understanding Uncertainty},
  author = {Lindley, Dennis V.},
  date = {2014},
  series = {Wiley Series in Probability and Statistics},
  edition = {Revised},
  publisher = {{John Wiley \&amp; Sons, Inc., Hoboken, NJ}}
}

@article{lineroReviewTreebasedBayesian2017,
  title = {A Review of Tree-Based {{Bayesian}} Methods},
  author = {Linero, Antonio R.},
  date = {2017-11-30},
  journaltitle = {Communications for Statistical Applications and Methods},
  shortjournal = {CSAM},
  volume = {24},
  number = {6},
  pages = {543--559},
  issn = {2383-4757},
  doi = {10/gprpg4},
  url = {http://www.csam.or.kr/journal/view.html?doi=10.29220/CSAM.2017.24.6.543},
  urldate = {2022-03-25},
  abstract = {Tree-based regression and classification ensembles form a standard part of the data-science toolkit. Many commonly used methods take an algorithmic view, proposing greedy methods for constructing decision trees; examples include the classification and regression trees algorithm, boosted decision trees, and random forests. Recent history has seen a surge of interest in Bayesian techniques for constructing decision tree ensembles, with these methods frequently outperforming their algorithmic counterparts. The goal of this article is to survey the landscape surrounding Bayesian decision tree methods, and to discuss recent modeling and computational developments. We provide connections between Bayesian tree-based methods and existing machine learning techniques, and outline several recent theoretical developments establishing frequentist consistency and rates of convergence for the posterior distribution. The methodology we present is applicable for a wide variety of statistical tasks including regression, classification, modeling of count data, and many others. We illustrate the methodology on both simulated and real datasets.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\2W57FTW9\\Linero_2017_A review of tree-based Bayesian methods.pdf}
}

@article{liuAnalysisOrderedCategorical2005,
  title = {The Analysis of Ordered Categorical Data: {{An}} Overview and a Survey of Recent Developments},
  shorttitle = {The Analysis of Ordered Categorical Data},
  author = {Liu, Ivy and Agresti, Alan},
  date = {2005-06},
  journaltitle = {Test},
  shortjournal = {Test},
  volume = {14},
  number = {1},
  pages = {1--73},
  issn = {1133-0686, 1863-8260},
  doi = {10/bg9vpj},
  url = {http://link.springer.com/10.1007/BF02595397},
  urldate = {2022-03-25},
  abstract = {This a.rticle reviews me\textasciitilde;hodologies used for analyzing ordered ca*;egoricaI (ordinal) response variables. We begin by surveyi\textasciitilde lg models for daZa with a single ordinal response variable. We also survey recently proposed strategies for modeling ordinal response va.riabies when the data. have ..\textasciitilde me type of clustering or when repeated measurement occurs at various ocea.si,.ms for each subject, such as in longitudinal studies. Primaa\textasciitilde " models in tha.t ease include m\textasciitilde,\textasciitilde ygned m(Jdels and clus\textasciitilde e.r-.spec\textasciitilde ]ic (condit\textasciitilde on\textasciitilde d) modd.\textasciitilde\textasciitilde for which effects apply conditionally at, t h e clus.ter level. Rela.ted discussion refers to multi-level and transitional models. The ma.in emphasis is on m a x i m u m likelihood inference, a l t h o u g h we indica.te certain models (e\textasciitilde g., marginal models, multi-level models) for which this can be computagionally diiticult. The Bayesian approach has also received eo\textasciitilde siderable attention for categorical data in the past decade, and we survey recent Bayesian approaches to modeling ordinal response variables. Alternative, n o n m o d e l ba..\textasciitilde d, a p p r o a c h e s are also. available fbr certain types of inference.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\HY8FTLRZ\\Liu_Agresti_2005_The analysis of ordered categorical data.pdf}
}

@article{logacevUnderstandingUnderspecificationComparison2016,
  title = {Understanding Underspecification: {{A}} Comparison of Two Computational Implementations},
  shorttitle = {Understanding Underspecification},
  author = {Logačev, Pavel and Vasishth, Shravan},
  date = {2016-05},
  journaltitle = {Quarterly Journal of Experimental Psychology},
  shortjournal = {Quarterly Journal of Experimental Psychology},
  volume = {69},
  number = {5},
  pages = {996--1012},
  issn = {1747-0218, 1747-0226},
  doi = {10.1080/17470218.2015.1134602},
  url = {http://journals.sagepub.com/doi/10.1080/17470218.2015.1134602},
  urldate = {2022-06-01},
  abstract = {Swets et al. (2008. Underspecification of syntactic ambiguities: Evidence from self-paced reading. Memory and Cognition, 36(1), 201–216) presented evidence that the so-called ambiguity advantage [Traxler et al. (1998). Adjunct attachment is not a form of lexical ambiguity resolution. Journal of Memory and Language, 39(4), 558–592], which has been explained in terms of the Unrestricted Race Model, can equally well be explained by assuming underspecification in ambiguous conditions driven by task-demands. Specifically, if comprehension questions require that ambiguities be resolved, the parser tends to make an attachment: when questions are about superficial aspects of the target sentence, readers tend to pursue an underspecification strategy. It is reasonable to assume that individual differences in strategy will play a significant role in the application of such strategies, so that studying average behaviour may not be informative. In order to study the predictions of the good-enough processing theory, we implemented two versions of underspecification: the partial specification model (PSM), which is an implementation of the Swets et al. proposal, and a more parsimonious version, the non-specification model (NSM). We evaluate the relative fit of these two kinds of underspecification to Swets et al.'s data; as a baseline, we also fitted three models that assume no underspecification. We find that a model without underspecification provides a somewhat better fit than both underspecification models, while the NSM model provides a better fit than the PSM. We interpret the results as lack of unambiguous evidence in favour of underspecification; however, given that there is considerable existing evidence for good-enough processing in the literature, it is reasonable to assume that some underspecification might occur. Under this assumption, the results can be interpreted as tentative evidence for NSM over PSM. More generally, our work provides a method for choosing between models of real-time processes in sentence comprehension that make qualitative predictions about the relationship between several dependent variables. We believe that sentence processing research will greatly benefit from a wider use of such methods.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\33659BYL\\10.1080@17470218.2015.1134602.pdf.pdf;D\:\\Zotero\\storage\\SS58AFVD\\Logačev and Vasishth - 2016 - Understanding underspecification A comparison of .pdf}
}

@article{loveJASPGraphicalStatistical2019,
  title = {{{JASP}}: {{Graphical Statistical Software}} for {{Common Statistical Designs}}},
  shorttitle = {{{{\textbf{JASP}}}}},
  author = {Love, Jonathon and Selker, Ravi and Marsman, Maarten and Jamil, Tahira and Dropmann, Damian and Verhagen, Josine and Ly, Alexander and Gronau, Quentin F. and Smíra, Martin and Epskamp, Sacha and Matzke, Dora and Wild, Anneliese and Knight, Patrick and Rouder, Jeffrey N. and Morey, Richard D. and Wagenmakers, Eric-Jan},
  date = {2019},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {88},
  number = {2},
  issn = {1548-7660},
  doi = {10/ggbnjf},
  url = {http://www.jstatsoft.org/v88/i02/},
  urldate = {2022-03-25},
  abstract = {This paper introduces JASP, a free graphical software package for basic statistical procedures such as t tests, ANOVAs, linear regression models, and analyses of contingency tables. JASP is open-source and differentiates itself from existing open-source solutions in two ways. First, JASP provides several innovations in user interface design; specifically, results are provided immediately as the user makes changes to options, output is attractive, minimalist, and designed around the principle of progressive disclosure, and analyses can be peer reviewed without requiring a “syntax”. Second, JASP provides some of the recent developments in Bayesian hypothesis testing and Bayesian parameter estimation. The ease with which these relatively complex Bayesian techniques are available in JASP encourages their broader adoption and furthers a more inclusive statistical reporting practice. The JASP analyses are implemented in R and a series of R packages.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\XPWKNST2\\Love et al_2019_bJASP-b.pdf}
}

@article{ludeckePerformancePackageAssessment2021,
  title = {Performance: {{An R Package}} for {{Assessment}}, {{Comparison}} and {{Testing}} of {{Statistical Models}}},
  shorttitle = {Performance},
  author = {Lüdecke, Daniel and Ben-Shachar, Mattan and Patil, Indrajeet and Waggoner, Philip and Makowski, Dominique},
  date = {2021-04-21},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {6},
  number = {60},
  pages = {3139},
  issn = {2475-9066},
  doi = {10/gk975r},
  url = {https://joss.theoj.org/papers/10.21105/joss.03139},
  urldate = {2022-04-16},
  abstract = {A crucial part of statistical analysis is evaluating a model’s quality and fit, or performance. During analysis, especially with regression models, investigating the fit of models to data also often involves selecting the best fitting model amongst many competing models. Upon investigation, fit indices should also be reported both visually and numerically to bring readers in on the investigative effort.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\GES9TP36\\Lüdecke et al. - 2021 - performance An R Package for Assessment, Comparis.pdf}
}

@article{ludtkeMoreStableEstimation2018,
  title = {More Stable Estimation of the {{STARTS}} Model: {{A Bayesian}} Approach Using {{Markov}} Chain {{Monte Carlo}} Techniques.},
  shorttitle = {More Stable Estimation of the {{STARTS}} Model},
  author = {Lüdtke, Oliver and Robitzsch, Alexander and Wagner, Jenny},
  date = {2018-09},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {23},
  number = {3},
  pages = {570--593},
  issn = {1939-1463, 1082-989X},
  doi = {10/gd86g5},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000155},
  urldate = {2022-03-29},
  abstract = {The STARTS (Stable Trait, AutoRegressive Trait, and State) model decomposes individual differences in psychological measurement across time into 3 sources of variation: a time-invariant stable component, a time-varying autoregressive component, and an occasion-specific state component. Previous simulation research and applications of the STARTS model have shown that serious estimation problems such as nonconvergence or inadmissible estimates (e.g., negative variances) frequently occur for STARTS model parameters. This article introduces a general approach to estimating the parameters of the STARTS model by employing Bayesian methods that use Markov Chain Monte Carlo (MCMC) techniques. With the specification of appropriate prior distributions, the Bayesian approach offers the advantage that the model estimates will be within the admissible range, and it should be possible to avoid estimation problems. Furthermore, we show how Bayesian methods can be used to stabilize STARTS model estimates by specifying weakly informative prior distributions for the model parameters. In a simulation study, the statistical properties (bias, root mean square error, coverage rate) of the parameter estimates obtained from the Bayesian approach are compared with those of the maximum-likelihood approach. A data example is presented to illustrate how the Bayesian approach can be used to estimate the STARTS model. Finally, further extensions of the STARTS model are discussed, and suggestions for applied research are made.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\67T89CQ3\\Lüdtke et al_2018_More stable estimation of the STARTS model.pdf}
}

@article{ludtkeRegressionModelsInvolving2020,
  title = {Regression Models Involving Nonlinear Effects with Missing Data: {{A}} Sequential Modeling Approach Using {{Bayesian}} Estimation.},
  shorttitle = {Regression Models Involving Nonlinear Effects with Missing Data},
  author = {Lüdtke, Oliver and Robitzsch, Alexander and West, Stephen G.},
  date = {2020-04},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {25},
  number = {2},
  pages = {157--181},
  issn = {1939-1463, 1082-989X},
  doi = {10/ghdxz9},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000233},
  urldate = {2022-03-26},
  abstract = {When estimating multiple regression models with incomplete predictor variables, it is necessary to specify a joint distribution for the predictor variables. A convenient assumption is that this distribution is a joint normal distribution, the default in many statistical software packages. This distribution will in general be misspecified if the predictors with missing data have nonlinear effects (e.g., x2) or are included in interaction terms (e.g., x · z). In the present article, we discuss a sequential modeling approach that can be applied to decompose the joint distribution of the variables into 2 parts: (a) a part that is due to the model of interest and (b) a part that is due to the model for the incomplete predictors. We demonstrate how the sequential modeling approach can be used to implement a multiple imputation strategy based on Bayesian estimation techniques that can accommodate rather complex substantive regression models with nonlinear effects and also allows a flexible treatment of auxiliary variables. In 4 simulation studies, we showed that the sequential modeling approach can be applied to estimate nonlinear effects in regression models with missing values on continuous, categorical, or skewed predictor variables under a broad range of conditions and investigated the robustness of the proposed approach against distributional misspecifications. We developed the R package mdmb, which facilitates a user-friendly application of the sequential modeling approach, and we present a real-data example that illustrates the flexibility of the software.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\UBKQS5PQ\\Lüdtke et al_2020_Regression models involving nonlinear effects with missing data.pdf}
}

@article{LunnEtAl:2009,
  title = {The {{BUGS}} Project: {{Evolution}}, Critique and Future Directions},
  author = {Lunn, David and Spiegelhalter, David and Thomas, Andrew and Best, Nicky},
  date = {2009},
  journaltitle = {Statistics in Medicine},
  volume = {28},
  number = {25},
  pages = {3049--3067},
  keywords = {❓ Multiple DOI}
}

@article{lyBayesianReanalysesSummary2018,
  title = {Bayesian {{Reanalyses From Summary Statistics}}: {{A Guide}} for {{Academic Consumers}}},
  author = {Ly, Alexander and Raj, Akash and Etz, Alexander and Marsman, Maarten and Gronau, Quentin F and Wagenmakers, Eric-Jan},
  date = {2018},
  pages = {8},
  abstract = {Across the social sciences, researchers have overwhelmingly used the classical statistical paradigm to draw conclusions from data, often focusing heavily on a single number: p. Recent years, however, have witnessed a surge of interest in an alternative statistical paradigm: Bayesian inference, in which probabilities are attached to parameters and models. We feel it is informative to provide statistical conclusions that go beyond a single number, and—regardless of one’s statistical preference—it can be prudent to report the results from both the classical and the Bayesian paradigms. In order to promote a more inclusive and insightful approach to statistical inference, we show how the Summary Stats module in the open-source software program JASP (https://jasp-stats.org) can provide comprehensive Bayesian reanalyses from just a few commonly reported summary statistics, such as t and N. These Bayesian reanalyses allow researchers—and also editors, reviewers, readers, and reporters—to (a) quantify evidence on a continuous scale using Bayes factors, (b) assess the robustness of that evidence to changes in the prior distribution, and (c) gauge which posterior parameter ranges are more credible than others by examining the posterior distribution of the effect size. The procedure is illustrated using Festinger and Carlsmith’s (1959) seminal study on cognitive dissonance.},
  langid = {english},
  keywords = {/unread,❓ Multiple DOI,I 级文献},
  file = {D\:\\Zotero\\storage\\5ANUYEKJ\\Ly et al_2018_Bayesian Reanalyses From Summary Statistics.pdf}
}

@article{maBayesianDecisionModels2019,
  title = {Bayesian {{Decision Models}}: {{A Primer}}},
  shorttitle = {Bayesian {{Decision Models}}},
  author = {Ma, Wei Ji},
  date = {2019-10},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {104},
  number = {1},
  pages = {164--175},
  issn = {08966273},
  doi = {10.1016/j.neuron.2019.09.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627319308402},
  urldate = {2022-04-26},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\SDTF4BJW\\Ma - 2019 - Bayesian Decision Models A Primer.pdf}
}

@book{MacKay:2003,
  title = {Information Theory, Inference and Learning Algorithms},
  author = {MacKay, David J. C.},
  date = {2003},
  publisher = {{Cambridge University Press, New York}}
}

@article{maiSoftwarePackagesBayesian2018,
  title = {Software {{Packages}} for {{Bayesian Multilevel Modeling}}},
  author = {Mai, Yujiao and Zhang, Zhiyong},
  date = {2018-07-04},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {25},
  number = {4},
  pages = {650--658},
  issn = {1070-5511, 1532-8007},
  doi = {10/gc7qsq},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2018.1431545},
  urldate = {2022-04-16},
  abstract = {Multilevel modeling is a statistical approach to analyze hierarchical data, which consist of individual observations nested within clusters. Bayesian methods is a well-known, sometimes better, alternative of Maximum likelihood methods for fitting multilevel models. Lack of userfriendly and computationally efficient software packages or programs was a main obstacle in applying Bayesian multilevel modeling. In recent years, the development of software packages for multilevel modeling with improved Bayesian algorithms and faster speed has been growing. This article aims to update the knowledge of available software packages for Bayesian multilevel modeling and therefore to promote the use of these packages. Three categories of software packages capable of Bayesian multilevel modeling including brms, MCMCglmm, glmmBUGS, Bambi, R2BayesX, BayesReg, R2MLwiN and others are introduced and compared in terms of computational efficiency, modeling capability and flexibility, as well as user-friendliness. Recommendations to practical users and suggestions for future development are also discussed.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\MIRE65YI\\Mai and Zhang - 2018 - Software Packages for Bayesian Multilevel Modeling.pdf;D\:\\Zotero\\storage\\PFWZBJWJ\\Mai_Zhang_2018_Software Packages for Bayesian Multilevel Modeling.pdf}
}

@article{makowskiBayestestRDescribingEffects2019,
  title = {{{bayestestR}}: {{Describing Effects}} and Their {{Uncertainty}}, {{Existence}} and {{Significance}} within the {{Bayesian Framework}}},
  shorttitle = {{{bayestestR}}},
  author = {Makowski, Dominique and Ben-Shachar, Mattan and Lüdecke, Daniel},
  date = {2019-08-13},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {4},
  number = {40},
  pages = {1541},
  issn = {2475-9066},
  doi = {10.21105/joss.01541},
  url = {https://joss.theoj.org/papers/10.21105/joss.01541},
  urldate = {2022-08-08},
  langid = {english},
  file = {D\:\\Zotero\\storage\\TBFVF3B6\\Makowski et al. - 2019 - bayestestR Describing Effects and their Uncertain.pdf}
}

@article{makowskiIndicesEffectExistence2019,
  title = {Indices of {{Effect Existence}} and {{Significance}} in the {{Bayesian Framework}}},
  author = {Makowski, Dominique and Ben-Shachar, Mattan S. and Chen, S. H. Annabel and Lüdecke, Daniel},
  date = {2019-12-10},
  journaltitle = {Frontiers in Psychology},
  shortjournal = {Front. Psychol.},
  volume = {10},
  pages = {2767},
  issn = {1664-1078},
  doi = {10/ggfw2j},
  url = {https://www.frontiersin.org/article/10.3389/fpsyg.2019.02767/full},
  urldate = {2022-03-25},
  abstract = {Turmoil has engulfed psychological science. Causes and consequences of the reproducibility crisis are in dispute. With the hope of addressing some of its aspects, Bayesian methods are gaining increasing attention in psychological science. Some of their advantages, as opposed to the frequentist framework, are the ability to describe parameters in probabilistic terms and explicitly incorporate prior knowledge about them into the model. These issues are crucial in particular regarding the current debate about statistical significance. Bayesian methods are not necessarily the only remedy against incorrect interpretations or wrong conclusions, but there is an increasing agreement that they are one of the keys to avoid such fallacies. Nevertheless, its flexible nature is its power and weakness, for there is no agreement about what indices of “significance” should be computed or reported. This lack of a consensual index or guidelines, such as the frequentist p-value, further contributes to the unnecessary opacity that many nonfamiliar readers perceive in Bayesian statistics. Thus, this study describes and compares several Bayesian indices, provide intuitive visual representation of their “behavior” in relationship with common sources of variance such as sample size, magnitude of effects and also frequentist significance. The results contribute to the development of an intuitive understanding of the values that researchers report, allowing to draw sensible recommendations for Bayesian statistics description, critical for the standardization of scientific reporting.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\5K5RUFAI\\Makowski et al_2019_Indices of Effect Existence and Significance in the Bayesian Framework.pdf;D\:\\Zotero\\storage\\WD8FEGC9\\Makowski et al_2019_Indices of Effect Existence and Significance in the Bayesian Framework.pdf}
}

@report{marbacherHowGoalsErase2021,
  type = {preprint},
  title = {How {{Goals Erase Framing Effects}} in {{Risky Decision Making}}},
  author = {Marbacher, Laura and Jarecki, Jana Bianca and Rieskamp, Jörg},
  date = {2021-05-13},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zawys},
  url = {https://osf.io/zawys},
  urldate = {2022-04-16},
  abstract = {Evidence has shown that goals systematically change risk preferences in repeated decisions under risk. For instance, decision makers could aim to reach goals in a limited time, such as “making at least \$1000 with ten stock investments within a year.” We test whether goal-based risky decisions differ when facing gains as compared to losses. More specifically, we examine the impact of outcome framing (gains vs. losses) and state framing (positive vs. negative resource states) on goalbased risky decisions. Our results (N=100) reveal no framing effects; instead, we find a consistently strong effect of the goal on risk preferences independent of framing. Computational modeling showed that a dynamic version of prospect theory, with a goal-dependent reference point, described 87\% of participants best. This model treats outcomes as gains and losses depending on the state-goal distance. Our results show how goals can erase standard framing effects observed in risky choices without goals.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\EMQA6MRU\\Marbacher et al. - 2021 - How Goals Erase Framing Effects in Risky Decision .pdf}
}

@article{marsmanBayesianBenefitsJASP2017,
  title = {Bayesian Benefits with {{JASP}}},
  author = {Marsman, Maarten and Wagenmakers, Eric-Jan},
  date = {2017-09-03},
  journaltitle = {European Journal of Developmental Psychology},
  shortjournal = {European Journal of Developmental Psychology},
  volume = {14},
  number = {5},
  pages = {545--555},
  issn = {1740-5629, 1740-5610},
  doi = {10/gg9p3w},
  url = {https://www.tandfonline.com/doi/full/10.1080/17405629.2016.1259614},
  urldate = {2022-03-25},
  abstract = {We illustrate the Bayesian approach to data analysis using the newly developed statistical software program JASP. With JASP, researchers are able to take advantage of the benefits that the Bayesian framework has to offer in terms of parameter estimation and hypothesis testing. The Bayesian advantages are discussed using real data on the relation between Quality of Life and Executive Functioning in children with Autism Spectrum Disorder.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\QTTR5Q57\\Marsman_Wagenmakers_2017_Bayesian benefits with JASP.pdf}
}

@article{marsmanBayesianBirdEye2017,
  title = {A {{Bayesian}} Bird's Eye View of ‘{{Replications}} of Important Results in Social Psychology’},
  author = {Marsman, Maarten and Schönbrodt, Felix D. and Morey, Richard D. and Yao, Yuling and Gelman, Andrew and Wagenmakers, Eric-Jan},
  date = {2017-01},
  journaltitle = {Royal Society Open Science},
  shortjournal = {R. Soc. open sci.},
  volume = {4},
  number = {1},
  pages = {160426},
  issn = {2054-5703},
  doi = {10/gf9db6},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsos.160426},
  urldate = {2022-03-25},
  abstract = {We applied three Bayesian methods to reanalyse the preregistered contributions to the               Social Psychology               special issue ‘Replications of Important Results in Social Psychology’ (Nosek \& Lakens. 2014 Registered reports: a method to increase the credibility of published results.               Soc. Psychol.               45               , 137–141. (               doi:10.1027/1864-9335/a000192               )). First, individual-experiment Bayesian parameter estimation revealed that for directed effect size measures, only three out of 44 central 95\% credible intervals did not overlap with zero and fell in the expected direction. For undirected effect size measures, only four out of 59 credible intervals contained values greater than                                                   0.10                                               (10\% of variance explained) and only 19 intervals contained values larger than                                                   0.05                                               . Second, a Bayesian random-effects meta-analysis for all 38               t               -tests showed that only one out of the 38 hierarchically estimated credible intervals did not overlap with zero and fell in the expected direction. Third, a Bayes factor hypothesis test was used to quantify the evidence for the null hypothesis against a default one-sided alternative. Only seven out of 60 Bayes factors indicated non-anecdotal support in favour of the alternative hypothesis (                                                                                               BF                                                                 10                                                           {$>$}                   3                                               ), whereas 51 Bayes factors indicated at least some support for the null hypothesis. We hope that future analyses of replication success will embrace a more inclusive statistical approach by adopting a wider range of complementary techniques.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\TZMZW48H\\Marsman et al_2017_A Bayesian bird's eye view of ‘Replications of important results in social.pdf}
}

@article{MatsumotoEtAl:1998,
  title = {Mersenne Twister: {{A}} 623-{{Dimensionally}} Equidistributed Uniform Pseudo-Random Number Generator},
  author = {Matsumoto, Makoto and Nishimura, Takuji},
  date = {1998-01},
  journaltitle = {ACM Transactions on Modeling and Computer Simulation},
  shortjournal = {ACM Trans. Model. Comput. Simul.},
  volume = {8},
  number = {1},
  pages = {3--30},
  doi = {10.1145/272991.272995},
  file = {D\:\\Zotero\\storage\\A32X4F4C\\Matsumoto_Nishimura_1998_Mersenne twister.pdf}
}

@article{matuschekBalancingTypeError2017,
  title = {Balancing {{Type I}} Error and Power in Linear Mixed Models},
  author = {Matuschek, Hannes and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald and Bates, Douglas},
  date = {2017-06},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {94},
  pages = {305--315},
  issn = {0749596X},
  doi = {10/gcx746},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X17300013},
  urldate = {2022-03-25},
  abstract = {Linear mixed-effects models have increasingly replaced mixed-model analyses of variance for statistical inference in factorial psycholinguistic experiments. Although LMMs have many advantages over ANOVA, like ANOVAs, setting them up for data analysis also requires some care. One simple option, when numerically possible, is to fit the full variancecovariance structure of random effects (the maximal model; Barr, Levy, Scheepers \& Tily, 2013), presumably to keep Type I error down to the nominal a in the presence of random effects. Although it is true that fitting a model with only random intercepts may lead to higher Type I error, fitting a maximal model also has a cost: it can lead to a significant loss of power. We demonstrate this with simulations and suggest that for typical psychological and psycholinguistic data, higher power is achieved without inflating Type I error rate if a model selection criterion is used to select a random effect structure that is supported by the data.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\9VFA3GZC\\Matuschek et al_2017_Balancing Type I error and power in linear mixed models.pdf}
}

@article{matuschekBalancingTypeError2017a,
  title = {Balancing {{Type I}} Error and Power in Linear Mixed Models},
  author = {Matuschek, Hannes and Kliegl, Reinhold and Vasishth, Shravan and Baayen, Harald and Bates, Douglas},
  date = {2017-06},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {94},
  pages = {305--315},
  issn = {0749596X},
  doi = {10.1016/j.jml.2017.01.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X17300013},
  urldate = {2022-09-01},
  abstract = {Linear mixed-effects models have increasingly replaced mixed-model analyses of variance for statistical inference in factorial psycholinguistic experiments. Although LMMs have many advantages over ANOVA, like ANOVAs, setting them up for data analysis also requires some care. One simple option, when numerically possible, is to fit the full variancecovariance structure of random effects (the maximal model; Barr, Levy, Scheepers \& Tily, 2013), presumably to keep Type I error down to the nominal a in the presence of random effects. Although it is true that fitting a model with only random intercepts may lead to higher Type I error, fitting a maximal model also has a cost: it can lead to a significant loss of power. We demonstrate this with simulations and suggest that for typical psychological and psycholinguistic data, higher power is achieved without inflating Type I error rate if a model selection criterion is used to select a random effect structure that is supported by the data.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\Y6XBAYPQ\\Matuschek et al. - 2017 - Balancing Type I error and power in linear mixed m.pdf}
}

@article{matzkeBayesianInferencePsychology2018,
  title = {Bayesian Inference for Psychology, Part {{III}}: {{Parameter}} Estimation in Nonstandard Models},
  shorttitle = {Bayesian Inference for Psychology, Part {{III}}},
  author = {Matzke, Dora and Boehm, Udo and Vandekerckhove, Joachim},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {77--101},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9qcp},
  url = {http://link.springer.com/10.3758/s13423-017-1394-5},
  urldate = {2022-03-25},
  abstract = {We demonstrate the use of three popular Bayesian software packages that enable researchers to estimate parameters in a broad class of models that are commonly used in psychological research. We focus on WinBUGS, JAGS, and Stan, and show how they can be interfaced from R and MATLAB. We illustrate the use of the packages through two fully worked examples; the examples involve a simple univariate linear regression and fitting a multinomial processing tree model to data from a classic false-memory experiment. We conclude with a comparison of the strengths and weaknesses of the packages. Our example code, data, and this text are available via https://osf.io/ucmaz/.},
  langid = {english},
  keywords = {/unread,II 级文献},
  file = {D\:\\Zotero\\storage\\RY8YVQY2\\Matzke et al_2018_Bayesian inference for psychology, part III.pdf}
}

@article{mayrEvidenceEpisodicRetrieval,
  title = {Evidence for Episodic Retrieval of Inadequate Prime Responses in Auditory Negative Priming},
  author = {Mayr, Susanne},
  pages = {9},
  doi = {10.1037/0096-1523.32.4.932},
  langid = {english},
  file = {D\:\\Zotero\\storage\\JKHZZEY4\\Mayr - Evidence for episodic retrieval of inadequate prim.pdf}
}

@book{McElreath:2016,
  title = {Statistical Rethinking: {{A}} Bayesian Course with Examples in {{R}} and Stan},
  author = {McElreath, Richard},
  date = {2016},
  publisher = {{CRC Press}}
}

@article{merkleBayesianLatentVariable2018,
  title = {Bayesian Latent Variable Models for the Analysis of Experimental Psychology Data},
  author = {Merkle, Edgar C. and Wang, Ting},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {256--270},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9d53},
  url = {http://link.springer.com/10.3758/s13423-016-1016-7},
  urldate = {2022-03-25},
  abstract = {In this paper, we address the use of Bayesian factor analysis and structural equation models to draw inferences from experimental psychology data. While such application is non-standard, the models are generally useful for the unified analysis of multivariate data that stem from, e.g., subjects’ responses to multiple experimental stimuli. We first review the models and the parameter identification issues inherent in the models. We then provide details on model estimation via JAGS and on Bayes factor estimation. Finally, we use the models to re-analyze experimental data on risky choice, comparing the approach to simpler, alternative methods.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\ANFV65L9\\Merkle_Wang_2018_Bayesian latent variable models for the analysis of experimental psychology data.pdf}
}

@article{meshiProblematicSocialMedia2021,
  title = {Problematic Social Media Use Is Associated with the Evaluation of Both Risk and Ambiguity during Decision Making},
  author = {Meshi, Dar and Freestone, David and Özdem-Mertens, Ceylan},
  date = {2021-10-05},
  journaltitle = {Journal of Behavioral Addictions},
  shortjournal = {JBA},
  volume = {10},
  number = {3},
  pages = {779--787},
  issn = {2062-5871, 2063-5303},
  doi = {10/gpwszd},
  url = {https://akjournals.com/view/journals/2006/10/3/article-p779.xml},
  urldate = {2022-04-16},
  abstract = {Background and aims: People can engage in excessive, maladaptive use of social media platforms. This problematic social media use mirrors substance use disorders with regard to symptoms and certain behavioral situations. For example, individuals with substance use disorders demonstrate aberrations in risk evaluations during decision making, and initial research on problematic social media use has revealed similar findings. However, these results concerning problematic social media use have been clouded by tasks that involve learning and that lack a clear demarcation between risky and ambiguous decision making. Therefore, we set out to specifically determine the relationship between problematic social media use and decision making under both risk and ambiguity, in the absence of learning. Methods: We assessed each participant’s (N 5 90) self-reported level of problematic social media use. We then had them perform the wheel of fortune task, which has participants make choices between a sure option or either a risky or ambiguous gamble. In this way, the task isolates decisions made under risk and ambiguity, and avoids trial-to-trial learning. Results: We found that the greater an individual’s problematic social media use, the more often that individual choses high-risk gambles or ambiguous gambles, regardless of the degree of ambiguity. Discussion and conclusions: Our findings indicate that greater problematic social media use is related to a greater affinity for high-risk situations and overall ambiguity. These findings have implications for the field, specifically clarifying and extending the extant literature, as well as providing future avenues for research.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\GS3NL5H3\\Meshi et al. - 2021 - Problematic social media use is associated with th.pdf}
}

@article{MetropolisEtAl:1949,
  title = {The Monte Carlo Method},
  author = {Metropolis, Nicholas and Ulam, S.},
  date = {1949},
  journaltitle = {Journal of the American Statistical Association},
  volume = {44},
  number = {247},
  pages = {335--341},
  doi = {10.1080/01621459.1949.10483310},
  file = {D\:\\Zotero\\storage\\8JWWFNH2\\Metropolis_Ulam_1949_The monte carlo method.pdf}
}

@book{MeynEtAl:2009,
  title = {Markov Chains and Stochastic Stability},
  author = {Meyn, Sean P and Tweedie, Richard L},
  date = {2009},
  publisher = {{Cambridge University Press}}
}

@article{miocevicPowerBayesianMediation2017,
  title = {Power in {{Bayesian Mediation Analysis}} for {{Small Sample Research}}},
  author = {Miočević, Milica and MacKinnon, David P. and Levy, Roy},
  date = {2017-09-03},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {24},
  number = {5},
  pages = {666--683},
  issn = {1070-5511, 1532-8007},
  doi = {10/gcph7h},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2017.1312407},
  urldate = {2022-03-25},
  abstract = {Bayesian methods have the potential for increasing power in mediation analysis (Koopman, Howe, Hollenbeck, \& Sin, 2015; Yuan \& MacKinnon, 2009). This article compares the power of Bayesian credibility intervals for the mediated effect to the power of normal theory, distribution of the product, percentile, and bias-corrected bootstrap confidence intervals at N ≤ 200. Bayesian methods with diffuse priors have power comparable to the distribution of the product and bootstrap methods, and Bayesian methods with informative priors had the most power. Varying degrees of precision of prior distributions were also examined. Increased precision led to greater power only when N ≥ 100 and the effects were small, N {$<$} 60 and the effects were large, and N {$<$} 200 and the effects were medium. An empirical example from psychology illustrated a Bayesian analysis of the single mediator model from prior selection to interpreting results.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\ISV7BCGM\\Miočević et al_2017_Power in Bayesian Mediation Analysis for Small Sample Research.pdf}
}

@article{miocevicTutorialBayesianPotential2018,
  title = {A {{Tutorial}} in {{Bayesian Potential Outcomes Mediation Analysis}}},
  author = {Miočević, Milica and Gonzalez, Oscar and Valente, Matthew J. and MacKinnon, David P.},
  date = {2018-01-02},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  shortjournal = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {25},
  number = {1},
  pages = {121--136},
  issn = {1070-5511, 1532-8007},
  doi = {10/ghwsjh},
  url = {https://www.tandfonline.com/doi/full/10.1080/10705511.2017.1342541},
  urldate = {2022-03-25},
  abstract = {Statistical mediation analysis is used to investigate intermediate variables in the relation between independent and dependent variables. Causal interpretation of mediation analyses is challenging because randomization of subjects to levels of the independent variable does not rule out the possibility of unmeasured confounders of the mediator to outcome relation. Furthermore, commonly used frequentist methods for mediation analysis compute the probability of the data given the null hypothesis, which is not the probability of a hypothesis given the data as in Bayesian analysis. Under certain assumptions, applying the potential outcomes framework to mediation analysis allows for the computation of causal effects, and statistical mediation in the Bayesian framework gives indirect effects probabilistic interpretations. This tutorial combines causal inference and Bayesian methods for mediation analysis so the indirect and direct effects have both causal and probabilistic interpretations. Steps in Bayesian causal mediation analysis are shown in the application to an empirical example.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\IG37CKE6\\Miočević et al_2018_A Tutorial in Bayesian Potential Outcomes Mediation Analysis.pdf}
}

@article{MitchellEtAl:1988,
  title = {Bayesian Variable Selection in Linear Regression},
  author = {Mitchell, T. J. and Beauchamp, J. J.},
  date = {1988},
  journaltitle = {Journal of the American Statistical Association},
  volume = {83},
  number = {404},
  pages = {1023--1032},
  keywords = {❓ Multiple DOI}
}

@article{mulderBayesianEstimationHypothesis2017,
  title = {Bayesian Estimation and Hypothesis Tests for a Circular {{Generalized Linear Model}}},
  author = {Mulder, Kees and Klugkist, Irene},
  date = {2017-10},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  volume = {80},
  pages = {4--14},
  issn = {00222496},
  doi = {10/gb4cd9},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249616300827},
  urldate = {2022-03-25},
  abstract = {Motivated by a study from cognitive psychology, we develop a Generalized Linear Model for circular data within the Bayesian framework, using the von Mises distribution. Although circular data arise in a wide variety of scientific fields, the number of methods for their analysis is limited. Our model allows inclusion of both continuous and categorical covariates. In a frequentist setting, this type of model is plagued by the likelihood surface of its regression coefficients, which is not logarithmically concave. In a Bayesian context, a weakly informative prior solves this issue, while for other parameters noninformative priors are available. In addition to an MCMC sampling algorithm, we develop Bayesian hypothesis tests based on the Bayes factor for both equality and inequality constrained hypotheses. In a simulation study, it can be seen that our method performs well. The analyses are available in the package CircGLMBayes. Finally, we apply this model to a dataset from experimental psychology, and show that it provides valuable insight for applied researchers. Extensions to dependent observations are within reach by means of the multivariate von Mises distribution.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\WMGV66KP\\Mulder_Klugkist_2017_Bayesian estimation and hypothesis tests for a circular Generalized Linear Model.pdf}
}

@unpublished{mulderBFpackFlexibleBayes2019,
  title = {{{BFpack}}: {{Flexible Bayes Factor Testing}} of {{Scientific Theories}} in {{R}}},
  shorttitle = {{{BFpack}}},
  author = {Mulder, Joris and Gu, Xin and Olsson-Collentine, Anton and Tomarken, Andrew and Böing-Messing, Florian and Hoijtink, Herbert and Meijerink, Marlyne and Williams, Donald R. and Menke, Janosch and Fox, Jean-Paul and Rosseel, Yves and Wagenmakers, Eric-Jan and van Lissa, Caspar},
  options = {useprefix=true},
  date = {2019-11-18},
  eprint = {1911.07728},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/1911.07728},
  urldate = {2022-03-25},
  abstract = {There has been a tremendous methodological development of Bayes factors for hypothesis testing in the social and behavioral sciences, and related fields. This development is due to the flexibility of the Bayes factor for testing multiple hypotheses simultaneously, the ability to test complex hypotheses involving equality as well as order constraints on the parameters of interest, and the interpretability of the outcome as the weight of evidence provided by the data in support of competing scientific theories. The available software tools for Bayesian hypothesis testing are still limited however. In this paper we present a new R-package called BFpack that contains functions for Bayes factor hypothesis testing for the many common testing problems. The software includes novel tools (i) for Bayesian exploratory testing (null vs positive vs negative effects), (ii) for Bayesian confirmatory testing (competing hypotheses with equality and/or order constraints), (iii) for common statistical analyses, such as linear regression, generalized linear models, (multivariate) analysis of (co)variance, correlation analysis, and random intercept models, (iv) using default priors, and (v) while allowing data to contain missing observations that are missing at random.},
  archiveprefix = {arXiv},
  keywords = {/unread,⛔ No DOI found,Statistics - Computation},
  file = {D\:\\Zotero\\storage\\SA253CK7\\Mulder et al_2019_BFpack.pdf}
}

@article{Muller:1997,
  title = {Integral Probability Metrics and Their Generating Classes of Functions},
  author = {Müller, Alfred},
  date = {1997},
  journaltitle = {Advances in Applied Probability},
  shortjournal = {Adv. in Appl. Probab.},
  volume = {29},
  number = {2},
  pages = {429--443},
  doi = {10.2307/1428011},
  file = {D\:\\Zotero\\storage\\EKSM67Y9\\Müller_1997_Integral probability metrics and their generating classes of functions.pdf}
}

@article{mullerMeasuringPriorSensitivity2012,
  title = {Measuring Prior Sensitivity and Prior Informativeness in Large {{Bayesian}} Models},
  author = {Müller, Ulrich K},
  date = {2012},
  journaltitle = {Journal of Monetary Economics},
  pages = {17},
  doi = {10.1016/j.jmoneco.2012.09.003},
  abstract = {In large Bayesian models, such as modern DSGE models, it is difficult to assess how much the prior affects the results. This paper derives measures of prior sensitivity and prior informativeness that account for the high dimensional interaction between prior and likelihood information. The basis for both measures is the derivative matrix of the posterior mean with respect to the prior mean, which is easily obtained from Markov Chain Monte Carlo output. We illustrate the approach by examining posterior results in the small model of Lubik and Schorfheide (2004) and the large model of Smets and Wouters (2007).},
  langid = {english},
  file = {D\:\\Zotero\\storage\\SEVNDXPB\\Müller - 2012 - Measuring prior sensitivity and prior informativen.pdf}
}

@article{muthenBayesianAnalysisMplus2010,
  title = {Bayesian {{Analysis In Mplus}}: {{A Brief Introduction}}},
  author = {Muthen, Bengt},
  date = {2010},
  pages = {92},
  langid = {english},
  keywords = {⛔ No DOI found,Bayesian,Mplus},
  file = {D\:\\Zotero\\storage\\75NBFKFZ\\Muthen_Bayesian Analysis In Mplus.pdf}
}

@article{muthUserfriendlyBayesianRegression2018,
  title = {User-Friendly {{Bayesian}} Regression Modeling: {{A}} Tutorial with Rstanarm and Shinystan},
  shorttitle = {User-Friendly {{Bayesian}} Regression Modeling},
  author = {Muth, Chelsea and Oravecz, Zita and Gabry, Jonah},
  date = {2018-04-01},
  journaltitle = {The Quantitative Methods for Psychology},
  shortjournal = {TQMP},
  volume = {14},
  number = {2},
  pages = {99--119},
  issn = {2292-1354},
  doi = {10/gdz3gn},
  url = {http://www.tqmp.org/RegularArticles/vol14-2/p099},
  urldate = {2022-03-25},
  abstract = {This tutorial provides a pragmatic introduction to specifying, estimating and interpreting single-level and hierarchical linear regression models in the Bayesian framework. We start by summarizing why one should consider the Bayesian approach to the most common forms of regression. Next we introduce the R package rstanarm for Bayesian applied regression modeling. An overview of rstanarm fundamentals accompanies step-by-step guidance for fitting a single-level regression model with the stan\_glm function, and fitting hierarchical regression models with the stan\_lmer function, illustrated with data from an experience sampling study on changes in affective states. Exploration of the results is facilitated by the intuitive and user-friendly shinystan package. Data and scripts are available on the Open Science Framework page of the project. For readers unfamiliar with R, this tutorial is self-contained to enable all researchers who apply regression techniques to try these methods with their own data. Regression modeling with the functions in the rstanarm package will be a straightforward transition for researchers familiar with their frequentist counterparts, lm (or glm) and lmer.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\VZWLG2LG\\Muth et al_2018_User-friendly Bayesian regression modeling.pdf}
}

@article{nalborczykCanWeDecode2020,
  title = {Can We Decode Phonetic Features in Inner Speech Using Surface Electromyography?},
  author = {Nalborczyk, Ladislas and Grandchamp, Romain and Koster, Ernst H. W. and Perrone-Bertolotti, Marcela and Lœvenbruck, Hélène},
  editor = {Sulpizio, Simone},
  date = {2020-05-27},
  journaltitle = {PLOS ONE},
  shortjournal = {PLoS ONE},
  volume = {15},
  number = {5},
  pages = {e0233282},
  issn = {1932-6203},
  doi = {10/gmczzf},
  url = {https://dx.plos.org/10.1371/journal.pone.0233282},
  urldate = {2021-09-14},
  abstract = {Although having a long history of scrutiny in experimental psychology, it is still controversial whether wilful inner speech (covert speech) production is accompanied by specific activity in speech muscles. We present the results of a preregistered experiment looking at the electromyographic correlates of both overt speech and inner speech production of two phonetic classes of nonwords. An automatic classification approach was undertaken to discriminate between two articulatory features contained in nonwords uttered in both overt and covert speech. Although this approach led to reasonable accuracy rates during overt speech production, it failed to discriminate inner speech phonetic content based on surface electromyography signals. However, exploratory analyses conducted at the individual level revealed that it seemed possible to distinguish between rounded and spread nonwords covertly produced, in two participants. We discuss these results in relation to the existing literature and suggest alternative ways of testing the engagement of the speech motor system during wilful inner speech production.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\ELNYPZMB\\Nalborczyk et al_2020_Can we decode phonetic features in inner speech using surface electromyography.pdf}
}

@report{Neal:1993,
  title = {Probabilistic Inference Using {{Markov Chain Monte Carlo}} Methods},
  author = {Neal, R.M.},
  date = {1993},
  number = {CRG-TR-93-1},
  institution = {{Department of Computer Science, University of Toronto}}
}

@article{Neal:2003,
  title = {Slice Sampling},
  author = {Neal, R.M.},
  date = {2003},
  journaltitle = {Annals of statistics},
  pages = {705--741},
  keywords = {⛔ No DOI found}
}

@article{nengjunyiBayesianMethodsHigh2013,
  title = {Bayesian {{Methods}} for {{High Dimensional Linear Models}}},
  author = {Nengjun Yi, Himel Mallick},
  date = {2013},
  journaltitle = {Journal of Biometrics \& Biostatistics},
  shortjournal = {J Biom Biostat},
  issn = {21556180},
  doi = {10/gprpbb},
  url = {https://www.omicsonline.org/bayesian-methods-for-high-dimensional-linear-models-2155-6180.S1-005.php?aid=15156},
  urldate = {2022-03-25},
  abstract = {In this article, we present a selective overview of some recent developments in Bayesian model and variable selection methods for high dimensional linear models. While most of the reviews in literature are based on conventional methods, we focus on recently developed methods, which have proven to be successful in dealing with high dimensional variable selection. First, we give a brief overview of the traditional model selection methods (viz. Mallow’s Cp, AIC, BIC, DIC), followed by a discussion on some recently developed methods (viz. EBIC, regularization), which have occupied the minds of many statisticians. Then, we review high dimensional Bayesian methods with a particular emphasis on Bayesian regularization methods, which have been used extensively in recent years. We conclude by briefly addressing the asymptotic behaviors of Bayesian variable selection methods for high dimensional linear models under different regularity conditions.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\HHZNSUNR\\Nengjun Yi_2013_Bayesian Methods for High Dimensional Linear Models.pdf}
}

@article{ngUsingGammaGeneralized2017,
  title = {Using the {{Gamma Generalized Linear Model}} for {{Modeling Continuous}}, {{Skewed}} and {{Heteroscedastic Outcomes}} in {{Psychology}}},
  author = {Ng, Victoria K.Y. and Cribbie, Robert A.},
  date = {2017-06},
  journaltitle = {Current Psychology},
  shortjournal = {Curr Psychol},
  volume = {36},
  number = {2},
  pages = {225--235},
  issn = {1046-1310, 1936-4733},
  doi = {10/gbks66},
  url = {http://link.springer.com/10.1007/s12144-015-9404-0},
  urldate = {2022-03-25},
  abstract = {Some researchers in psychology have ordinarily relied on traditional linear models when assessing the relationship between predictor(s) and a continuous outcome, even when the assumptions of the traditional model (e.g., normality, homoscedasticity) are not satisfied. Of those who abandon the traditional linear model, some opt for robust versions of the ANOVA and regression statistics that usually focus on relationships for the typical or average case instead of trying to model relationships for the full range of relevant cases. Generalized linear models, on the other hand, model the relationships among variables using all available and relevant data and can be appropriate under certain conditions of non-normality and heteroscedasticity. In this paper, we summarize the advantages and limitations of using generalized linear models with continuous outcomes and provide two simplified examples that highlight the methodology involved in selecting, comparing, and interpreting models for positively skewed outcomes and certain heteroscedastic relationships.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\ELJVQJX6\\Ng_Cribbie_2017_Using the Gamma Generalized Linear Model for Modeling Continuous, Skewed and.pdf}
}

@article{nguyenBayesianAnalysisSocial,
  title = {Bayesian Analysis in Social Sciences},
  author = {Nguyen, Minh-Hoang},
  pages = {6},
  doi = {10/gpwszb},
  langid = {english},
  file = {D\:\\Zotero\\storage\\E4UJIQ8U\\Nguyen - Bayesian analysis in social sciences.pdf}
}

@article{nicenboimAreWordsPreactivated2020a,
  title = {Are Words Pre-Activated Probabilistically during Sentence Comprehension? {{Evidence}} from New Data and a {{Bayesian}} Random-Effects Meta-Analysis Using Publicly Available Data},
  shorttitle = {Are Words Pre-Activated Probabilistically during Sentence Comprehension?},
  author = {Nicenboim, Bruno and Vasishth, Shravan and Rösler, Frank},
  date = {2020-05},
  journaltitle = {Neuropsychologia},
  shortjournal = {Neuropsychologia},
  volume = {142},
  pages = {107427},
  issn = {00283932},
  doi = {10.1016/j.neuropsychologia.2020.107427},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0028393220300981},
  urldate = {2021-09-14},
  abstract = {Several studies (e.g., Wicha et al., 2003b; DeLong et al., 2005) have shown that readers use information from the sentential context to predict nouns (or some of their features), and that predictability effects can be inferred from the EEG signal in determiners or adjectives appearing before the predicted noun. While these findings provide evidence for the pre-activation proposal, recent replication attempts together with inconsistencies in the results from the literature cast doubt on the robustness of this phenomenon. Our study presents the first attempt to use the effect of gender on predictability in German to study the pre-activation hypothesis, capitalizing on the fact that all German nouns have a gender and that their preceding determiners can show an unambiguous gender marking when the noun phrase has accusative case. Despite having a relatively large sample size (of 120 sub­ jects), both our preregistered and exploratory analyses failed to yield conclusive evidence for or against an effect of pre-activation. The sign of the effect is, however, in the expected direction: the more unexpected the gender of the determiner, the larger the negativity. The recent, inconclusive replication attempts by Nieuwland et al. (2018) and others also show effects with signs in the expected direction. We conducted a Bayesian random-ef­ fects meta-analysis using our data and the publicly available data from these recent replication attempts. Our meta-analysis shows a relatively clear but very small effect that is consistent with the pre-activation account and demonstrates a very important advantage of the Bayesian data analysis methodology: we can incrementally accumulate evidence to obtain increasingly precise estimates of the effect of interest.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\AMY2XW57\\Nicenboim et al_2020_Are words pre-activated probabilistically during sentence comprehension.pdf}
}

@article{nicenboimModelsRetrievalSentence2018,
  title = {Models of Retrieval in Sentence Comprehension: {{A}} Computational Evaluation Using {{Bayesian}} Hierarchical Modeling},
  shorttitle = {Models of Retrieval in Sentence Comprehension},
  author = {Nicenboim, Bruno and Vasishth, Shravan},
  date = {2018-04},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {99},
  pages = {1--34},
  issn = {0749596X},
  doi = {10/gfpbph},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X16301577},
  urldate = {2022-03-25},
  abstract = {Research on similarity-based interference has provided extensive evidence that the formation of dependencies between non-adjacent words relies on a cue-based retrieval mechanism. There are two different models that can account for one of the main predictions of interference, i.e., a slowdown at a retrieval site, when several items share a feature associated with a retrieval cue: Lewis and Vasishth’s (2005) activation-based model and McElree’s (2000) direct-access model. Even though these two models have been used almost interchangeably, they are based on different assumptions and predict differences in the relationship between reading times and response accuracy. The activation-based model follows the assumptions of the ACT-R framework, and its retrieval process behaves as a lognormal race between accumulators of evidence with a single variance. Under this model, accuracy of the retrieval is determined by the winner of the race and retrieval time by its rate of accumulation. In contrast, the directaccess model assumes a model of memory where only the probability of retrieval can be affected, while the retrieval time is drawn from the same distribution; in this model, differences in latencies are a byproduct of the possibility of backtracking and repairing incorrect retrievals. We implemented both models in a Bayesian hierarchical framework in order to evaluate them and compare them. The data show that correct retrievals take longer than incorrect ones, and this pattern is better fit under the directaccess model than under the activation-based model. This finding does not rule out the possibility that retrieval may be behaving as a race model with assumptions that follow less closely the ones from the ACT-R framework. By introducing a modification of the activation model, i.e., by assuming that the accumulation of evidence for retrieval of incorrect items is not only slower but noisier (i.e., different variances for the correct and incorrect items), the model can provide a fit as good as the one of the direct-access model. This first ever computational evaluation of alternative accounts of retrieval processes in sentence processing opens the way for a broader investigation of theories of dependency completion.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\RQ6QIC5J\\Nicenboim and Vasishth - 2018 - Models of retrieval in sentence comprehension A c.pdf;D\:\\Zotero\\storage\\TWIRRRK5\\Nicenboim_Vasishth_2018_Models of retrieval in sentence comprehension.pdf}
}

@misc{NISTSTS:2020,
  title = {A Statistical Test Suite for Random and Pseudorandom Number Generators for Cryptographic Applications},
  author = {Team, Random Bit Generation},
  date = {2020-06},
  url = {https://csrc.nist.gov/Projects/Random-Bit-Generation/Documentation-and-Software}
}

@article{nivDialoguesPredictionErrors2008,
  title = {Dialogues on Prediction Errors},
  author = {Niv, Yael and Schoenbaum, Geoffrey},
  date = {2008-07},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {12},
  number = {7},
  pages = {265--272},
  issn = {13646613},
  doi = {10/b6kzkj},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S136466130800137X},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\NCLGPKL2\\Niv_Schoenbaum_2008_Dialogues on prediction errors.pdf}
}

@article{nogarottoBayesianModelingPrior2018,
  title = {Bayesian {{Modeling}} and {{Prior Sensitivity Analysis}} for {{Zero-One Augmented Beta Regression Models}} with an {{Application}} to {{Psychometric Data}}},
  author = {Nogarotto, Danilo Covaes and Azevedo, Caio Lucidius Naberezny and Bazán, Jorge Luis},
  date = {2018},
  pages = {27},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\N7Q3I2AJ\\Nogarotto et al. - 2018 - Bayesian Modeling and Prior Sensitivity Analysis f.pdf}
}

@article{ohaganBayesianHeavytailedModels2012,
  title = {Bayesian Heavy-Tailed Models and Conflict Resolution: {{A}} Review},
  shorttitle = {Bayesian Heavy-Tailed Models and Conflict Resolution},
  author = {O’Hagan, Anthony and Pericchi, Luis},
  date = {2012-11-01},
  journaltitle = {Brazilian Journal of Probability and Statistics},
  shortjournal = {Braz. J. Probab. Stat.},
  volume = {26},
  number = {4},
  issn = {0103-0752},
  doi = {10/gprpf5},
  url = {https://projecteuclid.org/journals/brazilian-journal-of-probability-and-statistics/volume-26/issue-4/Bayesian-heavy-tailed-models-and-conflict-resolution-A-review/10.1214/11-BJPS164.full},
  urldate = {2022-03-25},
  abstract = {We review a substantial literature, spanning 50 years, concerning the resolution of conflicts using Bayesian heavy-tailed models. Conflicts arise when different sources of information about the model parameters (e.g., prior information, or the information in individual observations) suggest quite different plausible regions for those parameters. Traditional Bayesian models based on normal distributions or other conjugate structures typically resolve conflicts by centring the posterior at some compromise position, but this is not a realistic resolution when it means that the posterior is then in conflict with the different information sources. Bayesian modelling with heavy-tailed distributions has been shown to produce more reasonable conflict resolution, typically by favouring one source of information over the other. The less favoured source is ultimately wholly or partially rejected as the conflict becomes increasingly extreme.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\DWIGHACL\\O’Hagan_Pericchi_2012_Bayesian heavy-tailed models and conflict resolution.pdf;D\:\\Zotero\\storage\\MJXJTMGX\\O’Hagan_Pericchi_2012_Bayesian heavy-tailed models and conflict resolution.pdf}
}

@article{oharaReviewBayesianVariable2009,
  title = {A Review of {{Bayesian}} Variable Selection Methods: What, How and Which},
  shorttitle = {A Review of {{Bayesian}} Variable Selection Methods},
  author = {O'Hara, R. B. and Sillanpää, M. J.},
  date = {2009-03-01},
  journaltitle = {Bayesian Analysis},
  shortjournal = {Bayesian Anal.},
  volume = {4},
  number = {1},
  issn = {1936-0975},
  doi = {10/cft92v},
  url = {https://projecteuclid.org/journals/bayesian-analysis/volume-4/issue-1/A-review-of-Bayesian-variable-selection-methods--what-how/10.1214/09-BA403.full},
  urldate = {2022-03-25},
  abstract = {The selection of variables in regression problems has occupied the minds of many statisticians. Several Bayesian variable selection methods have been developed, and we concentrate on the following methods: Kuo \& Mallick, Gibbs Variable Selection (GVS), Stochastic Search Variable Selection (SSVS), adaptive shrinkage with Jeffreys’ prior or a Laplacian prior, and reversible jump MCMC. We review these methods, in the context of their different properties. We then implement the methods in BUGS, using both real and simulated data as examples, and investigate how the different methods perform in practice. Our results suggest that SSVS, reversible jump MCMC and adaptive shrinkage methods can all work well, but the choice of which method is better will depend on the priors that are used, and also on how they are implemented.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\3ZQI39DY\\O'Hara_Sillanpää_2009_A review of Bayesian variable selection methods.pdf}
}

@report{ONeill:2014,
  title = {{{PCG}}: {{A}} Family of Simple Fast Space-Efficient Statistically Good Algorithms for Random Number Generation},
  author = {O'Neill, Melissa E.},
  date = {2014-09},
  number = {HMC-CS-2014-0905},
  institution = {{Harvey Mudd College}},
  location = {{Claremont, CA}}
}

@article{oraveczFittingGrowthCurve2018,
  title = {Fitting Growth Curve Models in the {{Bayesian}} Framework},
  author = {Oravecz, Zita and Muth, Chelsea},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {235--255},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9jwd},
  url = {http://link.springer.com/10.3758/s13423-017-1281-0},
  urldate = {2022-03-25},
  abstract = {Growth curve modeling is a popular methodological tool due to its flexibility in simultaneously analyzing both within-person effects (e.g., assessing change over time for one person) and between-person effects (e.g., comparing differences in the change trajectories across people). This paper is a practical exposure to fitting growth curve models in the hierarchical Bayesian framework. First the mathematical formulation of growth curve models is provided. Then we give step-by-step guidelines on how to fit these models in the hierarchical Bayesian framework with corresponding computer scripts (JAGS and R). To illustrate the Bayesian GCM approach, we analyze a data set from a longitudinal study of marital relationship quality. We provide our computer code and example data set so that the reader can have hands-on experience fitting the growth curve model.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\92TGTEG4\\Oravecz_Muth_2018_Fitting growth curve models in the Bayesian framework.pdf}
}

@book{Owen:2013,
  title = {Monte Carlo Theory, Methods, and Examples},
  author = {Owen, Art B.},
  date = {2013}
}

@inproceedings{PapaspiliopoulosEtAl:2003,
  title = {Non-Centered Parameterisations for Hierarchical Models and Data Augmentation},
  booktitle = {Bayesian Statistics 7: {{Proceedings}} of the Seventh Valencia International Meeting},
  author = {Papaspiliopoulos, Omiros and Roberts, Gareth O and Sköld, Martin},
  editor = {Bernardo, JM and Bayarri, MJ and Berger, JO and Dawid, AP and Heckerman, D and Smith, AFM and West, M},
  date = {2003},
  volume = {307},
  organization = {{Oxford University Press, USA}},
  keywords = {⛔ No DOI found}
}

@article{PapaspiliopoulosEtAl:2007,
  title = {A General Framework for the Parametrization of Hierarchical Models},
  author = {Papaspiliopoulos, Omiros and Roberts, Gareth O and Sköld, Martin},
  date = {2007},
  journaltitle = {Statistical Science},
  pages = {59--73},
  keywords = {⛔ No DOI found}
}

@article{parolaVoicePatternsSchizophrenia2020a,
  title = {Voice Patterns in Schizophrenia: {{A}} Systematic Review and {{Bayesian}} Meta-Analysis},
  shorttitle = {Voice Patterns in Schizophrenia},
  author = {Parola, Alberto and Simonsen, Arndis and Bliksted, Vibeke and Fusaroli, Riccardo},
  date = {2020-02},
  journaltitle = {Schizophrenia Research},
  shortjournal = {Schizophrenia Research},
  volume = {216},
  pages = {24--40},
  issn = {09209964},
  doi = {10.1016/j.schres.2019.11.031},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0920996419305389},
  urldate = {2021-09-15},
  abstract = {Voice atypicalities have been a characteristic feature of schizophrenia since its first definitions. They are often associated with core negative symptoms such as flat affect and alogia, and with the social impairments seen in the disorder. This suggests that voice atypicalities may represent a marker of clinical features and social functioning in schizophrenia. We systematically reviewed and meta-analyzed the evidence for distinctive acoustic patterns in schizophrenia, as well as their relation to clinical features. We identified 46 articles, including 55 studies with a total of 1254 patients with schizophrenia and 699 healthy controls. Summary effect sizes (Hedges'g and Pearson's r) estimates were calculated using multilevel Bayesian modeling. We identified weak atypicalities in pitch variability (g = −0.55) related to flat affect, and stronger atypicalities in proportion of spoken time, speech rate, and pauses (g's between −0.75 and −1.89) related to alogia and flat affect. However, the effects were mostly modest (with the important exception of pause duration) compared to perceptual and clinical judgments, and characterized by large heterogeneity between studies. Moderator analyses revealed that tasks with a more demanding cognitive and social component showed larger effects both in contrasting patients and controls and in assessing symptomatology. In conclusion, studies of acoustic patterns are a promising but, yet unsystematic avenue for establishing markers of schizophrenia. We outline recommendations towards more cumulative, open, and theorydriven research.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\RF4AAX3C\\Parola et al_2020_Voice patterns in schizophrenia.pdf}
}

@article{parpartHeuristicsBayesianInference2018,
  title = {Heuristics as {{Bayesian}} Inference under Extreme Priors},
  author = {Parpart, Paula and Jones, Matt and Love, Bradley C.},
  date = {2018-05},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {102},
  pages = {127--144},
  issn = {00100285},
  doi = {10/gdfgxb},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028517303286},
  urldate = {2022-03-25},
  abstract = {Simple heuristics are often regarded as tractable decision strategies because they ignore a great deal of information in the input data. One puzzle is why heuristics can outperform full-information models, such as linear regression, which make full use of the available information. These “lessis-more” effects, in which a relatively simpler model outperforms a more complex model, are prevalent throughout cognitive science, and are frequently argued to demonstrate an inherent advantage of simplifying computation or ignoring information. In contrast, we show at the computational level (where algorithmic restrictions are set aside) that it is never optimal to discard information. Through a formal Bayesian analysis, we prove that popular heuristics, such as tallying and take-the-best, are formally equivalent to Bayesian inference under the limit of infinitely strong priors. Varying the strength of the prior yields a continuum of Bayesian models with the heuristics at one end and ordinary regression at the other. Critically, intermediate models perform better across all our simulations, suggesting that down-weighting information with the appropriate prior is preferable to entirely ignoring it. Rather than because of their simplicity, our analyses suggest heuristics perform well because they implement strong priors that approximate the actual structure of the environment. We end by considering how new heuristics could be derived by infinitely strengthening the priors of other Bayesian models. These formal results have implications for work in psychology, machine learning and economics.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\DAVWW7I4\\Parpart et al_2018_Heuristics as Bayesian inference under extreme priors.pdf}
}

@article{patwardhanNonlinearBayesianState2012,
  title = {Nonlinear {{Bayesian}} State Estimation: {{A}} Review of Recent Developments},
  shorttitle = {Nonlinear {{Bayesian}} State Estimation},
  author = {Patwardhan, Sachin C. and Narasimhan, Shankar and Jagadeesan, Prakash and Gopaluni, Bhushan and L. Shah, Sirish},
  date = {2012-10},
  journaltitle = {Control Engineering Practice},
  shortjournal = {Control Engineering Practice},
  volume = {20},
  number = {10},
  pages = {933--953},
  issn = {09670661},
  doi = {10/f39tp5},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0967066112000871},
  urldate = {2022-03-25},
  abstract = {Online estimation of the internal states is a perquisite for monitoring, control, and fault diagnosis of many engineering processes. A cost effective approach to monitor these variables in real time is to employ model-based state estimation techniques. Dynamic model-based state estimation is a rich and highly active area of research and many novel approaches have emerged over the last few years. In this paper, we review various recent developments in the area of nonlinear state estimators from a Bayesian perspective. In particular, we focus on the constrained state estimation (including systems modeled using differential-algebraic equations), the handling of multi-rate and delayed measurements and recent advances in model parameter estimation. Recent advances on the stability analysis of the estimation error dynamics are also briefly discussed. The review aims to provide an integrated view of important ideas, from the authors’ perspective that have driven the research in this area in recent years. \& 2012 Elsevier Ltd. All rights reserved.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\AQRUH6WU\\Patwardhan et al_2012_Nonlinear Bayesian state estimation.pdf}
}

@book{Pavliotis:2006,
  title = {Stochastic Processes and Applications},
  author = {Pavliotis, Grigorios A.},
  date = {2014},
  series = {Texts in Applied Mathematics},
  volume = {60},
  publisher = {{Springer, New York}}
}

@article{Pearl:2009,
  title = {Causal Inference in Statistics: An Overview},
  author = {Pearl, Judea},
  date = {2009},
  journaltitle = {Statistics Surveys},
  shortjournal = {Stat. Surv.},
  volume = {3},
  pages = {96--146},
  doi = {10.1214/09-SS057},
  file = {D\:\\Zotero\\storage\\EZCPA93W\\Pearl_2009_Causal inference in statistics.pdf}
}

@article{petzschnerBayesianPerspectiveMagnitude2015,
  title = {A {{Bayesian}} Perspective on Magnitude Estimation},
  author = {Petzschner, Frederike H. and Glasauer, Stefan and Stephan, Klaas E.},
  date = {2015-05},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {19},
  number = {5},
  pages = {285--293},
  issn = {13646613},
  doi = {10/gprpgn},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661315000509},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\A6EY3SPQ\\Petzschner et al_2015_A Bayesian perspective on magnitude estimation.pdf}
}

@article{Pickands:1975,
  title = {Statistical Inference Using Extreme Order Statistics},
  author = {III, James Pickands},
  date = {1975},
  journaltitle = {The Annals of Statistics},
  volume = {3},
  number = {1},
  pages = {119--131},
  doi = {10.1214/aos/1176343003},
  file = {D\:\\Zotero\\storage\\GKV98QD2\\III_1975_Statistical inference using extreme order statistics.pdf}
}

@article{PiironenEtAl:2017b,
  title = {Comparison of {{Bayesian}} Predictive Methods for Model Selection},
  author = {Piironen, Juho and Vehtari, Aki},
  date = {2017-05-01},
  journaltitle = {Statistics and Computing},
  volume = {27},
  number = {3},
  pages = {711--735},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9649-y},
  url = {https://doi.org/10.1007/s11222-016-9649-y},
  file = {D\:\\Zotero\\storage\\LA3MEVN5\\Piironen_Vehtari_2017_Comparison of Bayesian predictive methods for model selection.pdf}
}

@article{piironenSparsityInformationRegularization2017,
  title = {Sparsity Information and Regularization in the Horseshoe and Other Shrinkage Priors},
  author = {Piironen, Juho and Vehtari, Aki},
  date = {2017},
  shortjournal = {Electron. J. Statist.},
  volume = {11},
  number = {2},
  pages = {5018--5051},
  publisher = {{The Institute of Mathematical Statistics and the Bernoulli Society}},
  doi = {10.1214/17-EJS1337SI},
  url = {https://doi.org/10.1214/17-EJS1337SI},
  fjournal = {Electronic Journal of Statistics},
  file = {D\:\\Zotero\\storage\\4PCHR4HS\\Piironen_Vehtari_2017_Sparsity information and regularization in the horseshoe and other shrinkage.pdf;D\:\\Zotero\\storage\\LUH2HS9G\\Piironen_Vehtari_2017_Sparsity information and regularization in the horseshoe and other shrinkage.pdf}
}

@article{PowerAnalysisStructural2022,
  title = {Power analysis in structural equation modeling: Principles and methods},
  shorttitle = {Power analysis in structural equation modeling},
  date = {2022},
  journaltitle = {Advances in Psychological Science},
  shortjournal = {Advances in Psychological Science},
  volume = {30},
  number = {9},
  pages = {2117},
  issn = {1671-3710},
  doi = {10.3724/SP.J.1042.2022.02117},
  url = {https://journal.psych.ac.cn/xlkxjz/CN/10.3724/SP.J.1042.2022.02117},
  urldate = {2022-08-07},
  langid = {chinese},
  file = {D\:\\Zotero\\storage\\JNHUKGVA\\2022 - Power analysis in structural equation modeling Pr.pdf}
}

@article{pranckeviciusComparisonNaiveBayes2017,
  title = {Comparison of {{Naive Bayes}}, {{Random Forest}}, {{Decision Tree}}, {{Support Vector Machines}}, and {{Logistic Regression Classifiers}} for {{Text Reviews Classification}}},
  author = {Pranckevičius, Tomas and Marcinkevičius, Virginijus},
  date = {2017},
  journaltitle = {Baltic Journal of Modern Computing},
  shortjournal = {BJMC},
  volume = {5},
  number = {2},
  issn = {22558950},
  doi = {10/gj4p7p},
  url = {http://www.bjmc.lu.lv/fileadmin/user_upload/lu_portal/projekti/bjmc/Contents/5_2_05_Pranckevicius.pdf},
  urldate = {2022-03-25},
  abstract = {Today, a largely scalable computing environment provides a possibility of carrying out various data-intensive natural language processing and machine-learning tasks. One of these is text classification with some issues recently investigated by many data scientists. The authors of this paper investigate Naïve Bayes, Random Forest, Decision Tree, Support Vector Machines, and Logistic Regression classifiers implemented in Apache Spark, i.e. the in-memory intensive computing platform. The focus of the paper is on comparing these classifiers by evaluating the classification accuracy, based on the size of training data sets, and the number of n-grams. In experiments, short texts for product-review data from Amazon1 were analyzed.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\4WKFXXS7\\Pranckevičius_Marcinkevičius_2017_Comparison of Naive Bayes, Random Forest, Decision Tree, Support Vector.pdf}
}

@unpublished{prangleSummaryStatisticsApproximate2015,
  title = {Summary {{Statistics}} in {{Approximate Bayesian Computation}}},
  author = {Prangle, Dennis},
  date = {2015-12-17},
  eprint = {1512.05633},
  eprinttype = {arxiv},
  primaryclass = {math, stat},
  url = {http://arxiv.org/abs/1512.05633},
  urldate = {2022-03-26},
  abstract = {This document is due to appear as a chapter of the forthcoming Handbook of Approximate Bayesian Computation (ABC) edited by S. Sisson, Y. Fan, and M. Beaumont. Since the earliest work on ABC, it has been recognised that using summary statistics is essential to produce useful inference results. This is because ABC suffers from a curse of dimensionality effect, whereby using high dimensional inputs causes large approximation errors in the output. It is therefore crucial to find low dimensional summaries which are informative about the parameter inference or model choice task at hand. This chapter reviews the methods which have been proposed to select such summaries, extending the previous review paper of Blum et al. (2013) with recent developments. Related theoretical results on the ABC curse of dimensionality and sufficiency are also discussed.},
  archiveprefix = {arXiv},
  keywords = {/unread,⛔ No DOI found,Mathematics - Statistics Theory,Statistics - Computation,Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\MN4E7PAU\\Prangle_2015_Summary Statistics in Approximate Bayesian Computation.pdf}
}

@book{PressEtAl:2007,
  title = {Numerical Recipes: {{The}} Art of Scientific Computing},
  author = {Press, William H and Teukolsky, Saul A and Vetterling, William T and Flannery, Brian P},
  date = {2007},
  edition = {3rd},
  publisher = {{Cambridge Universit Press}}
}

@article{priceNeuroplasticityCognitivePsychological2020,
  title = {Neuroplasticity in Cognitive and Psychological Mechanisms of Depression: An Integrative Model},
  shorttitle = {Neuroplasticity in Cognitive and Psychological Mechanisms of Depression},
  author = {Price, Rebecca B. and Duman, Ronald},
  date = {2020-03},
  journaltitle = {Molecular Psychiatry},
  shortjournal = {Mol Psychiatry},
  volume = {25},
  number = {3},
  pages = {530--543},
  issn = {1359-4184, 1476-5578},
  doi = {10/ghmnzm},
  url = {http://www.nature.com/articles/s41380-019-0615-x},
  urldate = {2022-04-16},
  abstract = {Chronic stress and depressive-like behaviors in basic neuroscience research have been associated with impairments of neuroplasticity, such as neuronal atrophy and synaptic loss in the medial prefrontal cortex (mPFC) and hippocampus. The current review presents a novel integrative model of neuroplasticity as a multi-domain neurobiological, cognitive, and psychological construct relevant in depression and other related disorders of negative affect (e.g., anxiety). We delineate a working conceptual model in which synaptic plasticity deficits described in animal models are integrated and conceptually linked with human patient findings from cognitive science and clinical psychology. We review relevant reports including neuroimaging findings (e.g., decreased functional connectivity in prefrontal-limbic circuits), cognitive deficits (e.g., executive function and memory impairments), affective information processing patterns (e.g., rigid, negative biases in attention, memory, interpretations, and self-associations), and patient-reported symptoms (perseverative, inflexible thought patterns; inflexible and maladaptive behaviors). Finally, we incorporate discussion of integrative research methods capable of building additional direct empirical support, including using rapid-acting treatments (e.g., ketamine) as a means to test this integrative model by attempting to simultaneously reverse these deficits across levels of analysis.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\SUAAH8KH\\Price and Duman - 2020 - Neuroplasticity in cognitive and psychological mec.pdf}
}

@article{QinEtAl:2020,
  title = {On the Limitations of Single-Step Drift and Minorization in {{Markov}} Chain Convergence Analysis},
  author = {Qin, Qian and Hobert, James P.},
  date = {2020-03},
  journaltitle = {arXiv e-prints},
  number = {2003.09555},
  keywords = {⛔ No DOI found}
}

@book{RasmussenEtAl:2006,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{MIT Press, Cambridge, MA}}
}

@article{raudenbushEducationalApplicationsHierarchical1988,
  title = {Educational {{Applications}} of {{Hierarchical Linear Models}}: {{A Review}}},
  shorttitle = {Educational {{Applications}} of {{Hierarchical Linear Models}}},
  author = {Raudenbush, Stephen W.},
  date = {1988-06},
  journaltitle = {Journal of Educational Statistics},
  shortjournal = {Journal of Educational Statistics},
  volume = {13},
  number = {2},
  pages = {85--116},
  issn = {0362-9791},
  doi = {10/dz7p6f},
  url = {http://journals.sagepub.com/doi/10.3102/10769986013002085},
  urldate = {2022-03-25},
  abstract = {The search for appropriate statistical methods for hierarchical, multilevel data has been a prominent theme in educational statistics over the past 15 years. As a result of this search, an important class of models, termed hierarchical linear models by this review, has emerged. In the paradigmatic application of such models, observations within each group (e.g., classroom or school) vary as a function of group-level or “microparameters.” However, these microparameters vary randomly across the population of groups as a function of “macroparameters.” Research interest has focused on estimation of both micro- and macroparameters. This paper reviews estimation theory and application of such models. Also, the logic of these methods is extended beyond the paradigmatic case to include research domains as diverse as panel studies, meta-analysis, and classical test theory. Microparameters to be estimated may be as diverse as means, proportions, variances, linear regression coefficients, and logit linear regression coefficients. Estimation theory is reviewed from Bayes and empirical Bayes viewpoints and the examples considered involve data sets with two levels of hierarchy.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\KYEZD6HP\\Raudenbush_1988_Educational Applications of Hierarchical Linear Models.pdf}
}

@book{rencherLinearModelsStatistics2008,
  title = {Linear Models in Statistics},
  author = {Rencher, Alvin C. and Schaalje, G. Bruce},
  date = {2008},
  edition = {2nd ed},
  publisher = {{Wiley-Interscience}},
  location = {{Hoboken, N.J}},
  isbn = {978-0-471-75498-5},
  langid = {english},
  pagetotal = {672},
  keywords = {/unread,Linear models (Statistics)},
  annotation = {OCLC: ocn144331522},
  file = {D\:\\Zotero\\storage\\WRB48E9A\\Rencher_Schaalje_2008_Linear models in statistics.pdf}
}

@article{robertBayesianComputationalTools2014,
  title = {Bayesian {{Computational Tools}}},
  author = {Robert, Christian P.},
  date = {2014-01-03},
  journaltitle = {Annual Review of Statistics and Its Application},
  shortjournal = {Annu. Rev. Stat. Appl.},
  volume = {1},
  number = {1},
  pages = {153--177},
  issn = {2326-8298, 2326-831X},
  doi = {10/gprpf3},
  url = {https://www.annualreviews.org/doi/10.1146/annurev-statistics-022513-115543},
  urldate = {2022-03-25},
  abstract = {This article surveys advances in the field of Bayesian computation over the past 20 years from a purely personal viewpoint, hence containing some ommissions given the spectrum of the field. Monte Carlo, MCMC, and ABC themes are covered here, whereas the rapidly expanding area of particle methods is only briefly mentioned and different approximative techniques such as variational Bayes and linear Bayes methods do not appear at all. This article also contains some novel computational entries on the doubleexponential model that may be of interest.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\APUMCMC5\\Robert_2014_Bayesian Computational Tools.pdf;D\:\\Zotero\\storage\\FTSW3BPI\\Robert_2014_Bayesian Computational Tools.pdf}
}

@book{RobertEtAl:1999,
  title = {Monte {{Carlo}} Statistical Methods},
  author = {Robert, Christian P and Casella, George},
  date = {1999},
  publisher = {{Springer New York}}
}

@article{RobertsEtAl:1997,
  title = {Weak Convergence and Optimal Scaling of {{Random Walk Metropolis}} Algorithms},
  author = {Roberts, Gareth O and Gelman, Andrew and Gilks, Walter R and others},
  date = {1997},
  journaltitle = {The annals of applied probability},
  volume = {7},
  number = {1},
  pages = {110--120},
  keywords = {⛔ No DOI found}
}

@article{RobertsEtAl:1997b,
  title = {Geometric Ergodicity and Hybrid {{Markov}} Chains},
  author = {Roberts, Gareth O. and Rosenthal, Jeffrey S.},
  date = {1997},
  journaltitle = {Electronic Communications in Probability},
  shortjournal = {Electron. Comm. Probab.},
  volume = {2},
  pages = {no. 2, 13--25},
  doi = {10.1214/ECP.v2-981},
  file = {D\:\\Zotero\\storage\\VHYKANQF\\Roberts_Rosenthal_1997_Geometric ergodicity and hybrid Markov chains.pdf}
}

@article{RobertsEtAl:2004,
  title = {General State Space {{Markov}} Chains and {{MCMC}} Algorithms},
  author = {Roberts, Gareth O and Rosenthal, Jeffrey S},
  date = {2004},
  journaltitle = {Probability Surveys},
  volume = {1},
  pages = {20--71},
  doi = {10.1214/154957804100000024},
  file = {D\:\\Zotero\\storage\\MQCJENCF\\Roberts_Rosenthal_2004_General state space Markov chains and MCMC algorithms.pdf}
}

@article{roosSensitivityAnalysisBayesian,
  title = {Sensitivity {{Analysis}} for {{Bayesian Hierarchical Models}}},
  author = {Roos, Malgorzata and Martins, Thiago G and Held, Leonhard},
  pages = {29},
  doi = {10.1214/14-BA909},
  abstract = {Prior sensitivity examination plays an important role in applied Bayesian analyses. This is especially true for Bayesian hierarchical models, where interpretability of the parameters within deeper layers in the hierarchy becomes challenging. In addition, lack of information together with identifiability issues may imply that the prior distributions for such models have an undesired influence on the posterior inference. Despite its importance, informal approaches to prior sensitivity analysis are currently used. They require repetitive re-fits of the model with ad-hoc modified base prior parameter values. Other formal approaches to prior sensitivity analysis suffer from a lack of popularity in practice, mainly due to their high computational cost and absence of software implementation. We propose a novel formal approach to prior sensitivity analysis, which is fast and accurate. It quantifies sensitivity without the need for a model re-fit. Through a series of examples we show how our approach can be used to detect high prior sensitivities of some parameters as well as identifiability issues in possibly over-parametrized Bayesian hierarchical models.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\KUP8FMII\\Roos et al. - Sensitivity Analysis for Bayesian Hierarchical Mod.pdf}
}

@misc{roosSensitivityAnalysisBayesian2013,
  title = {Sensitivity Analysis for {{Bayesian}} Hierarchical Models},
  author = {Roos, Malgorzata and Martins, Thiago G. and Held, Leonhard and Rue, Havard},
  date = {2013-12-17},
  number = {arXiv:1312.4797},
  eprint = {1312.4797},
  eprinttype = {arxiv},
  primaryclass = {stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/1312.4797},
  urldate = {2022-09-01},
  abstract = {Prior sensitivity examination plays an important role in applied Bayesian analyses. This is especially true for Bayesian hierarchical models, where interpretability of the parameters within deeper layers in the hierarchy becomes challenging. In addition, lack of information together with identifiability issues may imply that the prior distributions for such models have an undesired influence on the posterior inference. Despite its relevance, informal approaches to prior sensitivity analysis are currently used. They require repetitive re-runs of the model with ad-hoc modified base prior parameter values. Other formal approaches to prior sensitivity analysis suffer from a lack of popularity in practice, mainly due to their high computational cost and absence of software implementation. We propose a novel formal approach to prior sensitivity analysis which is fast and accurate. It quantifies sensitivity without the need for a model re-run. We develope a readyto-use priorSens package in R for routine prior sensitivity investigation by R-INLA. Throughout a series of examples we show how our approach can be used to detect high prior sensitivities of some parameters as well as identifiability issues in possibly over-parametrized Bayesian hierarchical models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\US8ULJP8\\Roos et al. - 2013 - Sensitivity analysis for Bayesian hierarchical mod.pdf}
}

@article{roosSensitivityAnalysisBayesiana,
  title = {Sensitivity Analysis for {{Bayesian}} Hierarchical Models},
  author = {Roos, Malgorzata and Martins, Thiago G and Held, Leonhard},
  pages = {26},
  doi = {10.1214/14-BA909},
  abstract = {Prior sensitivity examination plays an important role in applied Bayesian analyses. This is especially true for Bayesian hierarchical models, where interpretability of the parameters within deeper layers in the hierarchy becomes challenging. In addition, lack of information together with identifiability issues may imply that the prior distributions for such models have an undesired influence on the posterior inference. Despite its relevance, informal approaches to prior sensitivity analysis are currently used. They require repetitive re-runs of the model with ad-hoc modified base prior parameter values. Other formal approaches to prior sensitivity analysis suffer from a lack of popularity in practice, mainly due to their high computational cost and absence of software implementation. We propose a novel formal approach to prior sensitivity analysis which is fast and accurate. It quantifies sensitivity without the need for a model re-run. We develope a readyto-use priorSens package in R for routine prior sensitivity investigation by R-INLA. Throughout a series of examples we show how our approach can be used to detect high prior sensitivities of some parameters as well as identifiability issues in possibly over-parametrized Bayesian hierarchical models.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\IKQ85T7E\\Roos et al. - Sensitivity analysis for Bayesian hierarchical mod.pdf}
}

@book{Rosenthal:2019,
  title = {A First Look at Stochastic Processes},
  author = {Rosenthal, J.S.},
  date = {2019},
  publisher = {{World Scientific}}
}

@article{rouderBayesianAnalysisFactorial2017,
  title = {Bayesian Analysis of Factorial Designs},
  author = {Rouder, Jeffrey N. and Morey, Richard D. and Verhagen, Josine and Swagman, April R. and Wagenmakers, Eric-Jan},
  date = {2017-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {22},
  number = {2},
  pages = {304--321},
  issn = {1939-1463, 1082-989X},
  doi = {10/gbkndn},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000057},
  urldate = {2022-03-25},
  abstract = {This article provides a Bayes factor approach to multiway analysis of variance (ANOVA) that allows researchers to state graded evidence for effects or invariances as determined by the data. ANOVA is conceptualized as a hierarchical model where levels are clustered within factors. The development is comprehensive in that it includes Bayes factors for fixed and random effects and for within-subjects, between-subjects, and mixed designs. Different model construction and comparison strategies are discussed, and an example is provided. We show how Bayes factors may be computed with BayesFactor package in R and with the JASP statistical package.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\GSTFLLKP\\Rouder et al_2017_Bayesian analysis of factorial designs.pdf}
}

@incollection{rouderBayesianHierarchicalModels2017,
  title = {Bayesian Hierarchical Models of Cognition},
  booktitle = {New {{Handbook}} of {{Mathematical Psychology}}},
  author = {Rouder, Jeffrey N. and Morey, Richard D. and Pratte, Michael S.},
  editor = {Batchelder, William H. and Colonius, Hans and Dzhafarov, Ehtibar N. and Myung, Jay},
  date = {2017},
  edition = {1},
  pages = {504--551},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781139245913.010},
  url = {https://www.cambridge.org/core/product/identifier/CBO9781139245913A018/type/book_part},
  urldate = {2022-03-25},
  isbn = {978-1-139-24591-3 978-1-107-02908-8},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\WFD4RRWA\\Rouder et al_2017_Bayesian hierarchical models of cognition.pdf}
}

@article{rouderBayesianInferencePsychology2018,
  title = {Bayesian Inference for Psychology, Part {{IV}}: Parameter Estimation and {{Bayes}} Factors},
  shorttitle = {Bayesian Inference for Psychology, Part {{IV}}},
  author = {Rouder, Jeffrey N. and Haaf, Julia M. and Vandekerckhove, Joachim},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {102--113},
  issn = {1069-9384, 1531-5320},
  doi = {10/gc9qfx},
  url = {http://link.springer.com/10.3758/s13423-017-1420-7},
  urldate = {2022-03-25},
  abstract = {In the psychological literature, there are two seemingly different approaches to inference: that from estimation of posterior intervals and that from Bayes factors. We provide an overview of each method and show that a salient difference is the choice of models. The two approaches as commonly practiced can be unified with a certain model specification, now popular in the statistics literature, called spike-and-slab priors. A spike-and-slab prior is a mixture of a null model, the spike, with an effect model, the slab. The estimate of the effect size here is a function of the Bayes factor, showing that estimation and model comparison can be unified. The salient difference is that common Bayes factor approaches provide for privileged consideration of theoretically useful parameter values, such as the value corresponding to the null hypothesis, while estimation approaches do not. Both approaches, either privileging the null or not, are useful depending on the goals of the analyst.},
  langid = {english},
  keywords = {/unread,II 级文献},
  file = {D\:\\Zotero\\storage\\J982EZ6X\\Rouder et al_2018_Bayesian inference for psychology, part IV.pdf}
}

@article{rouderIntroductionBayesianHierarchical2005,
  title = {An Introduction to {{Bayesian}} Hierarchical Models with an Application in the Theory of Signal Detection},
  author = {Rouder, Jeffrey N. and Lu, Jun},
  date = {2005-08},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {12},
  number = {4},
  pages = {573--604},
  issn = {1069-9384, 1531-5320},
  doi = {10/bfkk4b},
  url = {http://link.springer.com/10.3758/BF03196750},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\TITKGKNH\\Rouder_Lu_2005_An introduction to Bayesian hierarchical models with an application in the.pdf}
}

@article{rouderTheoriesModelsPredictions2018,
  title = {From Theories to Models to Predictions: {{A Bayesian}} Model Comparison Approach},
  shorttitle = {From Theories to Models to Predictions},
  author = {Rouder, Jeffrey N. and Haaf, Julia M. and Aust, Frederik},
  date = {2018-01-02},
  journaltitle = {Communication Monographs},
  shortjournal = {Communication Monographs},
  volume = {85},
  number = {1},
  pages = {41--56},
  issn = {0363-7751, 1479-5787},
  doi = {10/gdrbw3},
  url = {https://www.tandfonline.com/doi/full/10.1080/03637751.2017.1394581},
  urldate = {2022-03-25},
  abstract = {A key goal in research is to use data to assess competing hypotheses or theories. An alternative to the conventional significance testing is Bayesian model comparison. The main idea is that competing theories are represented by statistical models. In the Bayesian framework, these models then yield predictions about data even before the data are seen. How well the data match the predictions under competing models may be calculated, and the ratio of these matches – the Bayes factor – is used to assess the evidence for one model compared to another. We illustrate the process of going from theories to models and to predictions in the context of two hypothetical examples about how exposure to media affects attitudes toward refugees.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\7H86PM7M\\Rouder et al_2018_From theories to models to predictions.pdf}
}

@article{Rubin:1981,
  title = {Estimation in Parallel Randomized Experiments},
  author = {Rubin, Donald B},
  date = {1981},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  volume = {6},
  number = {4},
  pages = {377--401},
  keywords = {❓ Multiple DOI}
}

@article{Rubin:1984,
  title = {Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician},
  author = {Rubin, Donald B.},
  date = {1984},
  journaltitle = {The Annals of Statistics},
  shortjournal = {Ann. Statist.},
  volume = {12},
  number = {4},
  pages = {1151--1172},
  doi = {10/cc5dpx},
  file = {D\:\\Zotero\\storage\\9ZNZH3XY\\Rubin_1984_Bayesianly justifiable and relevant frequency calculations for the applied.pdf}
}

@article{rupprechterMajorDepressionImpairs2018,
  title = {Major {{Depression Impairs}} the {{Use}} of {{Reward Values}} for {{Decision-Making}}},
  author = {Rupprechter, Samuel and Stankevicius, Aistis and Huys, Quentin J. M. and Steele, J. Douglas and Seriès, Peggy},
  date = {2018-12},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {8},
  number = {1},
  pages = {13798},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-31730-w},
  url = {http://www.nature.com/articles/s41598-018-31730-w},
  urldate = {2022-03-03},
  langid = {english},
  keywords = {/unread,I 级文献},
  annotation = {13 citations (Crossref) [2022-03-03] ZSCC: 0000022},
  file = {D\:\\Zotero\\storage\\5SRB6CNV\\Rupprechter et al. - 2018 - Major Depression Impairs the Use of Reward Values .pdf;D\:\\Zotero\\storage\\BTJB4UYE\\Rupprechter et al_2018_Major Depression Impairs the Use of Reward Values for Decision-Making.pdf;D\:\\Zotero\\storage\\TQLWXK3K\\Rupprechter et al_2018_Major Depression Impairs the Use of Reward Values for Decision-Making.pdf}
}

@article{santangeloRunningOnlineBehavioral2022,
  title = {Running {{Online Behavioral Experiments Using R}}: {{Implementation}} of a {{Response-Time Decision Making Task}} as an {{R-Shiny App}}},
  shorttitle = {Running {{Online Behavioral Experiments Using R}}},
  author = {Santangelo, Agustín Perez and Solovey, Guillermo},
  date = {2022-01-07},
  journaltitle = {Journal of Cognition},
  volume = {5},
  number = {1},
  pages = {9},
  issn = {2514-4820},
  doi = {10/gn7r9v},
  url = {http://www.journalofcognition.org/articles/10.5334/joc.200/},
  urldate = {2022-04-16},
  abstract = {Online experiments allow for fast, massive, cost-efficient data collection. However, uncontrolled conditions in online experiments can be problematic, particularly when inferences hinge on response-times (RTs) in the millisecond range. To address this challenge, we developed a mobile-friendly open-source application using R-Shiny, a popular R package. In particular, we aimed to replicate the numerical distance effect, a well-established cognitive phenomenon. In the task, 169 participants (109 with a mobile device, 60 on a desktop computer) completed 116 trials displaying twodigit target numbers and decided whether they were larger or smaller than a fixed standard number. Sessions lasted \textasciitilde 7-minutes. Using generalized linear mixed models estimated with Bayesian inference methods, we observed a numerical distance effect: RTs decreased with the logarithm of the absolute difference between the target and the standard. Our results support the use of R-Shiny for RT-data collection. Furthermore, our method allowed us to measure systematic shifts in recorded RTs related to different OSs, web browsers, and devices, with mobile devices inducing longer shifts than desktop devices. Our work shows that precise RT measures can be reliably obtained online across mobile and desktop devices. It further paves the ground for the design of simple experimental tasks using R, a widely popular programming framework among cognitive scientists.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\XAEUAMIZ\\Santangelo and Solovey - 2022 - Running Online Behavioral Experiments Using R Imp.pdf}
}

@inproceedings{sarmaPriorSettingPractice2020,
  title = {Prior {{Setting}} in {{Practice}}: {{Strategies}} and {{Rationales Used}} in {{Choosing Prior Distributions}} for {{Bayesian Analysis}}},
  shorttitle = {Prior {{Setting}} in {{Practice}}},
  booktitle = {Proceedings of the 2020 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Sarma, Abhraneel and Kay, Matthew},
  date = {2020-04-21},
  pages = {1--12},
  publisher = {{ACM}},
  location = {{Honolulu HI USA}},
  doi = {10.1145/3313831.3376377},
  url = {https://dl.acm.org/doi/10.1145/3313831.3376377},
  urldate = {2022-08-21},
  abstract = {Bayesian statistical analysis is steadily growing in popularity and use. Choosing priors is an integral part of Bayesian inference. While there exist extensive normative recommendations for prior setting, little is known about how priors are chosen in practice. We conducted a survey (N = 50) and interviews (N = 9) where we used interactive visualizations to elicit prior distributions from researchers experienced with Bayesian statistics and asked them for rationales for those priors. We found that participants’ experience and philosophy influence how much and what information they are willing to incorporate into their priors, manifesting as different levels of informativeness and skepticism. We also identified three broad strategies participants use to set their priors: centrality matching, interval matching, and visual probability mass allocation. We discovered that participants’ understanding of the notion of “weakly informative priors”—a commonly-recommended normative approach to prior setting—manifests very differently across participants. Our results have implications both for how to develop prior setting recommendations and how to design tools to elicit priors in Bayesian analysis.},
  eventtitle = {{{CHI}} '20: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-6708-0},
  langid = {english},
  file = {D\:\\Zotero\\storage\\D647DPDQ\\Sarma and Kay - 2020 - Prior Setting in Practice Strategies and Rational.pdf}
}

@report{scarfLongitudinalStudyMental2021,
  type = {preprint},
  title = {A Longitudinal Study of Mental Wellbeing in Students That Transition into {{PhD}} Study},
  author = {Scarf, Damian and Winter, Taylor and Riordan, Benjamin and Hunter, John and Tustin, Karen and Gollop, Megan and Taylor, Nicola and Kokaua, Jesse and Poulton, Richie},
  date = {2021-01-19},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/eq6xg},
  url = {https://osf.io/eq6xg},
  urldate = {2022-04-16},
  abstract = {Journal editorials, career features, and the popular press, commonly talk of a graduate student mental health crisis. To date, studies on graduate student mental health have employed cross-sectional designs, limiting any causal conclusions regarding the relationship between graduate student and mental health. Here, we present the first longitudinal study on mental health in PhD students. Data were drawn from a longitudinal study of undergraduate students in New Zealand, allowing us to compare students who did, and did not, transition into PhD study following the completion of their undergraduate degree. Using multilevel Bayesian regression, we detected a 0.09 standard deviation decrease in mental health for students who enter PhD study. This finding is orders of magnitude smaller than one might expect based on previous cross-sectional research and provide an important message; that poor mental health is not an inevitable consequence of graduate study.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\V8ZGKPR5\\Scarf et al. - 2021 - A longitudinal study of mental wellbeing in studen.pdf}
}

@unpublished{schadDataAggregationCan2022,
  title = {Data Aggregation Can Lead to Biased Inferences in {{Bayesian}} Linear Mixed Models},
  author = {Schad, Daniel J. and Nicenboim, Bruno and Vasishth, Shravan},
  date = {2022-03-17},
  eprint = {2203.02361},
  eprinttype = {arxiv},
  primaryclass = {stat},
  url = {http://arxiv.org/abs/2203.02361},
  urldate = {2022-03-25},
  abstract = {Bayesian linear mixed-effects models are increasingly being used in the cognitive sciences to perform null hypothesis tests, where a null hypothesis that an effect is zero is compared with an alternative hypothesis that the effect exists and is different from zero. While software tools for Bayes factor null hypothesis tests are easily accessible, how to specify the data and the model correctly is often not clear. In Bayesian approaches, many authors recommend data aggregation at the by-subject level and running Bayes factors on aggregated data. Here, we use simulation-based calibration for model inference to demonstrate that null hypothesis tests can yield biased Bayes factors, when computed from aggregated data. Specifically, when random slope variances differ (i.e., violated sphericity assumption), Bayes factors are too conservative for contrasts where the variance is small and they are too liberal for contrasts where the variance is large. Moreover, Bayes factors for by-subject aggregated data are biased (too liberal) when random item variance is present but ignored in the analysis. We also perform corresponding frequentist analyses (type I and II error probabilities) to illustrate that the same problems exist and are well known from frequentist tools. These problems can be circumvented by running Bayesian linear mixed-effects models on non-aggregated data such as on individual trials and by explicitly modeling the full random effects structure. Reproducible code is available from https://osf.io/mjf47/.},
  archiveprefix = {arXiv},
  keywords = {/unread,⛔ No DOI found,I 级文献,Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\PYDL7K2G\\Schad et al_2022_Data aggregation can lead to biased inferences in Bayesian linear mixed models.pdf}
}

@article{schadHowCapitalizePriori2020,
  title = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models: {{A}} Tutorial},
  shorttitle = {How to Capitalize on a Priori Contrasts in Linear (Mixed) Models},
  author = {Schad, Daniel J. and Vasishth, Shravan and Hohenstein, Sven and Kliegl, Reinhold},
  date = {2020-02},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {110},
  pages = {104038},
  issn = {0749596X},
  doi = {10.1016/j.jml.2019.104038},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0749596X19300695},
  urldate = {2022-08-31},
  abstract = {Factorial experiments in research on memory, language, and in other areas are often analyzed using analysis of variance (ANOVA). However, for effects with more than one numerator degrees of freedom, e.g., for experimental factors with more than two levels, the ANOVA omnibus F-test is not informative about the source of a main effect or interaction. Because researchers typically have specific hypotheses about which condition means differ from each other, a priori contrasts (i.e., comparisons planned before the sample means are known) between specific conditions or combinations of conditions are the appropriate way to represent such hypotheses in the statistical model. Many researchers have pointed out that contrasts should be “tested instead of, rather than as a supplement to, the ordinary ‘omnibus’ F test” (Hays, 1973, p. 601). In this tutorial, we explain the mathematics underlying different kinds of contrasts (i.e., treatment, sum, repeated, polynomial, custom, nested, interaction contrasts), discuss their properties, and demonstrate how they are applied in the R System for Statistical Computing (R Core Team, 2018). In this context, we explain the generalized inverse which is needed to compute the coefficients for contrasts that test hypotheses that are not covered by the default set of contrasts. A detailed understanding of contrast coding is crucial for successful and correct specification in linear models (including linear mixed models). Contrasts defined a priori yield far more useful confirmatory tests of experimental hypotheses than standard omnibus F-tests. Reproducible code is available from https://osf.io/7ukf6/.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\2PCEQA5H\\Schad et al. - 2020 - How to capitalize on a priori contrasts in linear .pdf}
}

@article{schadPrincipledBayesianWorkflow2021,
  title = {Toward a Principled {{Bayesian}} Workflow in Cognitive Science},
  author = {Schad, Daniel J. and Betancourt, Michael and Vasishth, Shravan},
  date = {2021-02},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {26},
  number = {1},
  pages = {103--126},
  issn = {1939-1463, 1082-989X},
  doi = {10/ghbtt6},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000275},
  urldate = {2022-03-26},
  abstract = {Experiments in research on memory, language, and in other areas of cognitive science are increasingly being analyzed using Bayesian methods. This has been facilitated by the development of probabilistic programming languages such as Stan, and easily accessible front-end packages such as brms. The utility of Bayesian methods, however, ultimately depends on the relevance of the Bayesian model, in particular whether or not it accurately captures the structure of the data and the data analyst’s domain expertise. Even with powerful software, the analyst is responsible for verifying the utility of their model. To demonstrate this point, we introduce a principled Bayesian workflow (Betancourt, 2018) to cognitive science. Using a concrete working example, we describe basic questions one should ask about the model: prior predictive checks, computational faithfulness, model sensitivity, and posterior predictive checks. The running example for demonstrating the workflow is data on reading times with a linguistic manipulation of object versus subject relative clause sentences. This principled Bayesian workflow also demonstrates how to use domain knowledge to inform prior distributions. It provides guidelines and checks for valid data analysis, avoiding overfitting complex models to noise, and capturing relevant data structure in a probabilistic model. Given the increasing use of Bayesian methods, we aim to discuss how these methods can be properly employed to obtain robust answers to scientific questions. All data and code accompanying this article are available from https://osf.io/b2vx9/.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\SWIKJ792\\Schad et al_2021_Toward a principled Bayesian workflow in cognitive science.pdf}
}

@article{schadWorkflowTechniquesRobust2022,
  title = {Workflow Techniques for the Robust Use of Bayes Factors},
  author = {Schad, Daniel J. and Nicenboim, Bruno and Bürkner, Paul-Christian and Betancourt, Michael and Vasishth, Shravan},
  date = {2022-03-10},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000472},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000472},
  urldate = {2022-05-08},
  abstract = {Inferences about hypotheses are ubiquitous in the cognitive sciences. Bayes factors provide one general way to compare different hypotheses by their compatibility with the observed data. Those quantifications can then also be used to choose between hypotheses. While Bayes factors provide an immediate approach to hypothesis testing, they are highly sensitive to details of the data/model assumptions and it’s unclear whether the details of the computational implementation (such as bridge sampling) are unbiased for complex analyses. Here, we study how Bayes factors misbehave under different conditions. This includes a study of errors in the estimation of Bayes factors; the first-ever use of simulation-based calibration to test the accuracy and bias of Bayes factor estimates using bridge sampling; a study of the stability of Bayes factors against different MCMC draws and sampling variation in the data; and a look at the variability of decisions based on Bayes factors using a utility function. We outline a Bayes factor workflow that researchers can use to study whether Bayes factors are robust for their individual analysis. Reproducible code is available from https://osf.io/y354c/.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\VFN7QLGI\\Schad et al. - 2022 - Workflow techniques for the robust use of bayes fa.pdf}
}

@article{schollEffectApathyCompulsivity2022,
  title = {The Effect of Apathy and Compulsivity on Planning and Stopping in Sequential Decision-Making},
  author = {Scholl, Jacqueline and Trier, Hailey A. and Rushworth, Matthew F. S. and Kolling, Nils},
  editor = {Chambers, Christopher D.},
  date = {2022-03-31},
  journaltitle = {PLOS Biology},
  shortjournal = {PLoS Biol},
  volume = {20},
  number = {3},
  pages = {e3001566},
  issn = {1545-7885},
  doi = {10/gpv6fj},
  url = {https://dx.plos.org/10.1371/journal.pbio.3001566},
  urldate = {2022-04-08},
  abstract = {Real-life decision-making often comprises sequences of successive decisions about whether to take opportunities as they are encountered or keep searching for better ones instead. We investigated individual differences related to such sequential decision-making and link them especially to apathy and compulsivity in a large online sample (discovery sample: n = 449 and confirmation sample: n = 756). Our cognitive model revealed distinct changes in the way participants evaluated their environments and planned their own future behaviour. Apathy was linked to decision inertia, i.e., automatically persisting with a sequence of searches for longer than appropriate given the value of searching. Thus, despite being less motivated, they did not avoid the effort associated with longer searches. In contrast, compulsivity was linked to self-reported insensitivity to the cost of continuing with a sequence of searches. The objective measures of behavioural cost insensitivity were clearly linked to compulsivity only in the discovery sample. While the confirmation sample showed a similar effect, it did not reach significance. Nevertheless, in both samples, participants reported awareness of such bias (experienced as “overchasing”). In addition, this awareness made them report preemptively avoiding situations related to the bias. However, we found no evidence of them actually preempting more in the task, which might mean a misalignment of their metacognitive beliefs or that our behavioural measures were incomplete. In summary, individual variation in distinct, fundamental aspects of sequential decision-making can be linked to variation in 2 measures of behavioural traits associated with psychological illness in the normal population.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\UH528BJ2\\Scholl et al_2022_The effect of apathy and compulsivity on planning and stopping in sequential.pdf}
}

@article{schonbrodtBayesFactorDesign2018,
  title = {Bayes Factor Design Analysis: {{Planning}} for Compelling Evidence},
  shorttitle = {Bayes Factor Design Analysis},
  author = {Schönbrodt, Felix D. and Wagenmakers, Eric-Jan},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {128--142},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1230-y},
  url = {http://link.springer.com/10.3758/s13423-017-1230-y},
  urldate = {2022-08-03},
  abstract = {A sizeable literature exists on the use of frequentist power analysis in the null-hypothesis significance testing (NHST) paradigm to facilitate the design of informative experiments. In contrast, there is almost no literature that discusses the design of experiments when Bayes factors (BFs) are used as a measure of evidence. Here we explore Bayes Factor Design Analysis (BFDA) as a useful tool to design studies for maximum efficiency and informativeness. We elaborate on three possible BF designs, (a) a fixed-n design, (b) an open-ended Sequential Bayes Factor (SBF) design, where researchers can test after each participant and can stop data collection whenever there is strong evidence for either H1 or H0, and (c) a modified SBF design that defines a maximal sample size where data collection is stopped regardless of the current state of evidence. We demonstrate how the properties of each design (i.e., expected strength of evidence, expected sample size, expected probability of misleading evidence, expected probability of weak evidence) can be evaluated using Monte Carlo simulations and equip researchers with the necessary information to compute their own Bayesian design analyses.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\6G8JZUV5\\Schönbrodt and Wagenmakers - 2018 - Bayes factor design analysis Planning for compell.pdf;D\:\\Zotero\\storage\\UU3HDZE4\\Schönbrodt_Wagenmakers_2018_Bayes factor design analysis.pdf}
}

@article{seegerBayesianModellingMachine2009,
  title = {Bayesian {{Modelling}} in {{Machine Learning}}: {{A Tutorial Review}}},
  author = {Seeger, Matthias},
  date = {2009},
  pages = {38},
  abstract = {Many facets of Bayesian Modelling are firmly established in Machine Learning and give rise to state-of-the-art solutions to application problems. The sheer number of techniques, ideas and models which have been proposed, and the terminology, can be bewildering. With this tutorial review, we aim to give a wide high-level overview over this important field, concentrating on central ideas and methods, and on their interconnections. The reader will gain a basic understanding of the topics and their relationships, armed with which she can branch to details of her interest using the references to more specialized textbooks and reviews we provide here.},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\6JFP9HXD\\Seeger_2009_Bayesian Modelling in Machine Learning.pdf}
}

@article{Shannon:1948,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, C. E.},
  date = {1948},
  journaltitle = {Bell System Tech. J.},
  volume = {27},
  pages = {379--423, 623--656},
  keywords = {❓ Multiple DOI}
}

@article{Sherrard-SmithEtAl:2017,
  title = {A Novel Model Fitted to Multiple Life Stages of Malaria for Assessing Efficacy of Transmission-Blocking Interventions},
  author = {Sherrard-Smith, Ellie and Churcher, Thomas S. and Upton, Leanna M. and Sala, Katarzyna A. and Zakutansky, Sara E. and Slater, Hannah C. and Blagborough, Andrew M. and Betancourt, Michael},
  date = {2017-04},
  journaltitle = {Malaria Journal},
  volume = {16},
  number = {1},
  pages = {137},
  doi = {10.1186/s12936-017-1782-3},
  file = {D\:\\Zotero\\storage\\F8PAPIPA\\Sherrard-Smith et al_2017_A novel model fitted to multiple life stages of malaria for assessing efficacy.pdf}
}

@article{shewApplyingHierarchicalBayesian,
  title = {Applying {{Hierarchical Bayesian Models}} to {{ATP Data}}},
  author = {Shew, Horace},
  pages = {10},
  abstract = {The ATP tour is a tennis tour for professional men’s tennis players managed by the Association of Tennis Professionals. The tour consists of tournaments hosted annually, held all across the world on different surfaces worth different amounts of ranking points, i.e. ATP Masters 1000, ATP 500, ATP 250. In addition, the Grand Slam tournaments also count for ranking points. The tournaments differ in size of the draw, surface, location, and when during the year the tournament takes place. Along with the tournament itself, the attributes of a player and their opponent in a match also factor into his result at a tournament. The current ranking system has remained in place since 2009 and measures player performance over the long term, but we also want to capture short-term fluctuations in player performance. In this paper, we develop a hierarchical Bayesian model to predict player performance that takes these types of factors into account, using public data made available by Jeff Sackmann and Tennis Abstract (Sackmann, 2021). We examine the effects of tournament and player attributes on performance on the tour from 2009-2020. These models provide insight into how match-level, tournament-level, and player-level effects interact to influence player performance.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\NBG2EGQZ\\Shew - Applying Hierarchical Bayesian Models to ATP Data.pdf}
}

@article{SimpsonEtAl:2017,
  title = {Penalising Model Component Complexity: {{A}} Principled, Practical Approach to Constructing Priors},
  author = {Simpson, Daniel and Rue, Håvard and Riebler, Andrea and Martins, Thiago G. and Sørbye, Sigrunn H.},
  date = {2017-02},
  journaltitle = {Statistical Science},
  shortjournal = {Statist. Sci.},
  volume = {32},
  number = {1},
  pages = {1--28},
  keywords = {⛔ No DOI found}
}

@article{sinharayEmpiricalComparisonMethods2005,
  title = {An {{Empirical Comparison}} of {{Methods}} for {{Computing Bayes Factors}} in {{Generalized Linear Mixed Models}}},
  author = {Sinharay, Sandip and Stern, Hal S},
  date = {2005-06},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {14},
  number = {2},
  pages = {415--435},
  issn = {1061-8600, 1537-2715},
  doi = {10/c6tjxd},
  url = {http://www.tandfonline.com/doi/abs/10.1198/106186005X47471},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\V3YF869T\\Sinharay_Stern_2005_An Empirical Comparison of Methods for Computing Bayes Factors in Generalized.pdf}
}

@book{Sivia:2006,
  title = {Data Analysis},
  author = {Sivia, D. S.},
  date = {2006},
  series = {Oxford Science Publications},
  edition = {2},
  publisher = {{Oxford University Press, Oxford}}
}

@article{sorensenBayesianLinearMixed2016,
  title = {Bayesian Linear Mixed Models Using {{Stan}}: {{A}} Tutorial for Psychologists, Linguists, and Cognitive Scientists},
  shorttitle = {Bayesian Linear Mixed Models Using {{Stan}}},
  author = {Sorensen, Tanner and Hohenstein, Sven and Vasishth, Shravan},
  date = {2016-10-01},
  journaltitle = {The Quantitative Methods for Psychology},
  shortjournal = {TQMP},
  volume = {12},
  number = {3},
  pages = {175--200},
  issn = {2292-1354},
  doi = {10.20982/tqmp.12.3.p175},
  url = {http://www.tqmp.org/RegularArticles/vol12-3/p175},
  urldate = {2021-09-15},
  abstract = {With the arrival of the R packages nlme and lme4, linear mixed models (LMMs) have come to be widely used in experimentally-driven areas like psychology, linguistics, and cognitive science. This tutorial provides a practical introduction to fitting LMMs in a Bayesian framework using the probabilistic programming language Stan. We choose Stan (rather than WinBUGS or JAGS) because it provides an elegant and scalable framework for fitting models in most of the standard applications of LMMs. We ease the reader into fitting increasingly complex LMMs, using a twocondition repeated measures self-paced reading study.},
  langid = {english},
  keywords = {/unread,Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\SSWKUJ4Z\\Sorensen et al_2016_Bayesian linear mixed models using Stan.pdf;D\:\\Zotero\\storage\\XYTCRNDU\\Sorensen_Vasishth_2016_Bayesian linear mixed models using Stan.pdf}
}

@misc{Stan:2018,
  title = {Stan: {{A C}}++ Library for Probability and Sampling, Version 2.17.1},
  author = {{Stan Development Team}},
  date = {2018},
  url = {http://mc-stan.org/}
}

@article{sullivanIntroductionHierarchicalLinear1999,
  title = {An Introduction to Hierarchical Linear Modelling},
  author = {Sullivan, Lisa M. and Dukes, Kimberly A. and Losina, Elena},
  date = {1999-04-15},
  journaltitle = {Statistics in Medicine},
  shortjournal = {Statist. Med.},
  volume = {18},
  number = {7},
  pages = {855--888},
  issn = {0277-6715, 1097-0258},
  doi = {10/dv9z54},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(19990415)18:7<855::AID-SIM117>3.0.CO;2-7},
  urldate = {2022-03-25},
  abstract = {Hierarchical linear models are useful for understanding relationships in hierarchical data structures, such as patients within hospitals or physicians within hospitals. In this tutorial we provide an introduction to the technique in general terms, and then specify model notation and assumptions in detail. We describe estimation techniques and hypothesis testing procedures for the three types of parameters involved in hierarchical linear models: fixed effects, covariance components, and random effects. We illustrate the application using an example from the Type II Diabetes Patient Outcomes Research Team (PORT) study and use two popular PC-based statistical computing packages, HLM/2L and SAS Proc Mixed, to perform two-level hierarchical analysis. We compare output from the two packages applied to our example data as well as to simulated data. We elaborate on model interpretation and provide guidelines for model checking. Copyright 1999 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\JH4Q39T5\\Sullivan et al_1999_An introduction to hierarchical linear modelling.pdf}
}

@article{TaltsEtAl:2018,
  title = {Validating Bayesian Inference Algorithms with Simulation-Based Calibration},
  author = {Talts, Sean and Betancourt, Michael and Simpson, Daniel and Vehtari, Aki and Gelman, Andrew},
  date = {2018-04},
  keywords = {⛔ No DOI found}
}

@article{teamStanFunctionsReference,
  title = {Stan {{Functions Reference}}},
  author = {Team, Stan Development},
  pages = {185},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\8K3G3P78\\Team_Stan Functions Reference.pdf}
}

@article{teamStanReferenceManual,
  title = {Stan {{Reference Manual}}},
  author = {Team, Stan Development},
  pages = {191},
  langid = {english},
  keywords = {/unread,⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\E7BGSVXB\\Team_Stan Reference Manual.pdf}
}

@article{Tibshirani:1996,
  title = {Regression Shrinkage and Selection via the Lasso},
  author = {Tibshirani, Robert},
  date = {1996},
  journaltitle = {Journal of the Royal Statistical Society. Series B (Methodological)},
  volume = {58},
  number = {1},
  eprint = {2346178},
  eprinttype = {jstor},
  pages = {267--288},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {00359246},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  file = {D\:\\Zotero\\storage\\CBXTB4W8\\Tibshirani_1996_Regression shrinkage and selection via the lasso.pdf}
}

@article{tirunehOverweightObesityIts2021,
  title = {Overweight and/or Obesity and Its Determinants among under-Five Children in {{East African}} Countries: {{A}} Multilevel Analysis Using {{Bayesian}} Approach},
  shorttitle = {Overweight and/or Obesity and Its Determinants among under-Five Children in {{East African}} Countries},
  author = {Tiruneh, Sofonyas Abebaw and Gebremariam, Alemayehu Digssie and Engidaw, Melaku Tadege and Tesfa, Desalegn and Dagnaw, Fentaw Teshome and Zewde, Edgeit Abebe and Azanaw, Melkalem Mamuye},
  date = {2021-12},
  journaltitle = {Heliyon},
  shortjournal = {Heliyon},
  volume = {7},
  number = {12},
  pages = {e08643},
  issn = {24058440},
  doi = {10/gpwszz},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2405844021027468},
  urldate = {2022-04-16},
  abstract = {Introduction: Childhood overweight and/or obesity become a significant public health problem in the 21st century. It is a double burden next to undernutrition and has a dramatic rise in low- and middle-income countries. This study aimed to determine the prevalence of overweight and/or obesity and its determinants among under-five children in East African Countries. Methods: Data were retrieved from the recent nationally representative demographic and health survey datasets from eleven East African Countries. A total of 89,091 weighted numbers of under-five children participated. Statistical analysis was performed using the R (Brms R-package) software. Multivariable mixed-effects logistic regression analysis using the Bayesian approach was employed to identify the factors affecting overweight and/or obesity among under-five children. Results: Overall, 4.59\% (95\% CI, 4.45–4.73) of under-five children in East African Countries were overweight and/ or obese. Under-five children overweight and/or obesity was highest in Comoros and lowest in Burundi. Underfive children aged older than two years (Adjusted odds ratio (AOR) ¼ 0.65, 95\% credible interval (CrI), 0.57–0.73), females (AOR ¼ 0.84, 95\% CrI:, 0.75–0.94), under-five children live from rich household wealth status (AOR ¼ 1.25, 95\% CrI, 1.06–1.49), under-five children living in Malawi (AOR ¼ 2.60, 95\% CrI, 1.49–4.51), Mozambique (AOR ¼ 5.26, 95\% CrI, 3.52–7.79), Rwanda (AOR ¼ 5.63, 95\% CrI, 3.46–9.08), Tanzania (AOR ¼ 2.15, 95\% CrI, 1.47–3.12), and Uganda (AOR ¼ 2.62, 95\% CrI, 1.71–3.99) were a significant determinant for under-five overweight and/or obesity. Conclusion: Overweight and/or obesity among under-five children become a problem in low and middle-income countries. Older under-five children, male sex, children who live in rich household wealth, and children who live in a country in Malawi, Mozambique, Ruanda, Tanzania, and Uganda were significantly affected by overweight and/or obesity. Therefore, in these countries, responsible stakeholders shall give primary attention to curve the alarming increase in overweight and/or obesity among under-five children.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\9SZRYIG4\\Tiruneh et al. - 2021 - Overweight andor obesity and its determinants amo.pdf}
}

@article{trippasCharacterizingBeliefBias2018,
  title = {Characterizing Belief Bias in Syllogistic Reasoning: {{A}} Hierarchical {{Bayesian}} Meta-Analysis of {{ROC}} Data},
  shorttitle = {Characterizing Belief Bias in Syllogistic Reasoning},
  author = {Trippas, Dries and Kellen, David and Singmann, Henrik and Pennycook, Gordon and Koehler, Derek J. and Fugelsang, Jonathan A. and Dubé, Chad},
  date = {2018-12},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {6},
  pages = {2141--2174},
  issn = {1069-9384, 1531-5320},
  doi = {10/gfr29r},
  url = {http://link.springer.com/10.3758/s13423-018-1460-7},
  urldate = {2022-03-25},
  abstract = {The belief-bias effect is one of the most-studied biases in reasoning. A recent study of the phenomenon using the signal detection theory (SDT) model called into question all theoretical accounts of belief bias by demonstrating that beliefbased differences in the ability to discriminate between valid and invalid syllogisms may be an artifact stemming from the use of inappropriate linear measurement models such as analysis of variance (Dube et al., Psychological Review, 117(3), 831–863, 2010). The discrepancy between Dube et al.’s, Psychological Review, 117(3), 831–863 (2010) results and the previous three decades of work, together with former’s methodological criticisms suggests the need to revisit earlier results, this time collecting confidence-rating responses. Using a hierarchical Bayesian meta-analysis, we reanalyzed a corpus of 22 confidence-rating studies (N = 993). The results indicated that extensive replications using confidence-rating data are unnecessary as the observed receiver operating characteristic functions are not systematically asymmetric. These results were subsequently corroborated by a novel experimental design based on SDT’s generalized area theorem. Although the metaanalysis confirms that believability does not influence discriminability unconditionally, it also confirmed previous results that factors such as individual differences mediate the effect. The main point is that data from previous and future studies can be safely analyzed using appropriate hierarchical methods that do not require confidence ratings. More generally, our results set a new standard for analyzing data and evaluating theories in reasoning. Important methodological and theoretical considerations for future work on belief bias and related domains are discussed.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\UH45PZJU\\Trippas et al_2018_Characterizing belief bias in syllogistic reasoning.pdf}
}

@article{turkkanComputationHighestPosterior1993,
  title = {Computation of the Highest Posterior Density Interval in Bayesian Analysis},
  author = {Turkkan, Noyan and Pham-Gia, T.},
  date = {1993-01},
  journaltitle = {Journal of Statistical Computation and Simulation},
  shortjournal = {Journal of Statistical Computation and Simulation},
  volume = {44},
  number = {3-4},
  pages = {243--250},
  issn = {0094-9655, 1563-5163},
  doi = {10.1080/00949659308811461},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00949659308811461},
  urldate = {2022-08-03},
  langid = {english},
  file = {D\:\\Zotero\\storage\\6MKJ3BHG\\turkkan1993.pdf.pdf;D\:\\Zotero\\storage\\QB9NWZV2\\Turkkan and Pham-Gia - 1993 - Computation of the highest posterior density inter.pdf}
}

@article{turnerInformingCognitiveAbstractions2015,
  title = {Informing Cognitive Abstractions through Neuroimaging: {{The}} Neural Drift Diffusion Model.},
  shorttitle = {Informing Cognitive Abstractions through Neuroimaging},
  author = {Turner, Brandon M. and van Maanen, Leendert and Forstmann, Birte U.},
  options = {useprefix=true},
  date = {2015-04},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {122},
  number = {2},
  pages = {312--336},
  issn = {1939-1471, 0033-295X},
  doi = {10/f67stz},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0038894},
  urldate = {2022-03-25},
  abstract = {Trial-to-trial fluctuations in an observer’s state of mind have a direct influence on their behavior. However, characterizing an observer’s state of mind is difficult to do with behavioral data alone, particularly on a single-trial basis. In this article, we extend a recently developed hierarchical Bayesian framework for integrating neurophysiological information into cognitive models. In so doing, we develop a novel extension of the well-studied drift diffusion model (DDM) that uses single-trial brain activity patterns to inform the behavioral model parameters. We first show through simulation how the model outperforms the traditional DDM in a prediction task with sparse data. We then fit the model to experimental data consisting of a speed-accuracy manipulation on a random dot motion task. We use our cognitive modeling approach to show how prestimulus brain activity can be used to simultaneously predict response accuracy and response time. We use our model to provide an explanation for how activity in a brain region affects the dynamics of the underlying decision process through mechanisms assumed by the model. Finally, we show that our model performs better than the traditional DDM through a cross-validation test. By combining accuracy, response time, and the blood oxygen level– dependent response into a unified model, the link between cognitive abstraction and neuroimaging can be better understood.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\MUZ5HAMI\\Turner et al_2015_Informing cognitive abstractions through neuroimaging.pdf}
}

@article{Tweedie:1945,
  title = {Inverse Statistical Variates},
  author = {Tweedie, M. C. K.},
  date = {1945},
  journaltitle = {Nature},
  volume = {155},
  pages = {453},
  doi = {10.1038/155453a0},
  file = {D\:\\Zotero\\storage\\N267LEDD\\Tweedie_1945_Inverse statistical variates.pdf}
}

@article{Tweedie:1957,
  title = {Statistical Properties of Inverse {{Gaussian}} Distributions. {{I}}, {{II}}},
  author = {Tweedie, M. C. K.},
  date = {1957},
  shortjournal = {Ann. Math. Statist.},
  volume = {28},
  pages = {362--377, 696--705}
}

@misc{valtonRecommendationsBayesianHierarchical2020,
  title = {Recommendations for {{Bayesian}} Hierarchical Model Specifications for Case-Control Studies in Mental Health},
  author = {Valton, Vincent and Wise, Toby and Robinson, Oliver J.},
  date = {2020-11-03},
  number = {arXiv:2011.01725},
  eprint = {2011.01725},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2011.01725},
  urldate = {2022-06-02},
  abstract = {Hierarchical model fitting has become commonplace for case-control studies of cognition and behaviour in mental health. However, these techniques require us to formalise assumptions about the data-generating process at the group level, which may not be known. Specifically, researchers typically must choose whether to assume all subjects are drawn from a common population, or to model them as deriving from separate populations. These assumptions have profound implications for computational psychiatry, as they affect the resulting inference (latent parameter recovery) and may conflate or mask true group-level differences. To test these assumptions we ran systematic simulations on synthetic multi-group behavioural data from a commonly used multi-armed bandit task (reinforcement learning task). We then examined recovery of group differences in latent parameter space under the two commonly used generative modelling assumptions: (1) modelling groups under a common shared group-level prior (assuming all participants are generated from a common distribution, and are likely to share common characteristics); (2) modelling separate groups based on symptomatology or diagnostic labels, resulting in separate group-level priors. We evaluated the robustness of these approaches to variations in data quality and prior specifications on a variety of metrics. We found that fitting groups separately (assumptions 2), provided the most accurate and robust inference across all conditions. Our results suggest that when dealing with data from multiple clinical groups, researchers should analyse patient and control groups separately as it provides the most accurate and robust recovery of the parameters of interest.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Applications,Statistics - Methodology},
  file = {D\:\\Zotero\\storage\\PE628TYL\\Valton et al. - 2020 - Recommendations for Bayesian hierarchical model sp.pdf}
}

@book{vanderVaart:2000,
  title = {Asymptotic Statistics},
  author = {van der Vaart, Aad W},
  options = {useprefix=true},
  date = {2000},
  volume = {3},
  publisher = {{Cambridge University Press}}
}

@article{vandeschootBayesianStatisticsModelling2021,
  title = {Bayesian Statistics and Modelling},
  author = {van de Schoot, Rens and Depaoli, Sarah and King, Ruth and Kramer, Bianca and Märtens, Kaspar and Tadesse, Mahlet G. and Vannucci, Marina and Gelman, Andrew and Veen, Duco and Willemsen, Joukje and Yau, Christopher},
  options = {useprefix=true},
  date = {2021-12},
  journaltitle = {Nature Reviews Methods Primers},
  shortjournal = {Nat Rev Methods Primers},
  volume = {1},
  number = {1},
  pages = {1},
  issn = {2662-8449},
  doi = {10/ghs29x},
  url = {http://www.nature.com/articles/s43586-020-00001-2},
  urldate = {2022-03-26},
  abstract = {Bayesian statistics is an approach to data analysis based on Bayes’ theorem, where available knowledge about parameters in a statistical model is updated with the information in observed data. The background knowledge is expressed as a prior distribution and combined with observational data in the form of a likelihood function to determine the posterior distribution. The posterior can also be used for making predictions about future events. This Primer describes the stages involved in Bayesian analysis, from specifying the prior and data models to deriving inference, model checking and refinement. We discuss the importance of prior and posterior predictive checking, selecting a proper technique for sampling from a posterior distribution, variational inference and variable selection. Examples of successful applications of Bayesian analysis across various research fields are provided, including in social sciences, ecology, genetics, medicine and more. We propose strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist. Finally, we outline the impact of Bayesian analysis on artificial intelligence, a major goal in the next decade.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\AARAUHJS\\van de Schoot et al_2021_Bayesian statistics and modelling.pdf}
}

@article{vandeschootSystematicReviewBayesian2017,
  title = {A Systematic Review of {{Bayesian}} Articles in Psychology: {{The}} Last 25 Years.},
  shorttitle = {A Systematic Review of {{Bayesian}} Articles in Psychology},
  author = {van de Schoot, Rens and Winter, Sonja D. and Ryan, Oisín and Zondervan-Zwijnenburg, Mariëlle and Depaoli, Sarah},
  options = {useprefix=true},
  date = {2017-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {22},
  number = {2},
  pages = {217--239},
  issn = {1939-1463, 1082-989X},
  doi = {10/gbj7nw},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000100},
  urldate = {2022-03-25},
  abstract = {Although the statistical tools most often used by researchers in the field of psychology over the last 25 years are based on frequentist statistics, it is often claimed that the alternative Bayesian approach to statistics is gaining in popularity. In the current article, we investigated this claim by performing the very first systematic review of Bayesian psychological articles published between 1990 and 2015 (n ϭ 1,579). We aim to provide a thorough presentation of the role Bayesian statistics plays in psychology. This historical assessment allows us to identify trends and see how Bayesian methods have been integrated into psychological research in the context of different statistical frameworks (e.g., hypothesis testing, cognitive models, IRT, SEM, etc.). We also describe take-home messages and provide “big-picture” recommendations to the field as Bayesian statistics becomes more popular. Our review indicated that Bayesian statistics is used in a variety of contexts across subfields of psychology and related disciplines. There are many different reasons why one might choose to use Bayes (e.g., the use of priors, estimating otherwise intractable models, modeling uncertainty, etc.). We found in this review that the use of Bayes has increased and broadened in the sense that this methodology can be used in a flexible manner to tackle many different forms of questions. We hope this presentation opens the door for a larger discussion regarding the current state of Bayesian statistics, as well as future trends.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\DCPKYYKL\\van de Schoot et al_2017_A systematic review of Bayesian articles in psychology.pdf}
}

@article{vandoornJASPGuidelinesConducting2021,
  title = {The {{JASP}} Guidelines for Conducting and Reporting a {{Bayesian}} Analysis},
  author = {van Doorn, Johnny and van den Bergh, Don and Böhm, Udo and Dablander, Fabian and Derks, Koen and Draws, Tim and Etz, Alexander and Evans, Nathan J. and Gronau, Quentin F. and Haaf, Julia M. and Hinne, Max and Kucharský, Šimon and Ly, Alexander and Marsman, Maarten and Matzke, Dora and Gupta, Akash R. Komarlu Narendra and Sarafoglou, Alexandra and Stefan, Angelika and Voelkel, Jan G. and Wagenmakers, Eric-Jan},
  options = {useprefix=true},
  date = {2021-06},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {28},
  number = {3},
  pages = {813--826},
  issn = {1069-9384, 1531-5320},
  doi = {10/ghfv5h},
  url = {https://link.springer.com/10.3758/s13423-020-01798-5},
  urldate = {2022-03-25},
  abstract = {Despite the increasing popularity of Bayesian inference in empirical research, few practical guidelines provide detailed recommendations for how to apply Bayesian procedures and interpret the results. Here we offer specific guidelines for four different stages of Bayesian statistical reasoning in a research setting: planning the analysis, executing the analysis, interpreting the results, and reporting the results. The guidelines for each stage are illustrated with a running example. Although the guidelines are geared towards analyses performed with the open-source statistical software JASP, most guidelines extend to Bayesian inference in general.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\7MXIQ57D\\van Doorn et al_2021_The JASP guidelines for conducting and reporting a Bayesian analysis.pdf}
}

@article{vandorenCapturingEmotionCoherence2021,
  title = {Capturing Emotion Coherence in Daily Life: {{Using}} Ambulatory Physiology Measures and Ecological Momentary Assessments to Examine within-Person Associations and Individual Differences},
  shorttitle = {Capturing Emotion Coherence in Daily Life},
  author = {Van Doren, Natalia and Dickens, Chelsea N. and Benson, Lizbeth and Brick, Timothy R. and Gatzke-Kopp, Lisa and Oravecz, Zita},
  date = {2021-05},
  journaltitle = {Biological Psychology},
  shortjournal = {Biological Psychology},
  volume = {162},
  pages = {108074},
  issn = {03010511},
  doi = {10/gjvq7k},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S030105112100065X},
  urldate = {2022-04-16},
  abstract = {While emotion coherence has long been theorized to be a core feature of emotion, to date, studies examining response coherence have been conducted in laboratory settings. The present study used a combined approach of ambulatory physiology measures and ecological momentary assessment conducted over a 4-week period to examine the extent to which emotional experience and physiology show coherence in daily life within-persons; and whether individual differences in response coherence are associated with between-person differences in well-being, negative emotionality, and gender. Results revealed that, on average, individuals exhibited coher­ ence between subjective experience and physiology of emotion, but that there was substantial between-person variation in coherence in daily life. Exploratory analyses revealed no credible link between levels of response coherence and well-being, negative emotionality, or gender. Findings contribute to the literature by demon­ strating a novel methodological approach to measuring coherence in daily life and supporting the generaliz­ ability of coherence to ecologically valid contexts.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\FMLT7WA2\\Van Doren et al. - 2021 - Capturing emotion coherence in daily life Using a.pdf}
}

@article{vanerpPriorSensitivityAnalysis,
  title = {Prior {{Sensitivity Analysis}} in {{Default Bayesian Structural Equation Modeling}}},
  author = {van Erp, Sara and Mulder, Joris and Oberski, Daniel L},
  options = {useprefix=true},
  pages = {67},
  abstract = {Bayesian structural equation modeling (BSEM) has recently gained popularity because it enables researchers to fit complex models while solving some of the issues often encountered in classical maximum likelihood (ML) estimation, such as nonconvergence and inadmissible solutions. An important component of any Bayesian analysis is the prior distribution of the unknown model parameters. Often, researchers rely on default priors, which are constructed in an automatic fashion without requiring substantive prior information. However, the prior can have a serious influence on the estimation of the model parameters, which affects the mean squared error (MSE), bias, coverage rates, and quantiles of the estimates. In this paper, we investigate the performance of three different default priors: noninformative improper priors, vague proper priors, and empirical Bayes priors, with the latter being novel in the BSEM literature. Based on a simulation study, we find that these three default BSEM methods may perform very differently, especially with small samples. A careful prior sensitivity analysis is therefore needed when performing a default BSEM analysis. For this purpose, we provide a practical step-by-step guide for practitioners to conducting a prior sensitivity analysis in default BSEM. Our recommendations are illustrated using a well-known case study from the structural equation modeling literature and all code for conducting the prior sensitivity analysis is made available in the online supplemental material.},
  langid = {english},
  keywords = {❓ Multiple DOI},
  file = {D\:\\Zotero\\storage\\46HLGYSP\\van Erp et al. - Prior Sensitivity Analysis in Default Bayesian Str.pdf}
}

@article{vasishthBayesianDataAnalysis2018,
  title = {Bayesian Data Analysis in the Phonetic Sciences: {{A}} Tutorial Introduction},
  shorttitle = {Bayesian Data Analysis in the Phonetic Sciences},
  author = {Vasishth, Shravan and Nicenboim, Bruno and Beckman, Mary E. and Li, Fangfang and Kong, Eun Jong},
  date = {2018-11},
  journaltitle = {Journal of Phonetics},
  shortjournal = {Journal of Phonetics},
  volume = {71},
  pages = {147--161},
  issn = {00954470},
  doi = {10/gfzq3c},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0095447017302310},
  urldate = {2022-04-16},
  abstract = {This tutorial analyzes voice onset time (VOT) data from Dongbei (Northeastern) Mandarin Chinese and North American English to demonstrate how Bayesian linear mixed models can be fit using the programming language Stan via the R package brms. Through this case study, we demonstrate some of the advantages of the Bayesian framework: researchers can (i) flexibly define the underlying process that they believe to have generated the data; (ii) obtain direct information regarding the uncertainty about the parameter that relates the data to the theoretical question being studied; and (iii) incorporate prior knowledge into the analysis. Getting started with Bayesian modeling can be challenging, especially when one is trying to model one’s own (often unique) data. It is difficult to see how one can apply general principles described in textbooks to one’s own specific research problem. We address this barrier to using Bayesian methods by providing three detailed examples, with source code to allow easy reproducibility. The examples presented are intended to give the reader a flavor of the process of model-fitting; suggestions for further study are also provided. All data and code are available from: https://osf.io/g4zpv.},
  langid = {english},
  keywords = {/unread,I 级文献},
  file = {D\:\\Zotero\\storage\\4YX3KWY8\\Vasishth et al_2018_Bayesian data analysis in the phonetic sciences.pdf}
}

@report{vasishthBayesianHierarchicalFinite2017,
  type = {preprint},
  title = {Bayesian {{Hierarchical Finite Mixture Models}} of {{Reading Times}}: {{A Case Study}}},
  shorttitle = {Bayesian {{Hierarchical Finite Mixture Models}} of {{Reading Times}}},
  author = {Vasishth, Shravan and Nicenboim, Bruno and Chopin, Nicolas and Ryder, Robin},
  date = {2017-07-12},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/a4hs9},
  url = {https://osf.io/a4hs9},
  urldate = {2022-06-01},
  abstract = {We present a case study demonstrating the importance of Bayesian hierarchical mixture models as a modelling tool for evaluating the predictions of competing theories of cognitive processes. As a case study, we revisit two published data sets from psycholinguistics. In sentence comprehension, it is widely assumed that the distance between linguistic co-dependents affects the latency of dependency resolution: the longer the distance, the longer the time taken to complete the dependency (e.g., Gibson 2000). An alternative theory, direct access (McElree, 1993), assumes that retrieval times are a mixture of two distributions (Nicenboim \&amp; Vasishth, 2017): one distribution represents successful retrievals and the other represents an initial failure to retrieve the correct dependent, followed by a reanalysis that leads to successful retrieval. Here, dependency distance has the effect that in long-distance conditions the proportion of reanalyses is higher. We implement both theories as Bayesian hierarchical models and show that the direct-access model fits the Chinese relative clause reading time data better than the dependency-distance account. This work makes several novel contributions. First, we demonstrate how the researcher can reason about the underlying generative process of their data, thereby expressing the underlying cognitive process as a statistical model. Second, we show how models that have been developed in an exploratory manner to represent different underlying generative processes can be compared in terms of their predictive performance, using both K-fold cross validation on existing data, and using completely new data. Finally, we show how the models can be evaluated using simulated data.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\FML3FM3Z\\Vasishth et al. - 2017 - Bayesian Hierarchical Finite Mixture Models of Rea.pdf}
}

@article{vasishthSampleSizeDetermination2022a,
  title = {Sample {{Size Determination}} for {{Bayesian Hierarchical Models Commonly Used}} in {{Psycholinguistics}}},
  author = {Vasishth, Shravan and Yadav, Himanshu and Schad, Daniel J. and Nicenboim, Bruno},
  date = {2022-03-04},
  journaltitle = {Computational Brain \& Behavior},
  shortjournal = {Comput Brain Behav},
  issn = {2522-0861, 2522-087X},
  doi = {10.1007/s42113-021-00125-y},
  url = {https://link.springer.com/10.1007/s42113-021-00125-y},
  urldate = {2022-09-01},
  abstract = {We discuss an important issue that is not directly related to the main theses of the van Doorn et al. (Computational Brain and Behavior, 2021) paper, but which frequently comes up when using Bayesian linear mixed models: how to determine sample size in advance of running a study when planning a Bayes factor analysis. We adapt a simulation-based method proposed by Wang and Gelfand (Statistical Science 193–208, 2002) for a Bayes factor-based design analysis, and demonstrate how relatively complex hierarchical models can be used to determine approximate sample sizes for planning experiments.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\FHGLEFRA\\Vasishth et al. - 2022 - Sample Size Determination for Bayesian Hierarchica.pdf}
}

@report{veenmanBayesianHierarchicalModeling2022,
  type = {preprint},
  title = {Bayesian {{Hierarchical Modeling}}: {{An Introduction}} and {{Reassessment}}},
  shorttitle = {Bayesian {{Hierarchical Modeling}}},
  author = {Veenman, Myrthe and Stefan, Angelika and Haaf, Julia M.},
  date = {2022-08-19},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/pskvx},
  url = {https://osf.io/pskvx},
  urldate = {2022-08-20},
  abstract = {With the recent development of easy-to-use tools for Bayesian analysis, psychologists have started to embrace Bayesian hierarchical modeling. Bayesian hierarchical models provide an intuitive account of inter- and intraindividual variability and are particularly suited for the evaluation of repeated-measures designs. Here, we provide guidance for model specificaton and interpretation in Bayesian hierarchical modeling and describe common pitfalls that can arise in the process of model fitting and evaluation. Our introduction gives particular emphasis to prior specification and prior sensitivity, as well as to the calculation of Bayes factors for model comparisons. We illustrate the use of state-of-the-art software programs Stan and brms. The result is an overview over best practices in Bayesian hierarchical modeling that, as we hope, will help psychologists in making the best use of Bayesian hierarchical modeling.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\25M5CTAB\\Veenman et al. - 2022 - Bayesian Hierarchical Modeling An Introduction an.pdf}
}

@article{VehtariEtAl:2015a,
  title = {Pareto Smoothed Importance Sampling},
  author = {Vehtari, Aki and Simpson, Daniel and Gelman, Andrew and Yao, Yuling and Gabry, Jonah},
  date = {2015-07},
  keywords = {⛔ No DOI found}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki},
  date = {2017},
  journaltitle = {Stat Comput},
  pages = {20},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  langid = {english},
  keywords = {❓ Multiple DOI},
  file = {D\:\\Zotero\\storage\\8HHUHJBP\\Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf;D\:\\Zotero\\storage\\C93WJSCK\\Vehtari et al_2017_Practical Bayesian model evaluation using leave-one-out cross-validation and.pdf;D\:\\Zotero\\storage\\UXD3SFEH\\Vehtari_2017_Practical Bayesian model evaluation using leave-one-out cross-validation and.pdf}
}

@article{wagenmakersBayesianHypothesisTesting2010,
  title = {Bayesian Hypothesis Testing for Psychologists: {{A}} Tutorial on the {{Savage}}–{{Dickey}} Method},
  shorttitle = {Bayesian Hypothesis Testing for Psychologists},
  author = {Wagenmakers, Eric-Jan and Lodewyckx, Tom and Kuriyal, Himanshu and Grasman, Raoul},
  date = {2010-05},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {60},
  number = {3},
  pages = {158--189},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2009.12.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010028509000826},
  urldate = {2022-07-25},
  abstract = {In the field of cognitive psychology, the p-value hypothesis test has established a stranglehold on statistical reporting. This is unfortunate, as the p-value provides at best a rough estimate of the evidence that the data provide for the presence of an experimental effect. An alternative and arguably more appropriate measure of evidence is conveyed by a Bayesian hypothesis test, which prefers the model with the highest average likelihood. One of the main problems with this Bayesian hypothesis test, however, is that it often requires relatively sophisticated numerical methods for its computation. Here we draw attention to the Savage–Dickey density ratio method, a method that can be used to compute the result of a Bayesian hypothesis test for nested models and under certain plausible restrictions on the parameter priors. Practical examples demonstrate the method’s validity, generality, and flexibility.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\BW49VFC4\\Wagenmakers et al_2010_Bayesian hypothesis testing for psychologists.pdf}
}

@article{wagenmakersBayesianInferencePsychology2018,
  title = {Bayesian Inference for Psychology. {{Part II}}: {{Example}} Applications with {{JASP}}},
  shorttitle = {Bayesian Inference for Psychology. {{Part II}}},
  author = {Wagenmakers, Eric-Jan and Love, Jonathon and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Selker, Ravi and Gronau, Quentin F. and Dropmann, Damian and Boutin, Bruno and Meerhoff, Frans and Knight, Patrick and Raj, Akash and van Kesteren, Erik-Jan and van Doorn, Johnny and Šmíra, Martin and Epskamp, Sacha and Etz, Alexander and Matzke, Dora and de Jong, Tim and van den Bergh, Don and Sarafoglou, Alexandra and Steingroever, Helen and Derks, Koen and Rouder, Jeffrey N. and Morey, Richard D.},
  options = {useprefix=true},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {58--76},
  issn = {1069-9384, 1531-5320},
  doi = {10/gdz7tt},
  url = {http://link.springer.com/10.3758/s13423-017-1323-7},
  urldate = {2022-03-25},
  langid = {english},
  keywords = {/unread,II 级文献},
  file = {D\:\\Zotero\\storage\\5K4FA92K\\Wagenmakers et al. - 2018 - Bayesian inference for psychology. Part II Exampl.pdf}
}

@article{wagenmakersBayesianInferencePsychology2018a,
  title = {Bayesian Inference for Psychology. {{Part I}}: {{Theoretical}} Advantages and Practical Ramifications},
  shorttitle = {Bayesian Inference for Psychology. {{Part I}}},
  author = {Wagenmakers, Eric-Jan and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Love, Jonathon and Selker, Ravi and Gronau, Quentin F. and Šmíra, Martin and Epskamp, Sacha and Matzke, Dora and Rouder, Jeffrey N. and Morey, Richard D.},
  date = {2018-02},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychon Bull Rev},
  volume = {25},
  number = {1},
  pages = {35--57},
  issn = {1069-9384, 1531-5320},
  doi = {10.3758/s13423-017-1343-3},
  url = {http://link.springer.com/10.3758/s13423-017-1343-3},
  urldate = {2022-07-01},
  abstract = {Bayesian parameter estimation and Bayesian hypothesis testing present attractive alternatives to classical inference using confidence intervals and p values. In part I of this series we outline ten prominent advantages of the Bayesian approach. Many of these advantages translate to concrete opportunities for pragmatic researchers. For instance, Bayesian hypothesis testing allows researchers to quantify evidence and monitor its progression as data come in, without needing to know the intention with which the data were collected. We end by countering several objections to Bayesian hypothesis testing. Part II of this series discusses JASP, a free and open source software program that makes it easy to conduct Bayesian estimation and testing for a range of popular statistical scenarios (Wagenmakers et al., this issue).},
  langid = {english},
  keywords = {II 级文献},
  file = {D\:\\Zotero\\storage\\VT82BA2P\\Wagenmakers et al. - 2018 - Bayesian inference for psychology. Part I Theoret.pdf}
}

@article{wangBeiYeSiTongJiYuChuanTongTongJiFangFaDeBiJiao2021,
  title = {贝叶斯统计与传统统计方法的比较},
  author = {王, 婧 and 鲍, 贵},
  date = {2021},
  journaltitle = {统计与决策},
  volume = {37},
  number = {1},
  pages = {24--29},
  issn = {1002-6487},
  doi = {10.13546/j.cnki.tjyjc.2021.01.005},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=TJJC202101005&v=},
  abstract = {贝叶斯统计为数据分析提供了新的视角。贝叶斯因子量化备择假设和零假设相对证据的强度,是连续性测量。贝叶斯参数估计得到的95\%高密度区间和实际对等域为统计决策提供充分的信息。文章通过对一项实验研究数据的再分析,揭示了贝叶斯统计相对于传统统计所具有的优势,包括直觉上的吸引力、证据的力度与透明度以及避免过度解释研究发现。贝叶斯统计必将在应用语言学实证研究中发挥越来越重要的作用。},
  langid = {chinese},
  keywords = {95\% high density interval,95\%高密度区间,Bayes factor,region of practical equivalence,traditional statistics,传统统计,实际对等域 Bayesian statistics,贝叶斯因子,贝叶斯统计},
  annotation = {7 citations(CNKI)[4-26-2022]{$<$}北大核心, CSSCI{$>$}},
  file = {D\:\\Zotero\\storage\\6WW6IN4E\\贝叶斯统计与传统统计方法的比较_王婧.pdf}
}

@article{wedelTutorialAnalysisExperiments2022,
  title = {A Tutorial on the Analysis of Experiments Using {{BANOVA}}},
  author = {Wedel, Michel and Dong, Chen},
  date = {2022-06},
  journaltitle = {Psychological Methods},
  shortjournal = {Psychological Methods},
  volume = {27},
  number = {3},
  pages = {433--450},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000408},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/met0000408},
  urldate = {2022-07-31},
  abstract = {Bayesian methods are increasingly used in psychology for analyzing experimental data and for identifying mechanisms that mediate the experimental treatments. This article provides a tutorial on a Bayesian approach to the analysis of variance (BANOVA), which provides a comprehensive and coherent framework for those analyses. BANOVA encompasses the analysis of data from between, within, and mixed experimental designs with normal and non-normal dependent variables and accommodates unobserved individual differences in participants’ response to the experimental manipulations. An accompanying R package allows specification of a wide range of models with a simple syntax, and can calculate planned comparisons, simple effects, floodlight ranges, indirect effects in mediation, moderated mediation, and effect sizes of direct and indirect effects. The methodology and package are illustrated with applications to three data sets from previously published studies in psychology.},
  langid = {english},
  keywords = {I 级文献},
  file = {D\:\\Zotero\\storage\\RHKNAX3J\\Wedel and Dong - 2022 - A tutorial on the analysis of experiments using BA.pdf}
}

@article{weigardModelingEffectsMethylphenidate2019,
  title = {Modeling the Effects of Methylphenidate on Interference and Evidence Accumulation Processes Using the Conflict Linear Ballistic Accumulator},
  author = {Weigard, Alexander and Heathcote, Andrew and Sripada, Chandra},
  date = {2019-08},
  journaltitle = {Psychopharmacology},
  shortjournal = {Psychopharmacology},
  volume = {236},
  number = {8},
  pages = {2501--2512},
  issn = {0033-3158, 1432-2072},
  doi = {10/gjtf2r},
  url = {http://link.springer.com/10.1007/s00213-019-05316-x},
  urldate = {2022-04-16},
  abstract = {Rationale: Although methylphenidate and other stimulants have been demonstrated to improve task performance across a variety of domains, a computationally rigorous account of how these drugs alter cognitive processing remains elusive. Recent applications of mathematical models of cognitive processing and electrophysiological methods to this question have suggested that stimulants improve the integrity of evidence accumulation processes for relevant choices, potentially through catecholaminergic modulation of neural signal-to-noise ratios. However, this nascent line of work has thus far been limited to simple perceptual tasks and has largely omitted more complex “conflict” paradigms that contain experimental manipulations of specific top-down interference resolution processes. Objectives and Methods: To address this gap, this study applied the Conflict Linear Ballistic Accumulator (LBA), a newly proposed model designed for conflict tasks, to data from healthy adults who performed the MultiSource Interference Task (MSIT) after acute methylphenidate or placebo challenge. Results: Modelbased analyses revealed that methylphenidate improved performance by reducing individuals’ response thresholds and by enhancing evidence accumulation processes across all task conditions, either by improving the quality of evidence or by reducing variability in accumulation processes. In contrast, the drug did not reduce bottom-up interference or selectively facilitate top-down interference resolution processes probed by the experimental conflict manipulation. Conclusions: Enhancement of evidence accumulation is a biologically plausible and task-general mechanism of stimulant effects on cognition. Moreover, the assumption that methylphenidate’s effects on behavior are only visible with complex “executive” tasks may be misguided.},
  langid = {english},
  keywords = {LAB},
  file = {D\:\\Zotero\\storage\\HZK9CEG8\\Weigard et al. - 2019 - Modeling the effects of methylphenidate on interfe.pdf}
}

@article{Welford:1962,
  title = {Note on a Method for Calculating Corrected Sums of Squares and Products},
  author = {Welford, B. P.},
  date = {1962},
  journaltitle = {Technometrics : a journal of statistics for the physical, chemical, and engineering sciences},
  shortjournal = {Technometrics},
  volume = {4},
  number = {3},
  pages = {419--420},
  keywords = {⛔ No DOI found}
}

@article{wesslenInvestigatingEffectsVisual2019,
  title = {Investigating {{Effects}} of {{Visual Anchors}} on {{Decision}}‐{{Making}} about {{Misinformation}}},
  author = {Wesslen, R. and Santhanam, S. and Karduni, A. and Cho, I. and Shaikh, S. and Dou, W.},
  date = {2019-06},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {38},
  number = {3},
  pages = {161--171},
  issn = {0167-7055, 1467-8659},
  doi = {10/gmb2gt},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13679},
  urldate = {2022-04-16},
  abstract = {Cognitive biases are systematic errors in judgment due to an over-reliance on rule-of-thumb heuristics. Recent research suggests that cognitive biases, like numerical anchoring, transfers to visual analytics in the form of visual anchoring. However, it is unclear how visualization users can be visually anchored and how the anchors affect decision-making. To investigate, we performed a between-subjects laboratory experiment with 94 participants to analyze the effects of visual anchors and strategy cues using a visual analytics system. The decision-making task was to identify misinformation from Twitter news accounts. Participants were randomly assigned to conditions that modified the scenario video (visual anchor) and/or strategy cues provided. Our findings suggest that such interventions affect user activity, speed, confidence, and, under certain circumstances, accuracy. We discuss implications of our results on the forking paths problem and raise concerns on how visualization researchers train users to avoid unintentionally anchoring users and affecting the end result.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\3ETAPJSS\\Wesslen et al_2019_Investigating Effects of Visual Anchors on Decision‐Making about Misinformation.pdf;D\:\\Zotero\\storage\\SYIP68UV\\Wesslen et al. - 2019 - Investigating Effects of Visual Anchors on Decisio.pdf}
}

@article{westfallStatisticalPowerOptimal2014a,
  title = {Statistical Power and Optimal Design in Experiments in Which Samples of Participants Respond to Samples of Stimuli.},
  author = {Westfall, Jacob and Kenny, David A. and Judd, Charles M.},
  date = {2014},
  journaltitle = {Journal of Experimental Psychology: General},
  shortjournal = {Journal of Experimental Psychology: General},
  volume = {143},
  number = {5},
  pages = {2020--2045},
  issn = {1939-2222, 0096-3445},
  doi = {10.1037/xge0000014},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000014},
  urldate = {2022-08-31},
  abstract = {Researchers designing experiments in which a sample of participants responds to a sample of stimuli are faced with difficult questions about optimal study design. The conventional procedures of statistical power analysis fail to provide appropriate answers to these questions because they are based on statistical models in which stimuli are not assumed to be a source of random variation in the data, models that are inappropriate for experiments involving crossed random factors of participants and stimuli. In this article, we present new methods of power analysis for designs with crossed random factors, and we give detailed, practical guidance to psychology researchers planning experiments in which a sample of participants responds to a sample of stimuli. We extensively examine 5 commonly used experimental designs, describe how to estimate statistical power in each, and provide power analysis results based on a reasonable set of default parameter values. We then develop general conclusions and formulate rules of thumb concerning the optimal design of experiments in which a sample of participants responds to a sample of stimuli. We show that in crossed designs, statistical power typically does not approach unity as the number of participants goes to infinity but instead approaches a maximum attainable power value that is possibly small, depending on the stimulus sample. We also consider the statistical merits of designs involving multiple stimulus blocks. Finally, we provide a simple and flexible Web-based power application to aid researchers in planning studies with samples of stimuli.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\7Q4MZC5W\\Westfall et al. - 2014 - Statistical power and optimal design in experiment.pdf}
}

@article{whiteWordFrequencyEffect2018,
  title = {The Word Frequency Effect during Sentence Reading: {{A}} Linear or Nonlinear Effect of Log Frequency?},
  shorttitle = {The Word Frequency Effect during Sentence Reading},
  author = {White, Sarah J and Drieghe, Denis and Liversedge, Simon P and Staub, Adrian},
  date = {2018-01},
  journaltitle = {Quarterly Journal of Experimental Psychology},
  shortjournal = {Quarterly Journal of Experimental Psychology},
  volume = {71},
  number = {1},
  pages = {46--55},
  issn = {1747-0218, 1747-0226},
  doi = {10/gprpbw},
  url = {http://journals.sagepub.com/doi/10.1080/17470218.2016.1240813},
  urldate = {2022-03-25},
  abstract = {The effect of word frequency on eye movement behaviour during reading has been reported in many experimental studies. However, the vast majority of these studies compared only two levels of word frequency (high and low). Here we assess whether the effect of log word frequency on eye movement measures is linear, in an experiment in which a critical target word in each sentence was at one of three approximately equally spaced log frequency levels. Separate analyses treated log frequency as a categorical or a continuous predictor. Both analyses showed only a linear effect of log frequency on the likelihood of skipping a word, and on first fixation duration. Ex-Gaussian analyses of first fixation duration showed similar effects on distributional parameters in comparing high- and medium-frequency words, and medium- and low-frequency words. Analyses of gaze duration and the probability of a refixation suggested a nonlinear pattern, with a larger effect at the lower end of the log frequency scale. However, the nonlinear effects were small, and Bayes Factor analyses favoured the simpler linear models for all measures. The possible roles of lexical and post-lexical factors in producing nonlinear effects of log word frequency during sentence reading are discussed.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\QKZD6EVU\\White et al_2018_The word frequency effect during sentence reading.pdf}
}

@article{WilkinsonEtAl:1973,
  title = {Symbolic Description of Factorial Models for Analysis of Variance},
  author = {Wilkinson, G. N. and Rogers, C. E.},
  date = {1973},
  journaltitle = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {22},
  number = {3},
  pages = {392--399},
  keywords = {⛔ No DOI found}
}

@report{williamsBGGMPackageBayesian2019,
  type = {preprint},
  title = {{{BGGM}}: {{A R Package}} for {{Bayesian Gaussian Graphical Models}}},
  shorttitle = {{{BGGM}}},
  author = {Williams, Donald Ray and Mulder, Joris},
  date = {2019-06-14},
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/3b5hf},
  url = {https://osf.io/3b5hf},
  urldate = {2022-03-25},
  abstract = {Gaussian graphical models (GGM) allow for learning conditional independence structures that are encoded by partial correlations. Whereas there are several R packages for classical (i.e., frequentist) methods, there are only two that implement a Bayesian approach. These are exclusively focused on identifying the graphical structure. The R package BGGM not only contains novel Bayesian methods for this purpose, but it also includes Bayesian methodology for extending inference beyond identifying non-zero relations. BGGM is built around two Bayesian approaches for inference–estimation and hypothesis testing. The former focuses on the posterior distribution and includes extensions to assess predictability, as well as methodology to compare partial correlations. The latter includes methods for Bayesian hypothesis testing, in both exploratory and confirmatory contexts, with the novel matrix-F prior distribution. This allows for testing order and equality constrained hypotheses, as well as a combination of both with the Bayes factor. Further, there are two approaches for comparing GGMs across any number of groups with either the posterior predictive distribution or with Bayesian hypothesis testing. This work describes the software implementation of these methods. We end by discussing future directions for BGGM.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\TCQ3CSDT\\Williams_Mulder_2019_BGGM.pdf}
}

@article{williamsonSampleSizeCalculation,
  title = {Sample {{Size Calculation}} with {{R}}},
  author = {Williamson, Mark},
  pages = {37},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\3G5KP43F\\Williamson - Sample Size Calculation with R.pdf}
}

@article{woodsBayesianDesignExperiments2016,
  title = {Bayesian Design of Experiments for Generalised Linear Models and Dimensional Analysis with Industrial and Scientific Application},
  author = {Woods, David C. and Overstall, Antony M. and Adamou, Maria and Waite, Timothy W.},
  date = {2016-10-13},
  journaltitle = {Quality Engineering},
  shortjournal = {Quality Engineering},
  pages = {0--0},
  issn = {0898-2112, 1532-4222},
  doi = {10/gj9b3s},
  url = {https://www.tandfonline.com/doi/full/10.1080/08982112.2016.1246045},
  urldate = {2022-03-25},
  abstract = {The design of an experiment can be always be considered at least implicitly Bayesian, with prior knowledge used informally to aid decisions such as the variables to be studied and the choice of a plausible relationship between the explanatory variables and measured responses. Bayesian methods allow uncertainty in these decisions to be incorporated into design selection through prior distributions that encapsulate information available from scientific knowledge or previous experimentation. Further, a design may be explicitly tailored to the aim of the experiment through a decision-theoretic approach using an appropriate loss function. We review the area of decision-theoretic Bayesian design, with particular emphasis on recent advances in computational methods. For many problems arising in industry and science, experiments result in a discrete response that is well described by a member of the class of generalised linear models. Bayesian design for such nonlinear models is often seen as impractical as the expected loss is analytically intractable and numerical approximations are usually computationally expensive. We describe how Gaussian process emulation, commonly used in computer experiments, can play an important role in facilitating Bayesian design for realistic problems. A main focus is the combination of Gaussian process regression to approximate the expected loss with cyclic descent (coordinate exchange) optimisation algorithms to allow optimal designs to be found for previously infeasible problems. We also present the first optimal design results for statistical models formed from dimensional analysis, a methodology widely employed in the engineering and physical sciences to produce parsimonious and interpretable models. Using the famous paper helicopter experiment, we show the potential for the combination of Bayesian design, generalised linear models and dimensional analysis to produce small but informative experiments.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\65TM79EL\\Woods et al_2016_Bayesian design of experiments for generalised linear models and dimensional.pdf}
}

@article{woolrichBayesianInferenceFMRI2012,
  title = {Bayesian Inference in {{FMRI}}},
  author = {Woolrich, Mark W.},
  date = {2012-08},
  journaltitle = {NeuroImage},
  shortjournal = {NeuroImage},
  volume = {62},
  number = {2},
  pages = {801--810},
  issn = {10538119},
  doi = {10/ct2m88},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811911012110},
  urldate = {2022-03-25},
  abstract = {Bayesian inference has taken FMRI methods research into areas that frequentist statistics have struggled to reach. In this article we will consider some of the early forays into Bayes and what motivated its use. We shall see the impact that Bayes has had on haemodynamic modelling, spatial modelling, group analysis, model selection and brain connectivity analysis; and consider how these advancements have spun-off into related areas of neuroscience and some of the challenges that remain. Bayes has brought to the table inference flexibility, incorporation of prior information, adaptive regularisation and model selection. But perhaps more important than these things, is the ability of Bayes to empower the methods researcher with a mathematically principled framework for inferring on any model.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\LNMLPIBT\\Woolrich_2012_Bayesian inference in FMRI.pdf}
}

@article{WOS:000266975600014,
  title = {Bayesian Model Selection for Group Studies},
  author = {Stephan, Klaas Enno and Penny, Will D. and Daunizeau, Jean and Moran, Rosalyn J. and Friston, Karl J.},
  date = {2009-07-15},
  journaltitle = {NEUROIMAGE},
  volume = {46},
  number = {4},
  pages = {1004--1017},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2009.03.025},
  eissn = {1095-9572},
  orcid-numbers = {Daunizeau, Jean/0000-0001-9142-1270 Friston, Karl/0000-0001-7984-8909 Moran, Rosalyn/0000-0002-2736-2621 Stephan, Klaas Enno/0000-0002-8594-9092 Penny, William/0000-0001-9064-1191},
  researcherid-numbers = {Daunizeau, Jean/AAB-3996-2019 Daunizeau, Jean/F-9225-2010 Friston, Karl/D-9230-2011},
  unique-id = {WOS:000266975600014},
  file = {D\:\\Zotero\\storage\\MVRD8KT4\\Stephan et al_2009_Bayesian model selection for group studies.pdf}
}

@article{WOS:000328868600090,
  title = {Bayesian Model Selection for Group Studies - {{Revisited}}},
  author = {Rigoux, L. and Stephan, K. E. and Friston, K. J. and Daunizeau, J.},
  date = {2014-01-01},
  journaltitle = {NEUROIMAGE},
  volume = {84},
  pages = {971--985},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2013.08.065},
  eissn = {1095-9572},
  orcid-numbers = {Friston, Karl/0000-0001-7984-8909 Daunizeau, Jean/0000-0001-9142-1270 Stephan, Klaas Enno/0000-0002-8594-9092 RIGOUX, Lionel/0000-0003-3761-8931},
  researcherid-numbers = {Daunizeau, Jean/AAB-3996-2019 Friston, Karl/D-9230-2011 Daunizeau, Jean/F-9225-2010},
  unique-id = {WOS:000328868600090},
  file = {D\:\\Zotero\\storage\\U6CJQMII\\Rigoux et al_2014_Bayesian model selection for group studies - Revisited.pdf}
}

@article{wuTiaoChuChuanTongJiaSheJianYanFangFaDeXianJingBeiYeSiYinZiZaiXinLiXueYanJiuLingYuDeYingYong2018,
  title = {跳出传统假设检验方法的陷阱——贝叶斯因子在心理学研究领域的应用},
  author = {吴, 凡 and 顾, 全 and 施, 壮华 and 高, 在峰 and 沈, 模卫},
  date = {2018},
  journaltitle = {应用心理学},
  volume = {24},
  number = {3},
  pages = {195--202},
  issn = {1006-6020},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2018&filename=YXNX201803001&v=},
  abstract = {近年来,心理学研究者逐渐认识到假设检验这一推论统计方法在理论与实践中的不足。在心理学研究面对日益严重的"可重复危机"、急需更优良的验证手段时,贝叶斯因子分析在众多统计方法中脱颖而出。相比传统的假设检验方法,贝叶斯因子具有诸多优势,能够揭示备择假设与虚无假设成立可能性的高低,因此心理学界也出现了以贝叶斯因子分析取代传统假设检验的呼声。本文列举了贝叶斯因子相对于假设检验的主要优势,并重点介绍了贝叶斯因子在常规心理学研究中的计算方法及应用,同时说明了运用贝叶斯因子进行统计分析时需注意的问题。},
  langid = {chinese},
  keywords = {⛔ No DOI found,NHST,p value,p值,statistical inference,假设检验,推论统计 Bayes factor,贝叶斯因子},
  annotation = {26 citations(CNKI)[4-26-2022]{$<$}CSSCI{$>$}},
  file = {D\:\\Zotero\\storage\\FPIQ7YCX\\吴 et al_2018_跳出传统假设检验方法的陷阱——贝叶斯因子在心理学研究领域的应用.pdf}
}

@article{XinHaoJianCeLunYuBeiYeSiJueCeLiLunDeGuanXi,
  title = {信号检测论与贝叶斯决策理论的关系},
  file = {D\:\\Zotero\\storage\\UKDP5ICC\\信号检测论与贝叶斯决策理论的关系.pdf}
}

@article{yangBayesSenMCPackageBayesian2021a,
  title = {{{BayesSenMC}}: An {{R}} Package for {{Bayesian Sensitivity Analysis}} of {{Misclassification}}},
  author = {Yang, Jinhui and Lin, Lifeng and Chu, Haitao},
  date = {2021},
  volume = {13},
  pages = {11},
  abstract = {In case–control studies, the odds ratio is commonly used to summarize the association between a binary exposure and a dichotomous outcome. However, exposure misclassification frequently appears in case–control studies due to inaccurate data reporting, which can produce bias in measures of association. In this article, we implement a Bayesian sensitivity analysis of misclassification to provide a full posterior inference on the corrected odds ratio under both non-differential and differential misclassification. We present an R (R Core Team, 2018) package BayesSenMC, which provides user-friendly functions for its implementation. The usage is illustrated by a real data analysis on the association between bipolar disorder and rheumatoid arthritis.},
  langid = {english},
  file = {D\:\\Zotero\\storage\\SNR82DIM\\Yang et al. - 2021 - BayesSenMC an R package for Bayesian Sensitivity .pdf}
}

@article{YaoEtAl:2018,
  title = {Yes, but Did It Work?: {{Evaluating}} Variational Inference},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  date = {2018-02},
  keywords = {⛔ No DOI found}
}

@article{yeSensitivityAnalysisAssessment,
  title = {Sensitivity Analysis and Assessment of Prior Model Probabilities in {{MLBMA}} with Application to Unsaturated Fractured Tuff},
  author = {Ye, Ming and Neuman, Shlomo P and Meyer, Philip D and Pohlmann, Karl},
  pages = {14},
  doi = {10.1029/2005WR004260},
  langid = {english},
  file = {D\:\\Zotero\\storage\\R3SY33JB\\Ye et al. - Sensitivity analysis and assessment of prior model.pdf}
}

@article{youngBayesianDataAnalysis2019,
  title = {Bayesian Data Analysis as a Tool for Behavior Analysts: {{Bayesian}} Analysis},
  shorttitle = {Bayesian Data Analysis as a Tool for Behavior Analysts},
  author = {Young, Michael E.},
  date = {2019-03},
  journaltitle = {Journal of the Experimental Analysis of Behavior},
  shortjournal = {Jrnl Exper Analysis Behavior},
  volume = {111},
  number = {2},
  pages = {225--238},
  issn = {00225002},
  doi = {10/gfxnbc},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/jeab.512},
  urldate = {2022-04-16},
  abstract = {Bayesian approaches to data analysis are considered within the context of behavior analysis. The paper distinguishes between Bayesian inference, the use of Bayes Factors, and Bayesian data analysis using specialized tools. Given the importance of prior beliefs to these approaches, the review addresses those situations in which priors have a big effect on the outcome (Bayes Factors) versus a smaller effect (parameter estimation). Although there are many advantages to Bayesian data analysis from a philosophical perspective, in many cases a behavior analyst can be reasonably well-served by the adoption of traditional statistical tools as long as the focus is on parameter estimation and model comparison, not null hypothesis significance testing. A strong case for Bayesian analysis exists under specific conditions: When prior beliefs can help narrow parameter estimates (an especially important issue given the small sample sizes common in behavior analysis) and when an analysis cannot easily be conducted using traditional approaches (e.g., repeated measures censored regression).},
  langid = {english},
  file = {D\:\\Zotero\\storage\\UVIA6JJZ\\Young - 2019 - Bayesian data analysis as a tool for behavior anal.pdf}
}

@article{youngPlaceStatisticsBehavior2018,
  title = {A Place for Statistics in Behavior Analysis.},
  author = {Young, Michael E.},
  date = {2018-05},
  journaltitle = {Behavior Analysis: Research and Practice},
  shortjournal = {Behavior Analysis: Research and Practice},
  volume = {18},
  number = {2},
  pages = {193--202},
  issn = {2372-9414},
  doi = {10/gprpbc},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/bar0000099},
  urldate = {2022-03-25},
  abstract = {Behavior analysis has had an uneasy relationship with statistics. A historical reliance on visual inspection has slowly given way to null hypothesis significance testing and quantitative modeling, but this path has been fraught with missteps. There are challenges with reducing variability while also faithfully representing the variability that remains, and aggregation of outcome variables can undermine these goals. This manuscript highlights the shortcomings of human perception and judgment and the need to use modern statistical analysis to describe behavior and the uncertainty in these descriptions; statistical hypothesis testing based on a threshold should not be used as a substitute for human inference. A case is made for the increased use of generalized linear modeling, multilevel modeling, and model comparison as well as a need for stronger statistical training in behavior analysis programs.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\BLC2J5GW\\Young_2018_A place for statistics in behavior analysis.pdf}
}

@article{yuenBayesianMethodsUpdating2011,
  title = {Bayesian {{Methods}} for {{Updating Dynamic Models}}},
  author = {Yuen, Ka-Veng and Kuok, Sin-Chi},
  date = {2011-01-01},
  journaltitle = {Applied Mechanics Reviews},
  volume = {64},
  number = {1},
  pages = {010802},
  issn = {0003-6900, 2379-0407},
  doi = {10/cf5jzq},
  url = {https://asmedigitalcollection.asme.org/appliedmechanicsreviews/article/64/1/010802/465483/Bayesian-Methods-for-Updating-Dynamic-Models},
  urldate = {2022-03-25},
  abstract = {Abstract             Model updating of dynamical systems has been attracting much attention because it has a very wide range of applications in aerospace, civil, and mechanical engineering, etc. Many methods were developed and there has been substantial development in Bayesian methods for this purpose in the recent decade. This article introduces some state-of-the-art work. It consists of two main streams of model updating, namely model updating using response time history and model updating using modal measurements. The former one utilizes directly response time histories for the identification of uncertain parameters. In particular, the Bayesian time-domain approach, Bayesian spectral density approach and Bayesian fast Fourier transform approach will be introduced. The latter stream utilizes modal measurements of a dynamical system. The method introduced here does not require a mode matching process that is common in other existing methods. Afterwards, discussion will be given about the relationship among model complexity, data fitting capability and robustness. An application of a 22-story building will be presented. Its acceleration response time histories were recorded during a severe typhoon and they are utilized to identify the fundamental frequency of the building. Furthermore, three methods are used for analysis on this same set of measurements and comparison will be made.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\AYXIEG69\\Yuen_Kuok_2011_Bayesian Methods for Updating Dynamic Models.pdf}
}

@article{zgonnikovReachMotorCosts,
  title = {Beyond the Reach: {{Do}} Motor Costs Affect Intertemporal Choice?},
  author = {Zgonnikov, Arkady and Rano, Inaki and O’Hora, Denis and Atiya, Nadim and Wong-Lin, KongFatt},
  journaltitle = {Judgment and Decision Making},
  pages = {10},
  abstract = {Executing an important decision is often as easy as reaching towards the preferred option with a hand or a mouse cursor. But would we decide differently if choosing required walking a few steps towards an option? More generally, is our preference invariant to how we signal it? Previous research demonstrated that asymmetric motor costs can nudge the decision-maker towards a less costly option. However, virtually all traditional decision-making theories predict that increasing motor costs symmetrically for all options should not affect choice in any way. This prediction is disputed by the theory of embodied cognition, which suggests that motor behavior is an integral part of cognitive processes, and that motor costs of deciding can affect our choices. In this registered report, we will investigate whether varying motor costs of responding affects response dynamics and final choices in decisions between a readily available small reward and a larger but delayed reward. Our study will include two versions of an intertemporal choice task: in a baseline condition, the subjects will respond using a computer mouse; in a more motor costly walking condition they will walk towards the preferred option. First, we will investigate whether relative values of the intertemporal choice options affect walking trajectories in the same way as they affect mouse cursor dynamics. Second, we will test a hypothesis that in the walking condition, increased motor costs of a preference reversal would decrease the number of changes-of-mind and therefore increase the proportion of impulsive, smaller-but-sooner choices. Regardless the outcome, our findings will establish an empirical basis enabling the decision-making theories to address the complex interplay between cognitive and motor processes.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {D\:\\Zotero\\storage\\2SARZYAZ\\Zgonnikov et al. - Beyond the reach Do motor costs aﬀect intertempor.pdf}
}

@inproceedings{zhangBeiYeSiJieGouFangChengMoXingJiQiYanJiuXianZhuang2019,
  title = {贝叶斯结构方程模型及其研究现状},
  author = {张, 沥今 and 陆, 嘉琦 and 魏, 夏琰 and 潘, 俊豪},
  date = {2019},
  pages = {2063},
  publisher = {{中国心理学会}},
  url = {https://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CPFD&dbname=CPFDLAST2020&filename=ZGXG201910001A2Z&v=},
  abstract = {在心理学研究中结构方程模型被广泛用于检验潜变量间的关系,其估计方法有频率学方法(如,极大似然估计)和贝叶斯方法两类。而传统的频率学派方法对模型施加的限制往往过于严格,这种限制在大样本情况下很容易拒绝实际上和数据拟合良好的模型。在传统方法中为了解决这种限制带来的问题,研究者通常会结合理论和修正指数的建议,在模型中增加交叉载荷或残差相关。但是这种基于修正指数的方法很容易受到研究者主观选择的影响,容易导致一类错误率的增大和模型的过拟合,削弱其泛化能力。贝叶斯结构方程模型通过结合先验信息可以较好地解决上述问题,此外,在模型识别和拟合、参数估计、处理复杂模型和小样本情况等方面贝叶斯方法都有着更好的表现,能够更好地满足应用研究者在实证研究中的需求,但其在国内心理学领域的应用不足。本文将详细介绍贝叶斯结构方程建模的原理和优势,并通过实例分析与传统估计方法进行深入对比,展示贝叶斯建模的分析步骤和评价标准,希望能够为大家带来新的结构方程建模思路,解决采用传统方法建模时难以克服的问题。},
  langid = {chinese},
  keywords = {/unread,⛔ No DOI found,极大似然估计,结构方程模型,贝叶斯估计},
  file = {D\:\\Zotero\\storage\\UKTYCI8I\\张 et al_2019_贝叶斯结构方程模型及其研究现状.pdf}
}

@article{ZhangEtAl:2009,
  title = {A New and Efficient Estimation Method for the Generalized Pareto Distribution},
  author = {Zhang, Jin and Stephens, Michael A.},
  date = {2009},
  journaltitle = {Technometrics : a journal of statistics for the physical, chemical, and engineering sciences},
  shortjournal = {Technometrics},
  volume = {51},
  number = {3},
  pages = {316--325},
  keywords = {⛔ No DOI found}
}

@article{zhanUsingJAGSBayesian2019,
  title = {Using {{JAGS}} for {{Bayesian Cognitive Diagnosis Modeling}}: {{A Tutorial}}},
  shorttitle = {Using {{JAGS}} for {{Bayesian Cognitive Diagnosis Modeling}}},
  author = {Zhan, Peida and Jiao, Hong and Man, Kaiwen and Wang, Lijun},
  date = {2019-08},
  journaltitle = {Journal of Educational and Behavioral Statistics},
  shortjournal = {Journal of Educational and Behavioral Statistics},
  volume = {44},
  number = {4},
  pages = {473--503},
  issn = {1076-9986, 1935-1054},
  doi = {10/gnsf7t},
  url = {http://journals.sagepub.com/doi/10.3102/1076998619826040},
  urldate = {2022-03-25},
  abstract = {In this article, we systematically introduce the just another Gibbs sampler (JAGS) software program to fit common Bayesian cognitive diagnosis models (CDMs) including the deterministic inputs, noisy “and” gate model; the deterministic inputs, noisy “or” gate model; the linear logistic model; the reduced reparameterized unified model; and the log-linear CDM (LCDM). Further, we introduce the unstructured latent structural model and the higher order latent structural model. We also show how to extend these models to consider polytomous attributes, the testlet effect, and longitudinal diagnosis. Finally, we present an empirical example as a tutorial to illustrate how to use JAGS codes in R.},
  langid = {english},
  keywords = {/unread},
  file = {D\:\\Zotero\\storage\\V3353BKM\\Zhan et al_2019_Using JAGS for Bayesian Cognitive Diagnosis Modeling.pdf}
}


